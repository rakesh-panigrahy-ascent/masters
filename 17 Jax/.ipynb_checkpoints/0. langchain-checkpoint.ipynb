{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cdda0a64-c00e-463d-8efa-4924c56f0498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\"\n",
    "os.environ['LANGCHAIN_API_KEY']='ls__971f18068e7e4536a62f1811c3aeb059'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1edeb30-e43b-49a3-9353-402b59925c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d16e9384-f260-45dc-80d6-22dbee0885a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith is a language model developed by Google that can assist with testing in several ways:\\n\\n1. Code Generation: Langsmith can generate code snippets based on natural language inputs, which can be used for testing purposes. For example, you can give Langsmith a description of a functionality you want to test, and it will generate the corresponding test cases.\\n2. Test Case Generation: Langsmith can also generate test cases automatically based on the API documentation of a system or application. This can save developers a lot of time and effort in creating test cases manually.\\n3. Code Review: Langsmith can review code changes and suggest improvements, which can help identify potential issues before they become bugs. This can be especially useful during testing, as it can help catch errors early on.\\n4. Bug Reporting: If a bug is found during testing, Langsmith can assist in creating a clear and concise report that includes the necessary details to reproduce the issue. This can save developers time and effort in tracking down bugs.\\n5. Test Data Generation: Langsmith can generate test data automatically based on the API documentation of a system or application. This can be useful for testing functions that require a lot of input data, such as image processing or natural language processing tasks.\\n6. Automated Testing: Langsmith can assist in automating testing processes by generating test cases and executing them automatically. This can save developers time and effort in manual testing, and can also help ensure that tests are executed consistently and accurately.\\n7. Test Case Prioritization: Langsmith can prioritize test cases based on risk and complexity, which can help developers focus their efforts on the most critical tests first. This can save time and resources by avoiding unnecessary testing of simpler or less critical functionality.\\n8. Defect Prediction: Langsmith can predict potential defects in a system or application based on historical data and machine learning algorithms. This can help developers identify areas of the code that are likely to have issues, and prioritize testing efforts accordingly.\\n9. Testing Optimization: Langsmith can optimize testing processes by identifying the most efficient and effective ways to test different parts of a system or application. This can save time and resources by avoiding unnecessary testing of redundant or already well-tested functionality.\\n10. Collaboration: Langsmith can collaborate with developers and testers to generate test cases, review code changes, and identify potential issues before they become bugs. This can help ensure that testing is done efficiently and effectively, and that issues are caught early on in the development process.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86ace54b-e0be-4b5c-acf3-850058fc8072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcadc460-085d-4f26-b462-af42dc55832f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chaining\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "366cd2c5-a18b-4f84-8f77-93613ba8083a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAs a world-class technical documentation writer, I must say that LinguaSmith is an incredible tool for testing and proofreading your content. Here are some ways in which Langsmith can help with testing:\\n\\n1. Grammar and Spelling Checks: Langsmith's advanced grammar and spelling checks can identify even the most subtle errors in your content, ensuring that it is free of mistakes and typos.\\n2. Contextual Error Detection: Langsmith's contextual error detection capabilities allow it to identify errors that may not be caught by traditional grammar and spell checkers. For example, it can detect errors in sentence structure, punctuation, and word choice.\\n3. Consistency Checking: Langsmith can help you maintain consistency throughout your content by checking for consistent use of terminology, formatting, and style.\\n4. Content Reuse Detection: If you have a large volume of content to test, Langsmith can help identify duplicate or redundant content, allowing you to simplify or consolidate your content.\\n5. Readability Analysis: Langsmith's readability analysis can help you evaluate the complexity and clarity of your content, ensuring that it is easy to understand for your target audience.\\n6. Accessibility Audit: Langsmith can perform an accessibility audit to identify any barriers to accessibility in your content, such as lack of alt tags, incomplete table headers, or missing closed captions.\\n7. Localization Testing: If you are creating content for multiple regions or languages, Langsmith can help test the accuracy and cultural sensitivity of your content.\\n8. User Interface Testing: Langsmith can evaluate the usability of your content by analyzing the layout, readability, and overall user experience of your documents, articles, or websites.\\n9. Plagiarism Detection: Langsmith's advanced plagiarism detection capabilities can identify any instances of copied content, ensuring that your work is original and credit is given where it is due.\\n10. Collaboration Tools: Langsmith offers collaboration tools that allow multiple writers to work on a document simultaneously, streamlining the testing process and reducing the risk of errors.\\n\\nIn summary, Langsmith is an incredible tool for testing technical content, providing advanced grammar and spelling checks, contextual error detection, consistency checking, content reuse detection, readability analysis, accessibility audit, localization testing, user interface testing, and plagiarism detection. By leveraging these features, you can ensure that your content is accurate, consistent, and easy to understand for your target audience.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc1747c2-7299-4d2f-a2f0-76375691eab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output parsing\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "355c295e-90d5-46d1-a8d5-0448537f4c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ab318-5947-4609-8de9-e1ea510e5a21",
   "metadata": {},
   "source": [
    "### Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4e8e134-b55c-45f0-8d9c-287aa1dc5d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "995ff4b1-1969-4200-85c5-887d3c7fae9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using vector DB\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c64e1631-4db1-4593-a712-eccec6904d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Semantic search using FAISS\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16ece1-8b58-49bc-9a68-0fc8669809bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that we have this data indexed in a vectorstore, we will create a retrieval chain. This chain will take an incoming question, look up relevant documents, then pass those documents along with the original question into an LLM and ask it to answer the original question.\n",
    "\n",
    "First, let's set up the chain that takes a question and the retrieved documents and generates an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68f00ae2-e8ea-4c56-b91f-df0960d2ca7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b97da4-237c-4ce8-8bf9-269c363752e8",
   "metadata": {},
   "source": [
    "If we wanted to, we could run this ourselves by passing in documents directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ddbd894-6ff5-4d5a-b3f0-5e49bc2da6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on the provided context, Langsmith can help with testing by allowing users to visualize their test results.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a2dcd-129b-44b6-ac46-fa502105cfc4",
   "metadata": {},
   "source": [
    "However, we want the documents to first come from the retriever we just set up. That way, for a given question we can use the retriever to dynamically select the most relevant documents and pass those in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "612e7840-5a60-4537-8366-2b3c5e728bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f46408b-5a24-4845-9a41-c5066dfa261f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, LangSmith can help with testing by providing a platform for building and debugging production-grade LLM applications. Specifically, it offers the following testing capabilities:\n",
      "\n",
      "1. Evaluation: LangSmith provides an evaluation capability that allows you to test your LLM applications in a controlled environment before deploying them in production.\n",
      "2. Monitoring: LangSmith offers monitoring capabilities that enable you to track the performance and behavior of your LLM applications in real-time, allowing you to identify and fix issues quickly.\n",
      "3. Tracing: LangSmith provides tracing capabilities that allow you to debug and test your LLM applications by visualizing their execution path and identifying potential errors or bottlenecks.\n",
      "4. Prompt Hub: LangSmith offers a prompt management tool called the Prompt Hub, which allows you to manage and organize your prompts for your LLM applications, making it easier to test and evaluate them.\n",
      "\n",
      "Overall, LangSmith provides a comprehensive platform for building, testing, evaluating, and monitoring LLM applications, making it an ideal solution for developers and researchers working with language models.\n"
     ]
    }
   ],
   "source": [
    "# We can now invoke this chain. This returns a dictionary - the response from the LLM is in the answer key\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af0818c-341a-4f65-9005-439ab2e7fe6c",
   "metadata": {},
   "source": [
    "### Conversation Retrieval Chain\n",
    "\n",
    "The chain we've created so far can only answer single questions. One of the main types of LLM applications that people are building are chat bots. So how do we turn this chain into one that can answer follow up questions?\n",
    "\n",
    "We can still use the create_retrieval_chain function, but we need to change two things:\n",
    "\n",
    "The retrieval method should now not just work on the most recent input, but rather should take the whole history into account.\n",
    "The final LLM chain should likewise take the whole history into account\n",
    "\n",
    "\n",
    "Updating Retrieval\n",
    "\n",
    "In order to update retrieval, we will create a new chain. This chain will take in the most recent input (input) and the conversation history (chat_history) and use an LLM to generate a search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5985d60e-371c-4445-a795-ae6d60098c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3aa762-631c-46a3-8981-9fdfd9b9d05a",
   "metadata": {},
   "source": [
    "We can test this out by passing in an instance where the user is asking a follow up question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75817360-b1c6-438e-9157-5eb3a347e7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith\\n\\n\\n\\n\\n\\nSkip to main contentğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Startâ€‹Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Stepsâ€‹Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Introduction', 'language': 'en'})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d349a3-dec4-46da-aaae-4b891f6831ac",
   "metadata": {},
   "source": [
    "You should see that this returns documents about testing in LangSmith. This is because the LLM generated a new query, combining the chat history with the follow up question.\n",
    "\n",
    "Now that we have this new retriever, we can create a new chain to continue the conversation with these retrieved documents in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27bf9874-d4c1-43ab-b897-2c1b2047418a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4626bc4d-17b5-4770-a0d8-00105af6474d",
   "metadata": {},
   "source": [
    "We can now test this out end-to-end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "15d5c551-d831-4f88-aeb2-6288ab5a20a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content=\"LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith\\n\\n\\n\\n\\n\\nSkip to main contentğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricing (Coming Soon)Self-HostingTracingEvaluationMonitoringPrompt HubLangSmithOn this pageLangSmithIntroductionâ€‹LangSmith is a platform for building production-grade LLM applications.It lets you debug, test, evaluate, and monitor chains and intelligent agents built on any LLM framework and seamlessly integrates with LangChain, the go-to open source framework for building with LLMs.LangSmith is developed by LangChain, the company behind the open source LangChain framework.Quick Startâ€‹Tracing: Get started with the tracing quick start.Evaluation: Get started with the evaluation quick start.Next Stepsâ€‹Check out the following sections to learn more about LangSmith:User Guide: Learn about the workflows LangSmith supports at each stage of the LLM application lifecycle.Setup: Learn how to create an account, obtain an API key, and configure your environment.Pricing: Learn about the pricing model for LangSmith.Self-Hosting: Learn about self-hosting options for LangSmith.Tracing: Learn about the tracing capabilities of LangSmith.Evaluation: Learn about the evaluation capabilities of LangSmith.Prompt Hub Learn about the Prompt Hub, a prompt management tool built into LangSmith.Additional Resourcesâ€‹LangSmith Cookbook: A collection of tutorials and end-to-end walkthroughs using LangSmith.LangChain Python: Docs for the Python LangChain library.LangChain Python API Reference: documentation to review the core APIs of LangChain.LangChain JS: Docs for the TypeScript LangChain libraryDiscord: Join us on our Discord to discuss all things LangChain!Contact SalesIf you're interested in enterprise security and admin features, special deployment options, or access for large teams, reach out to speak with sales.NextUser GuideIntroductionQuick StartNext StepsAdditional ResourcesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright Â© 2024 LangChain, Inc.\", metadata={'source': 'https://docs.smith.langchain.com', 'title': 'LangSmith | ğŸ¦œï¸�ğŸ›\\xa0ï¸� LangSmith', 'description': 'Introduction', 'language': 'en'})],\n",
       " 'answer': \"Of course, I'd be happy to help you with that! LangSmith provides a comprehensive testing capability for your LLM applications. Here are some ways LangSmith can help you test your LLM apps:\\n\\n1. **Unit Testing**: LangSmith offers a built-in unit testing framework that allows you to write and run tests for your LLM code. You can test individual components or modules of your application in isolation, ensuring they function correctly before integrating them into the larger system.\\n2. **Integration Testing**: As your LLM application grows, LangSmith provides tools to help you integrate and test your components. You can verify that different parts of your application work together correctly and handle edge cases.\\n3. **End-to-End Testing**: With LangSmith's support for end-to-end testing, you can simulate real-world scenarios and test how your LLM application performs under various conditions. This helps identify potential issues before deploying the application in a production environment.\\n4. **Tracing**: LangSmith provides advanced tracing capabilities that allow you to track the behavior of your LLM applications. You can monitor performance, identify bottlenecks, and optimize your code for better efficiency.\\n5. **Evaluation**: LangSmith offers evaluation tools to help you measure the performance and accuracy of your LLM models. You can compare the results of different models or versions of your model, enabling you to make informed decisions about model improvements.\\n\\nTo get started with testing your LLM application using LangSmith, follow these next steps:\\n\\n1. Create a new project in LangSmith and import your LLM code.\\n2. Write and run unit tests for individual components of your application.\\n3. Integrate your components and run integration tests to ensure they work together correctly.\\n4. Use end-to-end testing to simulate real-world scenarios and test the performance of your application under various conditions.\\n5. Utilize tracing capabilities to monitor performance and identify potential issues.\\n6. Evaluate the performance and accuracy of your LLM models using LangSmith's evaluation tools.\\n\\nI hope this helps you get started with testing your LLM applications using LangSmith! If you have any further questions or need more guidance, feel free to ask.\"}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb7b7e2-707a-4a11-ba76-7638c0c30345",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8af6f-2d9e-49b4-adb1-7a5336ba6422",
   "metadata": {},
   "source": [
    "We've so far create examples of chains - where each step is known ahead of time. The final thing we will create is an agent - where the LLM decides what steps to take.\n",
    "\n",
    "NOTE: for this example we will only show how to create an agent using OpenAI models, as local models are not reliable enough yet.\n",
    "\n",
    "One of the first things to do when building an agent is to decide what tools it should have access to. For this example, we will give the agent access to two tools:\n",
    "\n",
    "1. The retriever we just created. This will let it easily answer questions about LangSmith\n",
    "2. A search tool. This will let it easily answer questions that require up to date information.\n",
    "\n",
    "First, let's set up a tool for the retriever we just created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a6bebd1-92b2-4ddf-9ad0-962b06cb5087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69029a76-27c0-4f3a-b386-0fa44b5af5ad",
   "metadata": {},
   "source": [
    "The search tool that we will use is Tavily. This will require an API key (they have generous free tier). After creating it on their platform, you need to set it as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea1c9eba-1888-4637-9c00-a1c0069ed0b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "os.environ['TAVILY_API_KEY'] = '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'\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ee2cee4-440b-4d3e-a1b7-90dd7cf2cf28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed65fe-3410-470d-accc-ed3835bb668c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now that we have the tools, we can create an agent to use them. We will go over this pretty quickly - for a deeper dive into what exactly is going on, check out the Agent's Getting Started documentation\n",
    "\n",
    "Now we can use it to get a predefined prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76f57c4f-c7e7-45ac-928b-e0ff363fdc89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain import hub\n",
    "# from langchain.agents import create_openai_functions_agent, cr\n",
    "# from langchain.agents import AgentExecutor\n",
    "\n",
    "# # Get the prompt to use - you can modify this!\n",
    "# # prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# prompt = hub.pull(\"homanp/superagent\")\n",
    "# # llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "# agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0dc815-a12f-4561-9328-dee2ae6e53a8",
   "metadata": {},
   "source": [
    "We can now invoke the agent and see how it responds! We can ask it questions about LangSmith:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34cacc1b-edc8-4862-aeaa-368cb815583c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e4610-ee2d-4968-a607-d3a17b733ce9",
   "metadata": {},
   "source": [
    "### LangServe\n",
    "\n",
    "#### Server\n",
    "To create a server for our application we'll make a serve.py file. This will contain our logic for serving our application. It consists of three things:\n",
    "\n",
    "The definition of our chain that we just built above\n",
    "Our FastAPI app\n",
    "A definition of a route from which to serve the chain, which is done with langserve.add_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc2f6b-7e8a-4183-9069-082d6d22314b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
