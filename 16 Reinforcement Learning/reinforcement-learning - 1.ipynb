{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-25T11:36:52.556470Z","iopub.execute_input":"2023-11-25T11:36:52.557149Z","iopub.status.idle":"2023-11-25T11:36:52.896792Z","shell.execute_reply.started":"2023-11-25T11:36:52.557122Z","shell.execute_reply":"2023-11-25T11:36:52.895921Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%html\n<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:36:56.097015Z","iopub.execute_input":"2023-11-25T11:36:56.097572Z","iopub.status.idle":"2023-11-25T11:36:56.106800Z","shell.execute_reply.started":"2023-11-25T11:36:56.097531Z","shell.execute_reply":"2023-11-25T11:36:56.105434Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<video controls autoplay><source src=\"https://huggingface.co/sb3/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>\n"},"metadata":{}}]},{"cell_type":"code","source":"!apt install swig cmake","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:37:01.339926Z","iopub.execute_input":"2023-11-25T11:37:01.340509Z","iopub.status.idle":"2023-11-25T11:37:06.625809Z","shell.execute_reply.started":"2023-11-25T11:37:01.340480Z","shell.execute_reply":"2023-11-25T11:37:06.624717Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ncmake is already the newest version (3.22.1-1ubuntu1.22.04.1).\nSuggested packages:\n  swig-doc swig-examples swig4.0-examples swig4.0-doc\nThe following NEW packages will be installed:\n  swig swig4.0\n0 upgraded, 2 newly installed, 0 to remove and 46 not upgraded.\nNeed to get 1116 kB of archives.\nAfter this operation, 5542 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1110 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5632 B]\nFetched 1116 kB in 0s (3593 kB/s)0m\u001b[33m\n\n\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package swig4.0.\n(Reading database ... 114840 files and directories currently installed.)\nPreparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package swig.\nPreparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking swig (4.0.2-1ubuntu1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Setting up swig4.0 (4.0.2-1ubuntu1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up swig (4.0.2-1ubuntu1) ...\n\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Processing triggers for man-db (2.10.2-1) ...\n\n\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J","output_type":"stream"}]},{"cell_type":"code","source":"!pip install moviepy","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:43:42.488754Z","iopub.execute_input":"2023-11-25T12:43:42.489977Z","iopub.status.idle":"2023-11-25T12:44:05.527423Z","shell.execute_reply.started":"2023-11-25T12:43:42.489916Z","shell.execute_reply":"2023-11-25T12:44:05.526332Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Collecting moviepy\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.66.1)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.0)\nCollecting proglog<=1.0.0 (from moviepy)\n  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.24.3)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.31.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Obtaining dependency information for imageio_ffmpeg>=0.2.0 from https://files.pythonhosted.org/packages/1a/98/3df1d8dd8f2c121b6c588b1e0d604f36592d56df9c41fb155ed546c6a5ed/imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata\n  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.1.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (68.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\nDownloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110721 sha256=c52056203c9106f4f41affe400f9c33664b8f48b1ec23cfa0cae49a1af78c6e9\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.9 moviepy-1.0.3 proglog-0.1.10\n","output_type":"stream"}]},{"cell_type":"code","source":"#Install dependencies\n!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:37:22.380049Z","iopub.execute_input":"2023-11-25T11:37:22.380410Z","iopub.status.idle":"2023-11-25T11:38:22.930877Z","shell.execute_reply.started":"2023-11-25T11:37:22.380383Z","shell.execute_reply":"2023-11-25T11:38:22.929752Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting stable-baselines3==2.0.0a5 (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1))\n  Downloading stable_baselines3-2.0.0a5-py3-none-any.whl (177 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting swig (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 2))\n  Obtaining dependency information for swig from https://files.pythonhosted.org/packages/50/ce/d683fd61491983749484105a752291fe094d6247e336de1b76eab5600e14/swig-4.1.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata\n  Downloading swig-4.1.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: gymnasium[box2d] in /opt/conda/lib/python3.10/site-packages (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3)) (0.26.3)\nCollecting huggingface_sb3 (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4))\n  Obtaining dependency information for huggingface_sb3 from https://files.pythonhosted.org/packages/b5/2c/e8c25087c6e43e5e68659f2a4651988831d4b3e70791c433537c90d147ce/huggingface_sb3-3.0-py3-none-any.whl.metadata\n  Downloading huggingface_sb3-3.0-py3-none-any.whl.metadata (6.3 kB)\nCollecting gymnasium==0.28.1 (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1))\n  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.24.3)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.2.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.0.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.7.3)\nCollecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1))\n  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.5.0)\nCollecting farama-notifications>=0.0.1 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1))\n  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\nINFO: pip is looking at multiple versions of gymnasium[box2d] to determine which version is compatible with other requirements. This could take a while.\nCollecting gymnasium[box2d] (from -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 3))\n  Obtaining dependency information for gymnasium[box2d] from https://files.pythonhosted.org/packages/a8/4d/3cbfd81ed84db450dbe73a89afcd8bc405273918415649ac6683356afe92/gymnasium-0.29.1-py3-none-any.whl.metadata\n  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n  Obtaining dependency information for gymnasium[box2d] from https://files.pythonhosted.org/packages/3f/00/a728a4a8608213482fc38d76d842657d29b546f214e83801a044de074612/gymnasium-0.29.0-py3-none-any.whl.metadata\n  Downloading gymnasium-0.29.0-py3-none-any.whl.metadata (10 kB)\nCollecting box2d-py==2.3.5 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1))\n  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pygame==2.1.3 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1))\n  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: huggingface-hub~=0.8 in /opt/conda/lib/python3.10/site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (0.17.3)\nRequirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (6.0.1)\nRequirement already satisfied: wasabi in /opt/conda/lib/python3.10/site-packages (from huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (1.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2023.10.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (4.66.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 4)) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11->stable-baselines3==2.0.0a5->-r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt (line 1)) (1.3.0)\nDownloading swig-4.1.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\nBuilding wheels for collected packages: box2d-py\n  Building wheel for box2d-py (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=494924 sha256=dc4ea14704f1d85cd2ee172b63a5bd9623da5d2594feb35a8b4094c19e72cb97\n  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\nSuccessfully built box2d-py\nInstalling collected packages: swig, farama-notifications, box2d-py, pygame, jax-jumpy, gymnasium, stable-baselines3, huggingface_sb3\n  Attempting uninstall: gymnasium\n    Found existing installation: Gymnasium 0.26.3\n    Uninstalling Gymnasium-0.26.3:\n      Successfully uninstalled Gymnasium-0.26.3\nSuccessfully installed box2d-py-2.3.5 farama-notifications-0.0.4 gymnasium-0.28.1 huggingface_sb3-3.0 jax-jumpy-1.0.0 pygame-2.1.3 stable-baselines3-2.0.0a5 swig-4.1.1.post0\n","output_type":"stream"}]},{"cell_type":"code","source":"#During the notebook, we‚Äôll need to generate a replay video. To do so, with colab, we need to have a virtual screen to be able to render the environment (and thus record the frames).\n!sudo apt-get update\n!apt install python-opengl\n!apt install ffmpeg\n!apt install xvfb\n!pip3 install pyvirtualdisplay","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:38:36.365114Z","iopub.execute_input":"2023-11-25T11:38:36.365489Z","iopub.status.idle":"2023-11-25T11:38:59.505775Z","shell.execute_reply.started":"2023-11-25T11:38:36.365461Z","shell.execute_reply":"2023-11-25T11:38:59.504641Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Get:1 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]\nGet:2 https://packages.cloud.google.com/apt google-fast-socket InRelease [5015 B]\nHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nHit:4 http://packages.cloud.google.com/apt gcsfuse-focal InRelease             \nGet:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]        \nGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\nGet:7 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [553 kB]\nGet:8 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]      \nGet:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]      \nGet:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [631 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1520 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1284 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1498 kB]\nGet:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1016 kB]\nGet:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1242 kB]\nGet:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1456 kB]\nGet:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\nFetched 9646 kB in 2s (5876 kB/s)                            \nReading package lists... Done\nW: https://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nW: http://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\n\u001b[1;31mE: \u001b[0mUnable to locate package python-opengl\u001b[0m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 61 not upgraded.\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nxvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.2).\n0 upgraded, 0 newly installed, 0 to remove and 61 not upgraded.\nCollecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay\nSuccessfully installed pyvirtualdisplay-3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nos.kill(os.getpid(), 9)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:39:11.244906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Virtual display\nfrom pyvirtualdisplay import Display\n\nvirtual_display = Display(visible=0, size=(1400, 900))\nvirtual_display.start()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:39:17.914615Z","iopub.execute_input":"2023-11-25T11:39:17.915648Z","iopub.status.idle":"2023-11-25T11:39:18.427673Z","shell.execute_reply.started":"2023-11-25T11:39:17.915609Z","shell.execute_reply":"2023-11-25T11:39:18.426689Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<pyvirtualdisplay.display.Display at 0x7c8ae9927d00>"},"metadata":{}}]},{"cell_type":"code","source":"import gymnasium as gym\nfrom huggingface_sb3 import load_from_hub, package_to_hub\nfrom huggingface_hub import (\n    notebook_login,\n)\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.monitor import Monitor","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:40:39.107014Z","iopub.execute_input":"2023-11-25T12:40:39.107845Z","iopub.status.idle":"2023-11-25T12:40:39.113510Z","shell.execute_reply.started":"2023-11-25T12:40:39.107809Z","shell.execute_reply":"2023-11-25T12:40:39.112586Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# First, we create our environment called LunarLander-v2\nenv = gym.make('LunarLander-v2')","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:45:54.758830Z","iopub.execute_input":"2023-11-25T11:45:54.759842Z","iopub.status.idle":"2023-11-25T11:45:54.821982Z","shell.execute_reply.started":"2023-11-25T11:45:54.759804Z","shell.execute_reply":"2023-11-25T11:45:54.821008Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Reset to initial state\nobservation, info = env.reset()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:46:19.659400Z","iopub.execute_input":"2023-11-25T11:46:19.660268Z","iopub.status.idle":"2023-11-25T11:46:19.666117Z","shell.execute_reply.started":"2023-11-25T11:46:19.660233Z","shell.execute_reply":"2023-11-25T11:46:19.665089Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for _ in range(20):\n    #Take random action\n    action = env.action_space.sample()\n    print('Action taken:', action)\n    \n    # Do this action in the environment and get\n    # next_state, reward, terminated, truncated and info\n    observation, reward, terminated, truncated, info = env.step(action)\n    \n    # If the game is terminated (in our case we land, crashed) or truncated (timeout)\n    if terminated or truncated:\n        print('Environment is reset')\n        observation, info = env.reset()\nenv.close()","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:51:16.649303Z","iopub.execute_input":"2023-11-25T11:51:16.649645Z","iopub.status.idle":"2023-11-25T11:51:16.661146Z","shell.execute_reply.started":"2023-11-25T11:51:16.649619Z","shell.execute_reply":"2023-11-25T11:51:16.660010Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Action taken: 3\nAction taken: 2\nAction taken: 3\nAction taken: 2\nAction taken: 3\nAction taken: 0\nAction taken: 2\nAction taken: 2\nAction taken: 2\nAction taken: 1\nAction taken: 1\nAction taken: 2\nAction taken: 1\nAction taken: 1\nAction taken: 2\nAction taken: 0\nAction taken: 2\nAction taken: 2\nAction taken: 3\nAction taken: 2\n","output_type":"stream"}]},{"cell_type":"code","source":"# We create our environment with gym.make(\"<name_of_the_environment>\")\nenv = gym.make(\"LunarLander-v2\")\nenv.reset()\nprint(\"_____OBSERVATION SPACE_____ \\n\")\nprint(\"Observation Space Shape\", env.observation_space.shape)\nprint(\"Sample observation\", env.observation_space.sample())","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:51:52.710122Z","iopub.execute_input":"2023-11-25T11:51:52.710921Z","iopub.status.idle":"2023-11-25T11:51:52.720365Z","shell.execute_reply.started":"2023-11-25T11:51:52.710886Z","shell.execute_reply":"2023-11-25T11:51:52.719360Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"_____OBSERVATION SPACE_____ \n\nObservation Space Shape (8,)\nSample observation [-35.911915    16.929241    -0.48472762  -3.5126724    2.9744513\n   1.4508443    0.3582742    0.17189333]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We see with Observation Space Shape (8,) that the observation is a vector of size 8, where each value contains different information about the lander:\n\n* Horizontal pad coordinate (x)\n* Vertical pad coordinate (y)\n* Horizontal speed (x)\n* Vertical speed (y)\n* Angle\n* Angular speed\n* If the left leg contact point has touched the land (boolean)\n* If the right leg contact point has touched the land (boolean)","metadata":{}},{"cell_type":"code","source":"print(\"\\n _____ACTION SPACE_____ \\n\")\nprint(\"Action Space Shape\", env.action_space.n)\nprint(\"Action Space Sample\", env.action_space.sample())  # Take a random action","metadata":{"execution":{"iopub.status.busy":"2023-11-25T11:53:43.355315Z","iopub.execute_input":"2023-11-25T11:53:43.356292Z","iopub.status.idle":"2023-11-25T11:53:43.362245Z","shell.execute_reply.started":"2023-11-25T11:53:43.356251Z","shell.execute_reply":"2023-11-25T11:53:43.361351Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\n _____ACTION SPACE_____ \n\nAction Space Shape 4\nAction Space Sample 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The action space (the set of possible actions the agent can take) is discrete with 4 actions available üéÆ:\n\n* Action 0: Do nothing,\n* Action 1: Fire left orientation engine,\n* Action 2: Fire the main engine,\n* Action 3: Fire right orientation engine.\n\n\nAfter every step a reward is granted. The total reward of an episode is the sum of the rewards for all the steps within that episode.\n\nFor each step, the reward:\n\n* Is increased/decreased the closer/further the lander is to the landing pad.\n* Is increased/decreased the slower/faster the lander is moving.\n* Is decreased the more the lander is tilted (angle not horizontal).\n* Is increased by 10 points for each leg that is in contact with the ground.\n* Is decreased by 0.03 points each frame a side engine is firing.\n* Is decreased by 0.3 points each frame the main engine is firing.\n\nThe episode receive an additional reward of -100 or +100 points for crashing or landing safely respectively.\n\nAn episode is considered a solution if it scores at least 200 points.\n\n# Vectorized Environment\nWe create a vectorized environment (a method for stacking multiple independent environments into a single environment) of 16 environments, this way, we‚Äôll have more diverse experiences during the training.","metadata":{}},{"cell_type":"code","source":"# Create the environment\nenv = make_vec_env(\"LunarLander-v2\", n_envs=16)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:00:08.281125Z","iopub.execute_input":"2023-11-25T12:00:08.282100Z","iopub.status.idle":"2023-11-25T12:00:08.300376Z","shell.execute_reply.started":"2023-11-25T12:00:08.282064Z","shell.execute_reply":"2023-11-25T12:00:08.299184Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Instantiate the agent\n# model = PPO('MlpPolicy', env, verbose=1)\nmodel = PPO(\n    policy=\"MlpPolicy\",\n    env=env,\n    n_steps=1024,\n    batch_size=64,\n    n_epochs=4,\n    gamma=0.999,\n    gae_lambda=0.98,\n    ent_coef=0.01,\n    verbose=1,\n)\n\n# Train the agent\nmodel.learn(total_timesteps=1000000)\n\n# Save the model\nmodel_name = \"ppo-LunarLander-v2\"\nmodel.save(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:06:51.078345Z","iopub.execute_input":"2023-11-25T12:06:51.079337Z","iopub.status.idle":"2023-11-25T12:27:55.867461Z","shell.execute_reply.started":"2023-11-25T12:06:51.079302Z","shell.execute_reply":"2023-11-25T12:27:55.866569Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Using cuda device\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 89.7     |\n|    ep_rew_mean     | -175     |\n| time/              |          |\n|    fps             | 2397     |\n|    iterations      | 1        |\n|    time_elapsed    | 6        |\n|    total_timesteps | 16384    |\n---------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 95.1         |\n|    ep_rew_mean          | -165         |\n| time/                   |              |\n|    fps                  | 2052         |\n|    iterations           | 2            |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0057260757 |\n|    clip_fraction        | 0.0165       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.38        |\n|    explained_variance   | -0.00249     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.02e+03     |\n|    n_updates            | 4            |\n|    policy_gradient_loss | -0.00436     |\n|    value_loss           | 4.29e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 94.4        |\n|    ep_rew_mean          | -133        |\n| time/                   |             |\n|    fps                  | 1968        |\n|    iterations           | 3           |\n|    time_elapsed         | 24          |\n|    total_timesteps      | 49152       |\n| train/                  |             |\n|    approx_kl            | 0.008502977 |\n|    clip_fraction        | 0.039       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.37       |\n|    explained_variance   | -0.00426    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 799         |\n|    n_updates            | 8           |\n|    policy_gradient_loss | -0.00603    |\n|    value_loss           | 3e+03       |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 96.5        |\n|    ep_rew_mean          | -136        |\n| time/                   |             |\n|    fps                  | 1915        |\n|    iterations           | 4           |\n|    time_elapsed         | 34          |\n|    total_timesteps      | 65536       |\n| train/                  |             |\n|    approx_kl            | 0.008253813 |\n|    clip_fraction        | 0.055       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.37       |\n|    explained_variance   | -0.000284   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 422         |\n|    n_updates            | 12          |\n|    policy_gradient_loss | -0.00467    |\n|    value_loss           | 1.28e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 98           |\n|    ep_rew_mean          | -109         |\n| time/                   |              |\n|    fps                  | 1878         |\n|    iterations           | 5            |\n|    time_elapsed         | 43           |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0060796468 |\n|    clip_fraction        | 0.0559       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.35        |\n|    explained_variance   | -0.000767    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 544          |\n|    n_updates            | 16           |\n|    policy_gradient_loss | -0.00353     |\n|    value_loss           | 960          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 95.3        |\n|    ep_rew_mean          | -93.2       |\n| time/                   |             |\n|    fps                  | 1850        |\n|    iterations           | 6           |\n|    time_elapsed         | 53          |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.005965106 |\n|    clip_fraction        | 0.0459      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.36       |\n|    explained_variance   | -8.55e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 227         |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00175    |\n|    value_loss           | 766         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 98.8        |\n|    ep_rew_mean          | -76         |\n| time/                   |             |\n|    fps                  | 1829        |\n|    iterations           | 7           |\n|    time_elapsed         | 62          |\n|    total_timesteps      | 114688      |\n| train/                  |             |\n|    approx_kl            | 0.009762142 |\n|    clip_fraction        | 0.117       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | 1.19e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 103         |\n|    n_updates            | 24          |\n|    policy_gradient_loss | -0.00706    |\n|    value_loss           | 427         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 101         |\n|    ep_rew_mean          | -63.7       |\n| time/                   |             |\n|    fps                  | 1813        |\n|    iterations           | 8           |\n|    time_elapsed         | 72          |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.009571984 |\n|    clip_fraction        | 0.0901      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -1.03e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 209         |\n|    n_updates            | 28          |\n|    policy_gradient_loss | -0.00511    |\n|    value_loss           | 390         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 110         |\n|    ep_rew_mean          | -54.8       |\n| time/                   |             |\n|    fps                  | 1771        |\n|    iterations           | 9           |\n|    time_elapsed         | 83          |\n|    total_timesteps      | 147456      |\n| train/                  |             |\n|    approx_kl            | 0.009274584 |\n|    clip_fraction        | 0.0611      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | -2.5e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 159         |\n|    n_updates            | 32          |\n|    policy_gradient_loss | -0.00608    |\n|    value_loss           | 379         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 121          |\n|    ep_rew_mean          | -33.3        |\n| time/                   |              |\n|    fps                  | 1747         |\n|    iterations           | 10           |\n|    time_elapsed         | 93           |\n|    total_timesteps      | 163840       |\n| train/                  |              |\n|    approx_kl            | 0.0094535975 |\n|    clip_fraction        | 0.0647       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | -3.93e-06    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 179          |\n|    n_updates            | 36           |\n|    policy_gradient_loss | -0.00468     |\n|    value_loss           | 354          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 121         |\n|    ep_rew_mean          | -28.2       |\n| time/                   |             |\n|    fps                  | 1714        |\n|    iterations           | 11          |\n|    time_elapsed         | 105         |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.009861911 |\n|    clip_fraction        | 0.0299      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -9.18e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 313         |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.00163    |\n|    value_loss           | 470         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 153          |\n|    ep_rew_mean          | -12.9        |\n| time/                   |              |\n|    fps                  | 1667         |\n|    iterations           | 12           |\n|    time_elapsed         | 117          |\n|    total_timesteps      | 196608       |\n| train/                  |              |\n|    approx_kl            | 0.0061453143 |\n|    clip_fraction        | 0.0392       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.19        |\n|    explained_variance   | -1.19e-07    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 192          |\n|    n_updates            | 44           |\n|    policy_gradient_loss | -0.00188     |\n|    value_loss           | 469          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 183         |\n|    ep_rew_mean          | -16.8       |\n| time/                   |             |\n|    fps                  | 1588        |\n|    iterations           | 13          |\n|    time_elapsed         | 134         |\n|    total_timesteps      | 212992      |\n| train/                  |             |\n|    approx_kl            | 0.009521425 |\n|    clip_fraction        | 0.0616      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | -3.58e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 291         |\n|    n_updates            | 48          |\n|    policy_gradient_loss | -0.00275    |\n|    value_loss           | 590         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 225          |\n|    ep_rew_mean          | -14.9        |\n| time/                   |              |\n|    fps                  | 1475         |\n|    iterations           | 14           |\n|    time_elapsed         | 155          |\n|    total_timesteps      | 229376       |\n| train/                  |              |\n|    approx_kl            | 0.0051821396 |\n|    clip_fraction        | 0.0286       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.13        |\n|    explained_variance   | 6.5e-06      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 316          |\n|    n_updates            | 52           |\n|    policy_gradient_loss | -0.00162     |\n|    value_loss           | 679          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 260          |\n|    ep_rew_mean          | -5.91        |\n| time/                   |              |\n|    fps                  | 1379         |\n|    iterations           | 15           |\n|    time_elapsed         | 178          |\n|    total_timesteps      | 245760       |\n| train/                  |              |\n|    approx_kl            | 0.0049358625 |\n|    clip_fraction        | 0.0298       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.17        |\n|    explained_variance   | -0.000653    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 340          |\n|    n_updates            | 56           |\n|    policy_gradient_loss | -0.0011      |\n|    value_loss           | 743          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 334         |\n|    ep_rew_mean          | -7.54       |\n| time/                   |             |\n|    fps                  | 1295        |\n|    iterations           | 16          |\n|    time_elapsed         | 202         |\n|    total_timesteps      | 262144      |\n| train/                  |             |\n|    approx_kl            | 0.004122353 |\n|    clip_fraction        | 0.0168      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.14       |\n|    explained_variance   | 0.00284     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 411         |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.000607   |\n|    value_loss           | 633         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 391         |\n|    ep_rew_mean          | -3.36       |\n| time/                   |             |\n|    fps                  | 1218        |\n|    iterations           | 17          |\n|    time_elapsed         | 228         |\n|    total_timesteps      | 278528      |\n| train/                  |             |\n|    approx_kl            | 0.004118602 |\n|    clip_fraction        | 0.00787     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.16       |\n|    explained_variance   | -0.00458    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 291         |\n|    n_updates            | 64          |\n|    policy_gradient_loss | -0.00153    |\n|    value_loss           | 651         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 392         |\n|    ep_rew_mean          | 5.82        |\n| time/                   |             |\n|    fps                  | 1176        |\n|    iterations           | 18          |\n|    time_elapsed         | 250         |\n|    total_timesteps      | 294912      |\n| train/                  |             |\n|    approx_kl            | 0.004756484 |\n|    clip_fraction        | 0.0394      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.17       |\n|    explained_variance   | 0.404       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 138         |\n|    n_updates            | 68          |\n|    policy_gradient_loss | -0.000945   |\n|    value_loss           | 314         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 318         |\n|    ep_rew_mean          | 10.9        |\n| time/                   |             |\n|    fps                  | 1136        |\n|    iterations           | 19          |\n|    time_elapsed         | 273         |\n|    total_timesteps      | 311296      |\n| train/                  |             |\n|    approx_kl            | 0.006108579 |\n|    clip_fraction        | 0.0509      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.17       |\n|    explained_variance   | 0.6         |\n|    learning_rate        | 0.0003      |\n|    loss                 | 157         |\n|    n_updates            | 72          |\n|    policy_gradient_loss | -0.00226    |\n|    value_loss           | 411         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 381         |\n|    ep_rew_mean          | 19.3        |\n| time/                   |             |\n|    fps                  | 1102        |\n|    iterations           | 20          |\n|    time_elapsed         | 297         |\n|    total_timesteps      | 327680      |\n| train/                  |             |\n|    approx_kl            | 0.008239804 |\n|    clip_fraction        | 0.0631      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.18       |\n|    explained_variance   | 0.746       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 69.4        |\n|    n_updates            | 76          |\n|    policy_gradient_loss | -0.00292    |\n|    value_loss           | 249         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 455          |\n|    ep_rew_mean          | 22.1         |\n| time/                   |              |\n|    fps                  | 1066         |\n|    iterations           | 21           |\n|    time_elapsed         | 322          |\n|    total_timesteps      | 344064       |\n| train/                  |              |\n|    approx_kl            | 0.0046648458 |\n|    clip_fraction        | 0.0323       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.21        |\n|    explained_variance   | 0.803        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 75.3         |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.00235     |\n|    value_loss           | 194          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 574         |\n|    ep_rew_mean          | 29.3        |\n| time/                   |             |\n|    fps                  | 1034        |\n|    iterations           | 22          |\n|    time_elapsed         | 348         |\n|    total_timesteps      | 360448      |\n| train/                  |             |\n|    approx_kl            | 0.005469485 |\n|    clip_fraction        | 0.0368      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.854       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 58.9        |\n|    n_updates            | 84          |\n|    policy_gradient_loss | -0.00117    |\n|    value_loss           | 128         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 643          |\n|    ep_rew_mean          | 34.3         |\n| time/                   |              |\n|    fps                  | 1007         |\n|    iterations           | 23           |\n|    time_elapsed         | 374          |\n|    total_timesteps      | 376832       |\n| train/                  |              |\n|    approx_kl            | 0.0073333345 |\n|    clip_fraction        | 0.054        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.852        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 96.7         |\n|    n_updates            | 88           |\n|    policy_gradient_loss | -0.00182     |\n|    value_loss           | 177          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 702         |\n|    ep_rew_mean          | 41.2        |\n| time/                   |             |\n|    fps                  | 979         |\n|    iterations           | 24          |\n|    time_elapsed         | 401         |\n|    total_timesteps      | 393216      |\n| train/                  |             |\n|    approx_kl            | 0.007134082 |\n|    clip_fraction        | 0.0522      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | 0.863       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 39.5        |\n|    n_updates            | 92          |\n|    policy_gradient_loss | -0.00235    |\n|    value_loss           | 147         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 693         |\n|    ep_rew_mean          | 39          |\n| time/                   |             |\n|    fps                  | 960         |\n|    iterations           | 25          |\n|    time_elapsed         | 426         |\n|    total_timesteps      | 409600      |\n| train/                  |             |\n|    approx_kl            | 0.006174732 |\n|    clip_fraction        | 0.0347      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.925       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 37.1        |\n|    n_updates            | 96          |\n|    policy_gradient_loss | -0.00161    |\n|    value_loss           | 83.5        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 708          |\n|    ep_rew_mean          | 43.3         |\n| time/                   |              |\n|    fps                  | 942          |\n|    iterations           | 26           |\n|    time_elapsed         | 452          |\n|    total_timesteps      | 425984       |\n| train/                  |              |\n|    approx_kl            | 0.0063852263 |\n|    clip_fraction        | 0.0207       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.19        |\n|    explained_variance   | 0.844        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 30.3         |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.00249     |\n|    value_loss           | 166          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 735          |\n|    ep_rew_mean          | 47.9         |\n| time/                   |              |\n|    fps                  | 926          |\n|    iterations           | 27           |\n|    time_elapsed         | 477          |\n|    total_timesteps      | 442368       |\n| train/                  |              |\n|    approx_kl            | 0.0066685705 |\n|    clip_fraction        | 0.0412       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.17        |\n|    explained_variance   | 0.904        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 34.8         |\n|    n_updates            | 104          |\n|    policy_gradient_loss | -0.00155     |\n|    value_loss           | 83.9         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 761          |\n|    ep_rew_mean          | 55.3         |\n| time/                   |              |\n|    fps                  | 909          |\n|    iterations           | 28           |\n|    time_elapsed         | 504          |\n|    total_timesteps      | 458752       |\n| train/                  |              |\n|    approx_kl            | 0.0065782648 |\n|    clip_fraction        | 0.0577       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.922        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 21.8         |\n|    n_updates            | 108          |\n|    policy_gradient_loss | -0.001       |\n|    value_loss           | 57.2         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 777         |\n|    ep_rew_mean          | 60.6        |\n| time/                   |             |\n|    fps                  | 897         |\n|    iterations           | 29          |\n|    time_elapsed         | 529         |\n|    total_timesteps      | 475136      |\n| train/                  |             |\n|    approx_kl            | 0.005500942 |\n|    clip_fraction        | 0.0421      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.17       |\n|    explained_variance   | 0.921       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 18.1        |\n|    n_updates            | 112         |\n|    policy_gradient_loss | -0.000776   |\n|    value_loss           | 66.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 834         |\n|    ep_rew_mean          | 73.5        |\n| time/                   |             |\n|    fps                  | 887         |\n|    iterations           | 30          |\n|    time_elapsed         | 553         |\n|    total_timesteps      | 491520      |\n| train/                  |             |\n|    approx_kl            | 0.009247559 |\n|    clip_fraction        | 0.0685      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | 0.954       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 19.4        |\n|    n_updates            | 116         |\n|    policy_gradient_loss | -0.00282    |\n|    value_loss           | 46.2        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 860          |\n|    ep_rew_mean          | 85.4         |\n| time/                   |              |\n|    fps                  | 878          |\n|    iterations           | 31           |\n|    time_elapsed         | 578          |\n|    total_timesteps      | 507904       |\n| train/                  |              |\n|    approx_kl            | 0.0041236235 |\n|    clip_fraction        | 0.0305       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.14        |\n|    explained_variance   | 0.941        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 22.3         |\n|    n_updates            | 120          |\n|    policy_gradient_loss | -0.00103     |\n|    value_loss           | 62.2         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 883          |\n|    ep_rew_mean          | 93.9         |\n| time/                   |              |\n|    fps                  | 871          |\n|    iterations           | 32           |\n|    time_elapsed         | 601          |\n|    total_timesteps      | 524288       |\n| train/                  |              |\n|    approx_kl            | 0.0043775756 |\n|    clip_fraction        | 0.0354       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.13        |\n|    explained_variance   | 0.953        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 9.57         |\n|    n_updates            | 124          |\n|    policy_gradient_loss | -0.00163     |\n|    value_loss           | 45.6         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 882         |\n|    ep_rew_mean          | 99.7        |\n| time/                   |             |\n|    fps                  | 865         |\n|    iterations           | 33          |\n|    time_elapsed         | 624         |\n|    total_timesteps      | 540672      |\n| train/                  |             |\n|    approx_kl            | 0.006151595 |\n|    clip_fraction        | 0.051       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | 0.97        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 11.5        |\n|    n_updates            | 128         |\n|    policy_gradient_loss | -0.00129    |\n|    value_loss           | 27          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 874         |\n|    ep_rew_mean          | 106         |\n| time/                   |             |\n|    fps                  | 859         |\n|    iterations           | 34          |\n|    time_elapsed         | 647         |\n|    total_timesteps      | 557056      |\n| train/                  |             |\n|    approx_kl            | 0.004672897 |\n|    clip_fraction        | 0.0309      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.05       |\n|    explained_variance   | 0.943       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 15.2        |\n|    n_updates            | 132         |\n|    policy_gradient_loss | -0.0012     |\n|    value_loss           | 55.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 889          |\n|    ep_rew_mean          | 111          |\n| time/                   |              |\n|    fps                  | 855          |\n|    iterations           | 35           |\n|    time_elapsed         | 670          |\n|    total_timesteps      | 573440       |\n| train/                  |              |\n|    approx_kl            | 0.0048930994 |\n|    clip_fraction        | 0.0219       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.05        |\n|    explained_variance   | 0.932        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 9.79         |\n|    n_updates            | 136          |\n|    policy_gradient_loss | -0.000177    |\n|    value_loss           | 81.8         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 912          |\n|    ep_rew_mean          | 116          |\n| time/                   |              |\n|    fps                  | 850          |\n|    iterations           | 36           |\n|    time_elapsed         | 693          |\n|    total_timesteps      | 589824       |\n| train/                  |              |\n|    approx_kl            | 0.0062560476 |\n|    clip_fraction        | 0.0433       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.03        |\n|    explained_variance   | 0.966        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.96         |\n|    n_updates            | 140          |\n|    policy_gradient_loss | -0.0012      |\n|    value_loss           | 35.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 881         |\n|    ep_rew_mean          | 115         |\n| time/                   |             |\n|    fps                  | 845         |\n|    iterations           | 37          |\n|    time_elapsed         | 717         |\n|    total_timesteps      | 606208      |\n| train/                  |             |\n|    approx_kl            | 0.004455928 |\n|    clip_fraction        | 0.0256      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1          |\n|    explained_variance   | 0.976       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 11          |\n|    n_updates            | 144         |\n|    policy_gradient_loss | -0.000575   |\n|    value_loss           | 25.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 883         |\n|    ep_rew_mean          | 119         |\n| time/                   |             |\n|    fps                  | 842         |\n|    iterations           | 38          |\n|    time_elapsed         | 738         |\n|    total_timesteps      | 622592      |\n| train/                  |             |\n|    approx_kl            | 0.004157063 |\n|    clip_fraction        | 0.0276      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.02       |\n|    explained_variance   | 0.957       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 22.8        |\n|    n_updates            | 148         |\n|    policy_gradient_loss | -0.00115    |\n|    value_loss           | 52.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 890         |\n|    ep_rew_mean          | 124         |\n| time/                   |             |\n|    fps                  | 838         |\n|    iterations           | 39          |\n|    time_elapsed         | 761         |\n|    total_timesteps      | 638976      |\n| train/                  |             |\n|    approx_kl            | 0.004618191 |\n|    clip_fraction        | 0.0417      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.05       |\n|    explained_variance   | 0.969       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 78.6        |\n|    n_updates            | 152         |\n|    policy_gradient_loss | -0.000622   |\n|    value_loss           | 39.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 906         |\n|    ep_rew_mean          | 129         |\n| time/                   |             |\n|    fps                  | 835         |\n|    iterations           | 40          |\n|    time_elapsed         | 784         |\n|    total_timesteps      | 655360      |\n| train/                  |             |\n|    approx_kl            | 0.004442365 |\n|    clip_fraction        | 0.0502      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | 0.983       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 6.06        |\n|    n_updates            | 156         |\n|    policy_gradient_loss | -0.00114    |\n|    value_loss           | 20.1        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 915          |\n|    ep_rew_mean          | 132          |\n| time/                   |              |\n|    fps                  | 831          |\n|    iterations           | 41           |\n|    time_elapsed         | 807          |\n|    total_timesteps      | 671744       |\n| train/                  |              |\n|    approx_kl            | 0.0056930687 |\n|    clip_fraction        | 0.0437       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | 0.977        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 20.5         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | 9.08e-05     |\n|    value_loss           | 33.1         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 933         |\n|    ep_rew_mean          | 140         |\n| time/                   |             |\n|    fps                  | 828         |\n|    iterations           | 42          |\n|    time_elapsed         | 830         |\n|    total_timesteps      | 688128      |\n| train/                  |             |\n|    approx_kl            | 0.004758279 |\n|    clip_fraction        | 0.0408      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.03       |\n|    explained_variance   | 0.99        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.7         |\n|    n_updates            | 164         |\n|    policy_gradient_loss | -0.000235   |\n|    value_loss           | 11.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 956         |\n|    ep_rew_mean          | 146         |\n| time/                   |             |\n|    fps                  | 826         |\n|    iterations           | 43          |\n|    time_elapsed         | 852         |\n|    total_timesteps      | 704512      |\n| train/                  |             |\n|    approx_kl            | 0.006611624 |\n|    clip_fraction        | 0.0244      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.986      |\n|    explained_variance   | 0.976       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 22.2        |\n|    n_updates            | 168         |\n|    policy_gradient_loss | -0.00113    |\n|    value_loss           | 33.6        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 964          |\n|    ep_rew_mean          | 148          |\n| time/                   |              |\n|    fps                  | 824          |\n|    iterations           | 44           |\n|    time_elapsed         | 874          |\n|    total_timesteps      | 720896       |\n| train/                  |              |\n|    approx_kl            | 0.0047538336 |\n|    clip_fraction        | 0.0594       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.969       |\n|    explained_variance   | 0.995        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 5.23         |\n|    n_updates            | 172          |\n|    policy_gradient_loss | -0.000204    |\n|    value_loss           | 5.54         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 972         |\n|    ep_rew_mean          | 150         |\n| time/                   |             |\n|    fps                  | 821         |\n|    iterations           | 45          |\n|    time_elapsed         | 897         |\n|    total_timesteps      | 737280      |\n| train/                  |             |\n|    approx_kl            | 0.004953146 |\n|    clip_fraction        | 0.0357      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.966      |\n|    explained_variance   | 0.985       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.27        |\n|    n_updates            | 176         |\n|    policy_gradient_loss | -0.000422   |\n|    value_loss           | 17.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 980         |\n|    ep_rew_mean          | 151         |\n| time/                   |             |\n|    fps                  | 818         |\n|    iterations           | 46          |\n|    time_elapsed         | 920         |\n|    total_timesteps      | 753664      |\n| train/                  |             |\n|    approx_kl            | 0.004779459 |\n|    clip_fraction        | 0.0381      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.991      |\n|    explained_variance   | 0.995       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.97        |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.000664   |\n|    value_loss           | 5.36        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 980        |\n|    ep_rew_mean          | 153        |\n| time/                   |            |\n|    fps                  | 816        |\n|    iterations           | 47         |\n|    time_elapsed         | 943        |\n|    total_timesteps      | 770048     |\n| train/                  |            |\n|    approx_kl            | 0.00528795 |\n|    clip_fraction        | 0.0427     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.981     |\n|    explained_variance   | 0.99       |\n|    learning_rate        | 0.0003     |\n|    loss                 | 3.37       |\n|    n_updates            | 184        |\n|    policy_gradient_loss | -0.00112   |\n|    value_loss           | 13.2       |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 985          |\n|    ep_rew_mean          | 152          |\n| time/                   |              |\n|    fps                  | 814          |\n|    iterations           | 48           |\n|    time_elapsed         | 965          |\n|    total_timesteps      | 786432       |\n| train/                  |              |\n|    approx_kl            | 0.0047866665 |\n|    clip_fraction        | 0.0437       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.962       |\n|    explained_variance   | 0.995        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.36         |\n|    n_updates            | 188          |\n|    policy_gradient_loss | 0.00072      |\n|    value_loss           | 5.36         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 985          |\n|    ep_rew_mean          | 152          |\n| time/                   |              |\n|    fps                  | 811          |\n|    iterations           | 49           |\n|    time_elapsed         | 988          |\n|    total_timesteps      | 802816       |\n| train/                  |              |\n|    approx_kl            | 0.0038607093 |\n|    clip_fraction        | 0.0456       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.945       |\n|    explained_variance   | 0.997        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.989        |\n|    n_updates            | 192          |\n|    policy_gradient_loss | -0.000617    |\n|    value_loss           | 3.53         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 992          |\n|    ep_rew_mean          | 153          |\n| time/                   |              |\n|    fps                  | 810          |\n|    iterations           | 50           |\n|    time_elapsed         | 1010         |\n|    total_timesteps      | 819200       |\n| train/                  |              |\n|    approx_kl            | 0.0055890866 |\n|    clip_fraction        | 0.0584       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.923       |\n|    explained_variance   | 0.997        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.939        |\n|    n_updates            | 196          |\n|    policy_gradient_loss | -0.00174     |\n|    value_loss           | 3            |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 985          |\n|    ep_rew_mean          | 154          |\n| time/                   |              |\n|    fps                  | 809          |\n|    iterations           | 51           |\n|    time_elapsed         | 1032         |\n|    total_timesteps      | 835584       |\n| train/                  |              |\n|    approx_kl            | 0.0046157725 |\n|    clip_fraction        | 0.048        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.94        |\n|    explained_variance   | 0.998        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.47         |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00145     |\n|    value_loss           | 2.61         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 983          |\n|    ep_rew_mean          | 156          |\n| time/                   |              |\n|    fps                  | 807          |\n|    iterations           | 52           |\n|    time_elapsed         | 1054         |\n|    total_timesteps      | 851968       |\n| train/                  |              |\n|    approx_kl            | 0.0044021807 |\n|    clip_fraction        | 0.0391       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.879       |\n|    explained_variance   | 0.99         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.16         |\n|    n_updates            | 204          |\n|    policy_gradient_loss | -1.78e-05    |\n|    value_loss           | 10.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 983         |\n|    ep_rew_mean          | 155         |\n| time/                   |             |\n|    fps                  | 806         |\n|    iterations           | 53          |\n|    time_elapsed         | 1076        |\n|    total_timesteps      | 868352      |\n| train/                  |             |\n|    approx_kl            | 0.004757706 |\n|    clip_fraction        | 0.0381      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.856      |\n|    explained_variance   | 0.977       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.17        |\n|    n_updates            | 208         |\n|    policy_gradient_loss | -0.000994   |\n|    value_loss           | 37.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 971         |\n|    ep_rew_mean          | 154         |\n| time/                   |             |\n|    fps                  | 805         |\n|    iterations           | 54          |\n|    time_elapsed         | 1098        |\n|    total_timesteps      | 884736      |\n| train/                  |             |\n|    approx_kl            | 0.004283608 |\n|    clip_fraction        | 0.0452      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.808      |\n|    explained_variance   | 0.998       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.21        |\n|    n_updates            | 212         |\n|    policy_gradient_loss | 0.000431    |\n|    value_loss           | 2.05        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 964          |\n|    ep_rew_mean          | 156          |\n| time/                   |              |\n|    fps                  | 804          |\n|    iterations           | 55           |\n|    time_elapsed         | 1119         |\n|    total_timesteps      | 901120       |\n| train/                  |              |\n|    approx_kl            | 0.0022711107 |\n|    clip_fraction        | 0.0234       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.808       |\n|    explained_variance   | 0.979        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 19.8         |\n|    n_updates            | 216          |\n|    policy_gradient_loss | 0.000443     |\n|    value_loss           | 37.9         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 956          |\n|    ep_rew_mean          | 159          |\n| time/                   |              |\n|    fps                  | 804          |\n|    iterations           | 56           |\n|    time_elapsed         | 1140         |\n|    total_timesteps      | 917504       |\n| train/                  |              |\n|    approx_kl            | 0.0036812932 |\n|    clip_fraction        | 0.035        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.798       |\n|    explained_variance   | 0.991        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.893        |\n|    n_updates            | 220          |\n|    policy_gradient_loss | -0.000889    |\n|    value_loss           | 14.4         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 926          |\n|    ep_rew_mean          | 160          |\n| time/                   |              |\n|    fps                  | 805          |\n|    iterations           | 57           |\n|    time_elapsed         | 1159         |\n|    total_timesteps      | 933888       |\n| train/                  |              |\n|    approx_kl            | 0.0033936668 |\n|    clip_fraction        | 0.036        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.795       |\n|    explained_variance   | 0.963        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 91.3         |\n|    n_updates            | 224          |\n|    policy_gradient_loss | 0.000483     |\n|    value_loss           | 69.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 932         |\n|    ep_rew_mean          | 163         |\n| time/                   |             |\n|    fps                  | 805         |\n|    iterations           | 58          |\n|    time_elapsed         | 1179        |\n|    total_timesteps      | 950272      |\n| train/                  |             |\n|    approx_kl            | 0.003306212 |\n|    clip_fraction        | 0.0219      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.805      |\n|    explained_variance   | 0.956       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 4.25        |\n|    n_updates            | 228         |\n|    policy_gradient_loss | -0.000943   |\n|    value_loss           | 67.5        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 910          |\n|    ep_rew_mean          | 165          |\n| time/                   |              |\n|    fps                  | 805          |\n|    iterations           | 59           |\n|    time_elapsed         | 1200         |\n|    total_timesteps      | 966656       |\n| train/                  |              |\n|    approx_kl            | 0.0042781727 |\n|    clip_fraction        | 0.0535       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.747       |\n|    explained_variance   | 0.97         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.58         |\n|    n_updates            | 232          |\n|    policy_gradient_loss | -0.000783    |\n|    value_loss           | 46           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 833         |\n|    ep_rew_mean          | 157         |\n| time/                   |             |\n|    fps                  | 806         |\n|    iterations           | 60          |\n|    time_elapsed         | 1218        |\n|    total_timesteps      | 983040      |\n| train/                  |             |\n|    approx_kl            | 0.004833604 |\n|    clip_fraction        | 0.0394      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.693      |\n|    explained_variance   | 0.93        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44.5        |\n|    n_updates            | 236         |\n|    policy_gradient_loss | -0.000808   |\n|    value_loss           | 112         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 765          |\n|    ep_rew_mean          | 158          |\n| time/                   |              |\n|    fps                  | 807          |\n|    iterations           | 61           |\n|    time_elapsed         | 1237         |\n|    total_timesteps      | 999424       |\n| train/                  |              |\n|    approx_kl            | 0.0037256952 |\n|    clip_fraction        | 0.0294       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.744       |\n|    explained_variance   | 0.909        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 120          |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.000791    |\n|    value_loss           | 151          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 725         |\n|    ep_rew_mean          | 174         |\n| time/                   |             |\n|    fps                  | 808         |\n|    iterations           | 62          |\n|    time_elapsed         | 1255        |\n|    total_timesteps      | 1015808     |\n| train/                  |             |\n|    approx_kl            | 0.009132361 |\n|    clip_fraction        | 0.103       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.657      |\n|    explained_variance   | 0.852       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 210         |\n|    n_updates            | 244         |\n|    policy_gradient_loss | -0.00386    |\n|    value_loss           | 283         |\n-----------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluate the agent ","metadata":{}},{"cell_type":"code","source":"# @title\neval_env = Monitor(gym.make(\"LunarLander-v2\"))\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\nprint(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:31:55.519044Z","iopub.execute_input":"2023-11-25T12:31:55.520182Z","iopub.status.idle":"2023-11-25T12:31:58.647021Z","shell.execute_reply.started":"2023-11-25T12:31:55.520135Z","shell.execute_reply":"2023-11-25T12:31:58.645991Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"mean_reward=260.89 +/- 19.449573305716058\n","output_type":"stream"}]},{"cell_type":"markdown","source":"So we got mean reward of 260.89, which means our lander is ready to land on moon\n\n# Push to huggingface model hub\n- Need to create write token to push the model","metadata":{}},{"cell_type":"code","source":"notebook_login()\n!git config --global credential.helper store","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:35:44.597219Z","iopub.execute_input":"2023-11-25T12:35:44.597676Z","iopub.status.idle":"2023-11-25T12:35:45.636419Z","shell.execute_reply.started":"2023-11-25T12:35:44.597644Z","shell.execute_reply":"2023-11-25T12:35:45.634957Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7889d43dcec042f8a56a99d22a984113"}},"metadata":{}}]},{"cell_type":"code","source":"# Define the name of the environment\nenv_id = \"LunarLander-v2\"\n#Define the model architecture we used\nmodel_architecture = \"PPO\"\n## Define a repo_id\n## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\nrepo_id = \"mlwithrakesh/ppo-LunarLander-v2\"\n## Define the commit message\ncommit_message = \"Upload PPO LunarLander-v2 trained agent\"","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:39:46.202646Z","iopub.execute_input":"2023-11-25T12:39:46.203123Z","iopub.status.idle":"2023-11-25T12:39:46.208895Z","shell.execute_reply.started":"2023-11-25T12:39:46.203091Z","shell.execute_reply":"2023-11-25T12:39:46.207829Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Create the evaluation env and set the render_mode=\"rgb_array\"\neval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode=\"rgb_array\"))])","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:40:48.869950Z","iopub.execute_input":"2023-11-25T12:40:48.870626Z","iopub.status.idle":"2023-11-25T12:40:48.877245Z","shell.execute_reply.started":"2023-11-25T12:40:48.870594Z","shell.execute_reply":"2023-11-25T12:40:48.876157Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"package_to_hub(\n    model=model,  # Our trained model\n    model_name=model_name,  # The name of our trained model\n    model_architecture=model_architecture,  # The model architecture we used: in our case PPO\n    env_id=env_id,  # Name of the environment\n    eval_env=eval_env,  # Evaluation Environment\n    repo_id=repo_id,  # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n    commit_message=commit_message,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:47:18.045298Z","iopub.execute_input":"2023-11-25T12:47:18.046207Z","iopub.status.idle":"2023-11-25T12:47:28.354981Z","shell.execute_reply.started":"2023-11-25T12:47:18.046170Z","shell.execute_reply":"2023-11-25T12:47:28.354016Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\u001b[38;5;4m‚Ñπ This function will save, evaluate, generate a video of your agent,\ncreate a model card and push everything to the hub. It might take up to 1min.\nThis is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: <function VecVideoRecorder.__del__ at 0x7c89a0342b00>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_video_recorder.py\", line 113, in __del__\n    self.close_video_recorder()\n  File \"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_video_recorder.py\", line 104, in close_video_recorder\n    self.video_recorder.close()\n  File \"/opt/conda/lib/python3.10/site-packages/gymnasium/wrappers/monitoring/video_recorder.py\", line 161, in close\n    clip.write_videofile(self.path, logger=moviepy_logger)\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n    for i, extra in enumerate(extras):\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/decorators.py\", line 54, in requires_duration\n    return f(clip, *a, **k)\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n    for i, extra in enumerate(extras):\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/decorators.py\", line 135, in use_clip_fps_by_default\n    return f(clip, *new_a, **new_kw)\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n    for i, extra in enumerate(extras):\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/decorators.py\", line 22, in convert_masks_to_RGB\n    return f(clip, *a, **k)\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/video/VideoClip.py\", line 300, in write_videofile\n    ffmpeg_write_video(self, filename, fps, codec,\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_writer.py\", line 213, in ffmpeg_write_video\n    with FFMPEG_VideoWriter(filename, clip.size, fps, codec = codec,\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_writer.py\", line 88, in __init__\n    '-r', '%.02f' % fps,\nTypeError: must be real number, not NoneType\n","output_type":"stream"},{"name":"stdout","text":"Saving video to /tmp/tmp5xnh5glo/-step-0-to-step-1000.mp4\nMoviepy - Building video /tmp/tmp5xnh5glo/-step-0-to-step-1000.mp4.\nMoviepy - Writing video /tmp/tmp5xnh5glo/-step-0-to-step-1000.mp4\n\n\u001b[38;5;1m‚úò must be real number, not NoneType\u001b[0m\n\u001b[38;5;1m‚úò We are unable to generate a replay of your agent, the package_to_hub\nprocess continues\u001b[0m\n\u001b[38;5;1m‚úò Please open an issue at\nhttps://github.com/huggingface/huggingface_sb3/issues\u001b[0m\nMoviepy - Building video /tmp/tmp5xnh5glo/-step-0-to-step-1000.mp4.\nMoviepy - Writing video /tmp/tmp5xnh5glo/-step-0-to-step-1000.mp4\n\n\u001b[38;5;4m‚Ñπ Pushing repo mlwithrakesh/ppo-LunarLander-v2 to the Hugging Face\nHub\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"ppo-LunarLander-v2.zip:   0%|          | 0.00/147k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bd36479f6cf44168114eec888912b82"}},"metadata":{}},{"name":"stdout","text":"\u001b[38;5;4m‚Ñπ Your model is pushed to the Hub. You can view your model here:\nhttps://huggingface.co/mlwithrakesh/ppo-LunarLander-v2/tree/main/\u001b[0m\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/mlwithrakesh/ppo-LunarLander-v2/tree/main/'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load a saved LunarLander model from the Hub","metadata":{}},{"cell_type":"markdown","source":"Because the model I download from the Hub was trained with Gym (the former version of Gymnasium) we need to install shimmy a API conversion tool that will help us to run the environment correctly.\n\nShimmy Documentation: https://github.com/Farama-Foundation/Shimmy","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:54:03.147372Z","iopub.execute_input":"2023-11-25T12:54:03.148086Z","iopub.status.idle":"2023-11-25T12:54:03.155549Z","shell.execute_reply.started":"2023-11-25T12:54:03.148035Z","shell.execute_reply":"2023-11-25T12:54:03.154243Z"}}},{"cell_type":"code","source":"!pip install shimmy","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:54:17.127074Z","iopub.execute_input":"2023-11-25T12:54:17.128052Z","iopub.status.idle":"2023-11-25T12:54:29.333102Z","shell.execute_reply.started":"2023-11-25T12:54:17.128012Z","shell.execute_reply":"2023-11-25T12:54:29.331980Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Collecting shimmy\n  Obtaining dependency information for shimmy from https://files.pythonhosted.org/packages/dc/f9/07ef16463db14ac1b30f149c379760f5cacf3fc677b295d29a92f3127914/Shimmy-1.3.0-py3-none-any.whl.metadata\n  Downloading Shimmy-1.3.0-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from shimmy) (1.24.3)\nRequirement already satisfied: gymnasium>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from shimmy) (0.28.1)\nRequirement already satisfied: jax-jumpy>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (1.0.0)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (2.2.1)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (4.5.0)\nRequirement already satisfied: farama-notifications>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from gymnasium>=0.27.0->shimmy) (0.0.4)\nDownloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\nInstalling collected packages: shimmy\nSuccessfully installed shimmy-1.3.0\n","output_type":"stream"}]},{"cell_type":"code","source":"repo_id = \"mlwithrakesh/ppo-LunarLander-v2\"  # The repo_id\nfilename = \"ppo-LunarLander-v2.zip\"  # The model filename.zip\n\n# When the model was trained on Python 3.8 the pickle protocol is 5\n# But Python 3.6, 3.7 use protocol 4\n# In order to get compatibility we need to:\n# 1. Install pickle5 (we done it at the beginning of the colab)\n# 2. Create a custom empty object we pass as parameter to PPO.load()\ncustom_objects = {\n    \"learning_rate\": 0.0,\n    \"lr_schedule\": lambda _: 0.0,\n    \"clip_range\": lambda _: 0.0,\n}\n\ncheckpoint = load_from_hub(repo_id, filename)\nmodel = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:57:02.160363Z","iopub.execute_input":"2023-11-25T12:57:02.161172Z","iopub.status.idle":"2023-11-25T12:57:02.573514Z","shell.execute_reply.started":"2023-11-25T12:57:02.161133Z","shell.execute_reply":"2023-11-25T12:57:02.572556Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading ppo-LunarLander-v2.zip:   0%|          | 0.00/147k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"503bf08292694d2582d460e04054a080"}},"metadata":{}},{"name":"stdout","text":"== CURRENT SYSTEM INFO ==\n- OS: Linux-5.15.133+-x86_64-with-glibc2.35 # 1 SMP Wed Nov 8 17:30:28 UTC 2023\n- Python: 3.10.12\n- Stable-Baselines3: 2.0.0a5\n- PyTorch: 2.0.0\n- GPU Enabled: True\n- Numpy: 1.24.3\n- Cloudpickle: 3.0.0\n- Gymnasium: 0.28.1\n- OpenAI Gym: 0.26.2\n\n== SAVED MODEL SYSTEM INFO ==\n- OS: Linux-5.15.133+-x86_64-with-glibc2.35 # 1 SMP Wed Nov 8 17:30:28 UTC 2023\n- Python: 3.10.12\n- Stable-Baselines3: 2.0.0a5\n- PyTorch: 2.0.0\n- GPU Enabled: True\n- Numpy: 1.24.3\n- Cloudpickle: 3.0.0\n- Gymnasium: 0.28.1\n- OpenAI Gym: 0.26.2\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# @title\neval_env = Monitor(gym.make(\"LunarLander-v2\"))\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\nprint(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-25T12:57:14.597897Z","iopub.execute_input":"2023-11-25T12:57:14.598648Z","iopub.status.idle":"2023-11-25T12:57:17.682784Z","shell.execute_reply.started":"2023-11-25T12:57:14.598603Z","shell.execute_reply":"2023-11-25T12:57:17.681732Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"mean_reward=266.50 +/- 19.21535826587336\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}