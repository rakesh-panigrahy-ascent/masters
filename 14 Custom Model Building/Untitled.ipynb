{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e31e3f1",
   "metadata": {},
   "source": [
    "### Sequential vs Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8310580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2bee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Implemention 1\n",
    "model =  keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\", name=\"layer1\"),\n",
    "    layers.Dense(8, activation=\"relu\", name=\"layer2\"), \n",
    "    layers.Dense(4, name=\"layer3\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0615b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Implemention 2\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(16, activation=\"relu\", name=\"layer1\"))\n",
    "model.add(layers.Dense(8, activation=\"relu\", name=\"layer2\"))\n",
    "model.add(layers.Dense(4, name=\"layer3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c2d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional Implemention 2\n",
    "\n",
    "#Encode an image to a vector\n",
    "image_model = keras.Sequential([\n",
    "    layers.Conv2D(128, (3,3), activation='relu', input_shape=(299,299,3)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten()\n",
    "])\n",
    "\n",
    "img_input = layers.Input(shape=(299,299,3))\n",
    "encoded_image = image_model(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7749d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Language model\n",
    "txt_input = layers.Input(shape=(200,), dtype='int32', name='context')\n",
    "embed_output = layers.Embedding(input_dim=5000, output_dim=512, input_length=200)(txt_input)\n",
    "encoded_txt = layers.LSTM(128)(embed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac7ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenation\n",
    "concat = layers.concatenate([encoded_image, encoded_txt])\n",
    "output_class = layers.Dense(512, activation='softmax')(concat)\n",
    "final_model = keras.Model(inputs=[img_input, txt_input], outputs = output_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c3a1e",
   "metadata": {},
   "source": [
    "Here, the inception_block uses two branches of the CNN_block. The outputs coming from these two branches are then merged together by passing two instances of CNN_block as a list to the layers.concatenate layer.\n",
    "\n",
    " \n",
    "\n",
    "This feature is called Shared layers, where you have reused the same block again inside our new block/lego. By sharing the information across two or more different inputs, shared layers allow you to train a model even on lesser data.\n",
    "\n",
    " \n",
    "\n",
    "Now that you have defined all the blocks that would be used for the model, you can go ahead and build the architecture for the same. Consider the model that you want to build is the following.\n",
    "\n",
    "(input shape: 28,28,1))\n",
    "\n",
    "        ↓\n",
    "[CNN_block(32 units)]\n",
    "\n",
    "        ↓\n",
    "[MaxPooling2D(3)]\n",
    "\n",
    "        ↓\n",
    "[Inception_block (32 units, 32 units)]\n",
    "\n",
    "        ↓\n",
    "[Inception_block (64 units, 64 units)]\n",
    "\n",
    "        ↓\n",
    "[CNN_block(128 units)]\n",
    "\n",
    "        ↓\n",
    "[GlobalAveragePooling2D()]\n",
    "\n",
    "        ↓\n",
    "[Dense (256 units, relu activation)]\n",
    "\n",
    "        ↓\n",
    "[Dropout(0.5)]\n",
    "\n",
    "        ↓\n",
    "[Dense (10 units)]\n",
    "\n",
    "        ↓\n",
    "(output: logits of a probability distribution over 10 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce48eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_block(x,filters, kernel_size=3, padding=\"same\"):\n",
    "    # Defining a function which returns an operation of Convolution, BatchNormalisation and Relu.\n",
    "    # Here x is the input.\n",
    "    x = Conv2D(filters, (3,3), padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d9ba5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block(x, filter1, filter2):\n",
    "    # Defining a function which applies two CNN blocks. The output of both these blocks are then concatenated\n",
    "    conv1 = CNN_block(x, filter1)\n",
    "    conv2 = CNN_block(x, filter2)\n",
    "    x = keras.layers.concatenate([conv1, conv2])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba1c5dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"final_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 28, 28, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 28, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " tf.nn.relu (TFOpLambda)        (None, 28, 28, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 9, 9, 32)     0           ['tf.nn.relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 9, 9, 32)     9248        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 9, 9, 32)     9248        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 9, 9, 32)    128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 9, 9, 32)    128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_1 (TFOpLambda)      (None, 9, 9, 32)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.nn.relu_2 (TFOpLambda)      (None, 9, 9, 32)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 9, 9, 64)     0           ['tf.nn.relu_1[0][0]',           \n",
      "                                                                  'tf.nn.relu_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 9, 9, 64)     36928       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 9, 9, 64)     36928       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 9, 9, 64)    256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 9, 9, 64)    256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_3 (TFOpLambda)      (None, 9, 9, 64)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " tf.nn.relu_4 (TFOpLambda)      (None, 9, 9, 64)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 9, 9, 128)    0           ['tf.nn.relu_3[0][0]',           \n",
      "                                                                  'tf.nn.relu_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 9, 9, 128)    147584      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 9, 9, 128)   512         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " tf.nn.relu_5 (TFOpLambda)      (None, 9, 9, 128)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 128)         0           ['tf.nn.relu_5[0][0]']           \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          33024       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           2570        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 277,258\n",
      "Trainable params: 276,554\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = CNN_block(inputs,32)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = inception_block(x,32, 32)\n",
    "x = inception_block(x,64, 64)\n",
    "x = CNN_block(x,128)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "model = keras.Model(inputs, outputs, name=\"final_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79414726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53a53446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf799e4",
   "metadata": {},
   "source": [
    "### Model Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e0833",
   "metadata": {},
   "source": [
    "In the previous segment, you have learnt how to implement Sequential and  Functional API.\n",
    "\n",
    "Among these two, you might have observed that the Sequential API is the easiest approach to build models, but it’s also a naive approach there are many limitations when it comes to:\n",
    "\n",
    "Building models with multiple inputs and outputs\n",
    "Sharing layers\n",
    " \n",
    "\n",
    "The Functional API bridge this gap by allowing you to create more complex models. This approach provides the support of multiple inputs and multiple outputs, layer sharing, branching and reusability. But in this approach for each block, we are applying operations on the built-in layers. The Keras API provides you with many built-in layers like:\n",
    "\n",
    "Convolutional layers: Conv1D, Conv2D, etc.\n",
    "Pooling layers: MaxPooling1D, MaxPooling2D, etc.\n",
    "RNN layers: GRU, LSTM, etc.\n",
    "BatchNormalization, Dropout, Embedding, etc.\n",
    " \n",
    "\n",
    "But if you don't want to work with these built-in layers and you want to create your own layers, then the third approach - Model Subclassing provides an elegant solution.\n",
    "\n",
    " \n",
    "\n",
    "Model Subclassing is tailor-made for advanced developers who want to customise how their model, layer, and training process works. Let's understand this in detail in the next video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339a071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ff1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c8a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520cb41b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
