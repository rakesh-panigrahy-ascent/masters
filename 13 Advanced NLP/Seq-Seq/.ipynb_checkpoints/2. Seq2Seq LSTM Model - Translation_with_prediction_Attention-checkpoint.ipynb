{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoJPolOgWGG4"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1578827658934,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "zlt_1eHPWGG6",
    "outputId": "c7f7274e-0d9c-465b-af63-7aa1918a1c14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzxABbMJWGG-"
   },
   "source": [
    "### Read the data\n",
    "<font size=\"2\">Data for this exercise can be downloaded from http://www.manythings.org/anki/</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5469,
     "status": "ok",
     "timestamp": 1578827661268,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "ommjMLuF75Dk",
    "outputId": "ebf03a27-f816-4ba5-e10c-66838546e3b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7558,
     "status": "ok",
     "timestamp": 1578827663386,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "1vDoJM0zWGG_",
    "outputId": "1c797d05-8816-470c-ca02-9793848b0f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-12 11:14:19--  http://www.manythings.org/anki/hin-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:30::6818:6dc4, ...\n",
      "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 126500 (124K) [application/zip]\n",
      "Saving to: ‘hin-eng.zip’\n",
      "\n",
      "\r",
      "hin-eng.zip           0%[                    ]       0  --.-KB/s               \r",
      "hin-eng.zip          86%[================>   ] 106.57K   439KB/s               \r",
      "hin-eng.zip         100%[===================>] 123.54K   508KB/s    in 0.2s    \n",
      "\n",
      "2020-01-12 11:14:20 (508 KB/s) - ‘hin-eng.zip’ saved [126500/126500]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#You can use wget to download the file directly\n",
    "!wget http://www.manythings.org/anki/hin-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8soXgFrWGHB"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "\n",
    "#Read the zip file\n",
    "zf = zipfile.ZipFile('hin-eng.zip', 'r')\n",
    "\n",
    "#Extract data from zip file\n",
    "data = ''\n",
    "with zf.open('hin.txt') as readfile:\n",
    "  for line in io.TextIOWrapper(readfile, 'utf-8'):\n",
    "    data += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7532,
     "status": "ok",
     "timestamp": 1578827663388,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "SQFmYMvhWGHE",
    "outputId": "475e0a26-7681-4933-8cc4-67e85e3be33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #6179123 (fastrizwaan)\\nHello!\\tनमस्'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[400:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lx5AWe-0WGHT"
   },
   "source": [
    "\n",
    "### Extract Source and Target Language pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7521,
     "status": "ok",
     "timestamp": 1578827663389,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "mjma2IuuWGHU",
    "outputId": "6d1c7752-3c1b-41e0-baaa-48b21a7b71b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have a car.\\tमेरे पास एक गाड़ी है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #252272 (CK) & #477720 (minshirui)',\n",
       " 'I have a dog.\\tमेरे पास एक कुत्ता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #378502 (CK) & #443037 (minshirui)',\n",
       " 'I understand.\\tमैं समझता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433468 (CK) & #588495 (minshirui)',\n",
       " \"I'm a doctor.\\tमैं डॉक्टर हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #256018 (CK) & #449296 (minshirui)\",\n",
       " 'It is a book.\\tयह किताब है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #42097 (CK) & #443050 (minshirui)']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split by newline character\n",
    "data =  data.split('\\n')\n",
    "\n",
    "#Show some Data\n",
    "data[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7513,
     "status": "ok",
     "timestamp": 1578827663391,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "Af9jau2XWGHX",
    "outputId": "7a319537-1477-49c8-f2f3-2f27f1893e02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2780"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A4ow84XDWGHb"
   },
   "source": [
    "### Separate Source and Target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GTzjK4G6WGHb"
   },
   "outputs": [],
   "source": [
    "encoder_text = [] #Initialize Source language list\n",
    "decoder_text = [] #Initialize Target language list\n",
    "\n",
    "#Iterate over data\n",
    "for line in data:\n",
    "    try:\n",
    "        in_txt, out_txt,_ = line.split('\\t')\n",
    "        encoder_text.append(in_txt)\n",
    "        \n",
    "        # Add tab '<start>' as 'start sequence in target\n",
    "        # And '<end>' as End\n",
    "        decoder_text.append('<start> ' + out_txt + ' <end>')\n",
    "    except:\n",
    "        pass #ignore data which goes into error        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4T4HJ3A9WGHd"
   },
   "source": [
    "### Separate Source and Target pairs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7497,
     "status": "ok",
     "timestamp": 1578827663392,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "xyZqwGuvWGHe",
    "outputId": "a007b496-cad1-40c9-96b3-4156f6cd17a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have a car.',\n",
       " 'I have a dog.',\n",
       " 'I understand.',\n",
       " \"I'm a doctor.\",\n",
       " 'It is a book.']"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7483,
     "status": "ok",
     "timestamp": 1578827663393,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "v2CILOS3WGHg",
    "outputId": "27963750-f317-4900-d654-914ec30186a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> मेरे पास एक गाड़ी है। <end>',\n",
       " '<start> मेरे पास एक कुत्ता है। <end>',\n",
       " '<start> मैं समझता हूँ। <end>',\n",
       " '<start> मैं डॉक्टर हूँ। <end>',\n",
       " '<start> यह किताब है। <end>']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_text[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnRP431qWGHj"
   },
   "source": [
    "### Tokenize Source language sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7801,
     "status": "ok",
     "timestamp": 1578827663720,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "9ucqBYr4WGHk",
    "outputId": "9ccf1e8e-81f8-4068-d11a-0bb9fb5a251a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 14, 6, 96], [2, 14, 6, 124], [2, 208], [39, 6, 150], [10, 5, 6, 69]]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenizer for source language\n",
    "encoder_t = tf.keras.preprocessing.text.Tokenizer()\n",
    "encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences\n",
    "encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers \n",
    "encoder_seq[100:105] #Display some converted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7792,
     "status": "ok",
     "timestamp": 1578827663721,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "zZv-TPVOWGHn",
    "outputId": "856200b6-5a9d-492f-b491-5de601e69352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length for Source language:  22\n",
      "Source language vocablury size:  2375\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of sentence\n",
    "max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n",
    "print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n",
    "\n",
    "#Source language Vocablury\n",
    "encoder_vocab_size = len(encoder_t.word_index)\n",
    "print('Source language vocablury size: ', encoder_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BeASC50tWGHr"
   },
   "source": [
    "### Tokenize Target language sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zcyow_keWGHr"
   },
   "outputs": [],
   "source": [
    "#Tokenizer for target language, filters should not <start> and <end>\n",
    "#remove < and > used in Target language sequences\n",
    "decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n",
    "decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7781,
     "status": "ok",
     "timestamp": 1578827663722,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "phLrIK6WWGHt",
    "outputId": "9771b40e-3372-404c-b1ca-395fe9fcdc56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length for Target language:  27\n",
      "Target language vocablury size:  2973\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of sentence\n",
    "max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n",
    "print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n",
    "\n",
    "#Target language Vocablury\n",
    "decoder_vocab_size = len(decoder_t.word_index)\n",
    "print('Target language vocablury size: ', decoder_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6fXf48uMWGH6"
   },
   "source": [
    "### Compare different sentences length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7595,
     "status": "ok",
     "timestamp": 1578827663724,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "w0aRkCfiWGH7",
    "outputId": "83ca87fb-9e74-485b-f241-e428704ff13a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length for sentence number 100:  4\n",
      "Length for sentence number 2000:  8\n"
     ]
    }
   ],
   "source": [
    "#Source Language sentences\n",
    "print('Length for sentence number 100: ', len(encoder_seq[100]))\n",
    "print('Length for sentence number 2000: ', len(encoder_seq[2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7079,
     "status": "ok",
     "timestamp": 1578827663724,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "W2qZN4BvWGH_",
    "outputId": "49664a19-20db-401d-d789-ae9c24b942aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length for sentence number 100:  7\n",
      "Length for sentence number 2000:  8\n"
     ]
    }
   ],
   "source": [
    "#Target Language sentences\n",
    "print('Length for sentence number 100: ', len(decoder_seq[100]))\n",
    "print('Length for sentence number 2000: ', len(decoder_seq[2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmeSCSs6WGIC"
   },
   "source": [
    "### How do we make it same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqps8juMWGIE"
   },
   "source": [
    "### Padding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rnbyRs9WGIF"
   },
   "outputs": [],
   "source": [
    "#Source sentences\n",
    "encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n",
    "                                                                   maxlen=max_encoder_seq_length, #22\n",
    "                                                                   padding='pre')\n",
    "\n",
    "#Target Sentences\n",
    "decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, \n",
    "                                                                   maxlen=max_decoder_seq_length, #27\n",
    "                                                                   padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 836,
     "status": "ok",
     "timestamp": 1578827671958,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "a61g_ADpWGIH",
    "outputId": "47f6b6d2-4446-480c-e1dd-50580740fe11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data shape:  (2779, 22)\n",
      "Target data shape:  (2779, 27)\n"
     ]
    }
   ],
   "source": [
    "print('Source data shape: ', encoder_input_data.shape)\n",
    "print('Target data shape: ', decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nl4oxg8cWGIJ"
   },
   "source": [
    "#### Integer to Word converter for Decoder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jhwnBD-0WGIK"
   },
   "outputs": [],
   "source": [
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1578827674294,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "q8TP07uxWGIP",
    "outputId": "7638eb0b-8240-4656-e484-499da8592fb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'की'"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word_decoder[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5g4Y4oRvWGIV"
   },
   "source": [
    "### Building Decoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YuoPA9aWWGIV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Initialize array\n",
    "decoder_target_data = np.zeros((decoder_input_data.shape[0], decoder_input_data.shape[1]))\n",
    "\n",
    "#Shift Target output by one word\n",
    "for i in range(decoder_input_data.shape[0]):\n",
    "    for j in range(1,decoder_input_data.shape[1]):\n",
    "        decoder_target_data[i][j-1] = decoder_input_data[i][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haordQCuWGIX"
   },
   "source": [
    "#### Convert target data in one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vs2SKKI5WGIY"
   },
   "outputs": [],
   "source": [
    "#Initialize one hot encoding array\n",
    "decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], #number of sentences\n",
    "                                   decoder_input_data.shape[1], #Number of words in each sentence\n",
    "                                   len(decoder_t.word_index)+1)) #Vocab size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoX_6OP4WGIm"
   },
   "outputs": [],
   "source": [
    "#Build one hot encoded array\n",
    "for i in range(decoder_target_data.shape[0]):\n",
    "    for j in range(decoder_target_data.shape[1]):\n",
    "        decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n",
    "                                                                     num_classes=len(decoder_t.word_index)+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1578827678984,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "Y5fO1TTWWGIo",
    "outputId": "fc91d34c-993c-4379-830f-6fa393064a44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2779, 27, 2974)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQYFym0AWGIq"
   },
   "source": [
    "### Building the Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fRfYeB2AWGIr"
   },
   "outputs": [],
   "source": [
    "#Define config parameters\n",
    "encoder_embedding_size = 50\n",
    "decoder_embedding_size = 50\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "71ukvjyeWGIt"
   },
   "source": [
    "#### Build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1578827758213,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "2SHW_YvkWGIw",
    "outputId": "fadeac63-81c6-409b-f859-98c4c0093836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#Input Layer\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "\n",
    "#Embedding layer\n",
    "encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, encoder_embedding_size)\n",
    "\n",
    "#Get embedding layer output by feeding inputs\n",
    "encoder_embedding_output = encoder_embedding(encoder_inputs)\n",
    "\n",
    "#---Following code has been commented out for Attention-------\n",
    "#LSTM Layer and its output\n",
    "#x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n",
    "\n",
    "#Build a list to feed Decoder\n",
    "#encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YbfLAFglWGIx"
   },
   "source": [
    "#### Build Encoder - Get all hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EnZJnNSbWGIz"
   },
   "outputs": [],
   "source": [
    "#Create LSTM Layer and get All hidden states, last hidden and cell state\n",
    "encoder_lstm = tf.keras.layers.LSTM(rnn_units,return_state=True, return_sequences=True)\n",
    "\n",
    "#Get 3 outputs of LSTM Layer\n",
    "encoder_all_h_states, state_h, state_c = encoder_lstm(encoder_embedding_output)\n",
    "\n",
    "#Build a list to feed Decoder\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RAIuXWK5WGI1"
   },
   "source": [
    "#### Build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYY-zwUSWGI2"
   },
   "outputs": [],
   "source": [
    "#Decode input - padded Target sentences\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "\n",
    "#Decoder Embedding layer\n",
    "decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, decoder_embedding_size)\n",
    "\n",
    "#Embedding layer output\n",
    "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
    "\n",
    "#Decoder RNN\n",
    "decoder_rnn = tf.keras.layers.LSTM(rnn_units, return_sequences=True, return_state=True)\n",
    "\n",
    "#Decoder RNN Output, State initialization from Encoder states\n",
    "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
    "decoder_all_h_states,_,_ = decoder_rnn(decoder_embedding_output, \n",
    "                                       initial_state=encoder_states)\n",
    "\n",
    "#---Following code has been commented out for Attention-------\n",
    "#Output Layer\n",
    "#decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n",
    "\n",
    "#Output of Dense layer\n",
    "#decoder_outputs = decoder_dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwtwXesXWGI4"
   },
   "source": [
    "#### Build Decoder...Alignment Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOJtf8kMWGI5"
   },
   "outputs": [],
   "source": [
    "#1. Dot Product between Decoder_all_h_states and encoder_all_h_states\n",
    "#2. Apply softmax to get Alignment matrix\n",
    "\n",
    "#Dimensions details\n",
    "#decoder_all_states = batch_size x max_decoder_length x rnn_units\n",
    "#encoder_all_states = batch_size x max_encoder_length x rnn_units\n",
    "#score = batch_size x max_decoder_length x max_encoder_length\n",
    "#alignment matrix = batch_size x max_decoder_length x max_encoder_length\n",
    "\n",
    "score = tf.keras.layers.dot([decoder_all_h_states, encoder_all_h_states], axes=2)\n",
    "alignment_matrix = tf.keras.layers.Activation('softmax')(score)\n",
    "\n",
    "#Try general and concat approaches to alignment matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 836,
     "status": "ok",
     "timestamp": 1578828019812,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "SNzzFkm4W0N8",
    "outputId": "d590873d-ad8d-44b9-bffc-3893238ffce0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation/truediv:0' shape=(?, ?, ?) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cYFfIGyvWGI6"
   },
   "source": [
    "#### Build Decoder...Context Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ICneq6WGI6"
   },
   "outputs": [],
   "source": [
    "#Weighted sum of multiplication of Alignment matrix and encoder states\n",
    "#Dimension of context_vector =  batch_size x max_decoder_length x rnn_units\n",
    "\n",
    "context_vector = tf.keras.layers.dot([alignment_matrix, encoder_all_h_states], axes=[2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1578828066301,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "S3EtN7Ho9fHy",
    "outputId": "c93f427d-7a51-48f6-bb39-28ef00e90d9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dot_1/MatMul:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4GOKQuJiWGI8"
   },
   "source": [
    "#### Build Decoder...Attention Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L9aJaK5LWGI8"
   },
   "outputs": [],
   "source": [
    "#Concatenate context vector and decoder_all_h_states\n",
    "#context_decoder_hidden = batch_size x max_decoder_length x rnn_units\n",
    "#attention_vector = batch_size x max_decoder_length x 128\n",
    "\n",
    "context_decoder_hidden = tf.keras.layers.concatenate([context_vector, \n",
    "                                                      decoder_all_h_states])\n",
    "\n",
    "attention_dense_layer = tf.keras.layers.Dense(128, use_bias=False, \n",
    "                                              activation='tanh')\n",
    "\n",
    "attention_vector = attention_dense_layer(context_decoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1578828215344,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "v1nE-nHNfqix",
    "outputId": "68be9117-fe28-4e49-b25b-3f6babbe3a75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/Tanh:0' shape=(?, ?, 128) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yvcsEikBWGI-"
   },
   "source": [
    "#### Build Decoder...Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GinU4PH5WGI_"
   },
   "outputs": [],
   "source": [
    "#Output layer\n",
    "decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, activation='softmax')\n",
    "\n",
    "#With attention input will be attention_vector and not decoder_all_h_states\n",
    "decoder_outputs = decoder_dense(attention_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__FmqX3qWGJL"
   },
   "source": [
    "### Build Model using both Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbtWE0_JWGJL"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n",
    "                              decoder_outputs) #Output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WG4pyK_jWGJO"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uHhrDTBZWGJQ"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 654014,
     "status": "ok",
     "timestamp": 1578828937322,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "81ciKSvCWGJQ",
    "outputId": "52d3d3f0-bb34-486a-a038-8915eda905d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2223 samples, validate on 556 samples\n",
      "Epoch 1/25\n",
      "2223/2223 [==============================] - 28s 12ms/sample - loss: 4.3687 - acc: 0.7177 - val_loss: 3.3492 - val_acc: 0.5939\n",
      "Epoch 2/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 2.1416 - acc: 0.7391 - val_loss: 3.3560 - val_acc: 0.5939\n",
      "Epoch 3/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 2.1055 - acc: 0.7391 - val_loss: 3.3382 - val_acc: 0.5939\n",
      "Epoch 4/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 2.0448 - acc: 0.7391 - val_loss: 3.1883 - val_acc: 0.5939\n",
      "Epoch 5/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.8299 - acc: 0.7391 - val_loss: 2.9404 - val_acc: 0.5939\n",
      "Epoch 6/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.6557 - acc: 0.7405 - val_loss: 2.7506 - val_acc: 0.5968\n",
      "Epoch 7/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.5274 - acc: 0.7635 - val_loss: 2.6247 - val_acc: 0.6250\n",
      "Epoch 8/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.4476 - acc: 0.7805 - val_loss: 2.5592 - val_acc: 0.6349\n",
      "Epoch 9/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.3976 - acc: 0.7828 - val_loss: 2.5542 - val_acc: 0.6384\n",
      "Epoch 10/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.3641 - acc: 0.7860 - val_loss: 2.4792 - val_acc: 0.6410\n",
      "Epoch 11/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.3366 - acc: 0.7899 - val_loss: 2.4811 - val_acc: 0.6409\n",
      "Epoch 12/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.3120 - acc: 0.7921 - val_loss: 2.4763 - val_acc: 0.6441\n",
      "Epoch 13/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.2924 - acc: 0.7929 - val_loss: 2.5034 - val_acc: 0.6429\n",
      "Epoch 14/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.2753 - acc: 0.7939 - val_loss: 2.4898 - val_acc: 0.6434\n",
      "Epoch 15/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.2600 - acc: 0.7943 - val_loss: 2.4903 - val_acc: 0.6450\n",
      "Epoch 16/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.2454 - acc: 0.7951 - val_loss: 2.4668 - val_acc: 0.6455\n",
      "Epoch 17/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.2312 - acc: 0.7958 - val_loss: 2.5096 - val_acc: 0.6438\n",
      "Epoch 18/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.2184 - acc: 0.7966 - val_loss: 2.4946 - val_acc: 0.6459\n",
      "Epoch 19/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.2041 - acc: 0.7975 - val_loss: 2.5130 - val_acc: 0.6450\n",
      "Epoch 20/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.1903 - acc: 0.7979 - val_loss: 2.4790 - val_acc: 0.6473\n",
      "Epoch 21/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.1770 - acc: 0.7983 - val_loss: 2.5378 - val_acc: 0.6472\n",
      "Epoch 22/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.1627 - acc: 0.7997 - val_loss: 2.5120 - val_acc: 0.6491\n",
      "Epoch 23/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.1464 - acc: 0.8016 - val_loss: 2.5273 - val_acc: 0.6485\n",
      "Epoch 24/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.1300 - acc: 0.8035 - val_loss: 2.5007 - val_acc: 0.6506\n",
      "Epoch 25/25\n",
      "2223/2223 [==============================] - 26s 12ms/sample - loss: 1.1144 - acc: 0.8048 - val_loss: 2.5640 - val_acc: 0.6477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f33085de9e8>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_one_hot,\n",
    "          batch_size=64,\n",
    "          epochs=25,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gO-p-OaWGJT"
   },
   "source": [
    "### Save the model for later reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUJcwtNyWGJU"
   },
   "outputs": [],
   "source": [
    "#model.save('models/seq2seq_training_translation_attention.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PjuM6UkoWGJW"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('models/seq2seq_training_translation_attention.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8k64d1HWGJY"
   },
   "source": [
    "# Building Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_w__FLXCWGJZ"
   },
   "source": [
    "### Build the Encoder Model to predict Encoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9sSoCtMWGJZ"
   },
   "outputs": [],
   "source": [
    "encoder_model = tf.keras.models.Model(inputs=encoder_inputs, #Padded input sequences\n",
    "                                      outputs=[encoder_all_h_states] + #Hidden states at all time steps\n",
    "                                      encoder_states) #Hidden state and Cell state at last time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RScHHgr5WGJb"
   },
   "source": [
    "### Build the Decoder Model \n",
    "<p/>\n",
    "\n",
    "<ol><li>Define Input for both 'h' state and 'c' state initialization </li>\n",
    "    <li><font color=\"blue\">Define Input for all encoder states - Attention Layer </font></li>\n",
    "<li>Get Decoder RNN outputs along with h and c state</li>\n",
    "<li><font color=\"blue\">Build Attention Layer</font></li>\n",
    "<li><font color=\"blue\">Get Decoder Dense layer output using Attention vector</font></li>\n",
    "    <li><font color=\"blue\">Build Model</font></li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZGRM_UQWGJc"
   },
   "source": [
    "##### Step 1 - Define Input for both 'h' state and 'c' state initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wq4XvgTAWGJc"
   },
   "outputs": [],
   "source": [
    "#Hidden state input\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n",
    "\n",
    "#Cell state input\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n",
    "\n",
    "#Putting it together\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U4rg9wJMWGJe"
   },
   "source": [
    "##### Step 2 - Define Input encoder states - Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYozwBH2WGJe"
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.keras.layers.Input(shape=(max_encoder_seq_length, rnn_units,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu7AJ7teWGJg"
   },
   "source": [
    "##### Step 3 - Get Decoder RNN outputs along with h and c state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPbxVkdoWGJh"
   },
   "outputs": [],
   "source": [
    "#Get Embedding layer output\n",
    "x = decoder_embedding(decoder_inputs)\n",
    "\n",
    "#We will use the layer which we trained earlier\n",
    "rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n",
    "\n",
    "#Why do we need this?\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YnDK-mtkWGJk"
   },
   "source": [
    "##### Step 4 - Build Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RFkceyHWGJk"
   },
   "outputs": [],
   "source": [
    "#Alignment score\n",
    "p_score = tf.keras.layers.dot([rnn_outputs, encoder_outputs], axes=2)\n",
    "\n",
    "#Perform softmax to get Alignment matrix\n",
    "p_alignment_matrix = tf.keras.layers.Activation('softmax')(p_score)\n",
    "\n",
    "#Context Vector\n",
    "p_context_vector = tf.keras.layers.dot([p_alignment_matrix, encoder_outputs], axes=[2,1])\n",
    "\n",
    "#Build Attention Vector\n",
    "# 1. Caoncatenate both context vector and decoder outputs\n",
    "# 2. Feed it to the Dense layer \n",
    "p_context_decoder_hidden = tf.keras.layers.concatenate([p_context_vector, rnn_outputs])\n",
    "p_attention_vector = attention_dense_layer(p_context_decoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLw9G3KkWGJl",
    "outputId": "c6708e95-d1bd-42f0-c5f1-4b0ebca1847a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_1/truediv:0' shape=(?, ?, 22) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_alignment_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUVTE025WGJn"
   },
   "source": [
    "##### Step 5 - Get Decoder Dense layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o60fmWbJWGJo"
   },
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_dense(p_attention_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oE7o-lOfWGJ3"
   },
   "source": [
    "##### Step 6 - Build Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "545vI4cXWGJ4"
   },
   "outputs": [],
   "source": [
    "#3 Inputs - Word, h/c state and all hidden states from encoder\n",
    "#3 Outputs - predicted word, h and c state values for next run and alignment matrix for visualization\n",
    "\n",
    "decoder_model = tf.keras.models.Model([decoder_inputs] +  #Start sequence and then word\n",
    "                                      decoder_states_inputs + #h and c state value for initialization\n",
    "                                      [encoder_outputs],  #Encoder all hidden states for Attention layer\n",
    "                                      [decoder_outputs] + #Model word prediction\n",
    "                                      decoder_states +   #h and c states for next run\n",
    "                                      [p_alignment_matrix]) #for Alignment matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7VEzNGyWGJ5"
   },
   "source": [
    "# Predicting output from Seq2Seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcg5mBcYWGJ6"
   },
   "source": [
    "##### Build a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1VoPsIkWGJ6"
   },
   "outputs": [],
   "source": [
    "def decode_sentence(input_sequence):\n",
    "    \n",
    "    #Get the encoder state values\n",
    "    encoder_output =  encoder_model.predict(input_sequence)\n",
    "    decoder_initial_states_value = encoder_output[1:]    \n",
    "    encoded_seqs = encoder_output[0]\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        #Decoder model with 3 inputs\n",
    "        predicted_outputs, h, c, a_matrix = decoder_model.predict([target_seq] + \n",
    "                                                                  decoder_initial_states_value +\n",
    "                                                                  [encoded_seqs])\n",
    "        \n",
    "        #Get the predicted word index with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter index\n",
    "        if (predicted_output == 0):\n",
    "            predicted_word = ' '\n",
    "        else:\n",
    "            predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or len(predicted_sentence) > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "                    \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value for decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "        #print(a_matrix)\n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuQcVTVZWGJ8"
   },
   "source": [
    "##### Call Prediction function on a random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkJznTF8WGJ9",
    "outputId": "0eb5c8f5-f122-4c71-d2c4-0b990bca8b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Input sentence:  I laughed.\n",
      "Predicted sentence:  वह अपने लिए बहुत बहुत नहीं है।\n"
     ]
    }
   ],
   "source": [
    "#Generate a random number\n",
    "start_num = np.random.randint(0, high=len(encoder_text) - 10)\n",
    "\n",
    "#Predict model output for 5 sentences\n",
    "for i in range(start_num, start_num + 1):\n",
    "    input_seq = encoder_input_data[i : i+1]\n",
    "    #print(input_seq)\n",
    "    predicted_sentence = decode_sentence(input_seq)\n",
    "    print('--------')\n",
    "    print ('Input sentence: ', encoder_text[i])\n",
    "    print ('Predicted sentence: ', predicted_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS-RjZPlWGJ-"
   },
   "source": [
    "##### Save encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2l-qAT-bWGJ-"
   },
   "outputs": [],
   "source": [
    "#Compile models to avoid error\n",
    "encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "\n",
    "#Save the models\n",
    "encoder_model.save('models/seq2seq_encoder_eng_hin.hd5')  #Encoder model\n",
    "decoder_model.save('models/seq2seq_decoder_eng_hin.hd5')  #Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oh0okCv0WGKA"
   },
   "source": [
    "##### Save encoder and decoder tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qwfb-v7OWGKB"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(encoder_t,open('models/encoder_tokenizer_eng','wb'))\n",
    "pickle.dump(decoder_t,open('models/decoder_tokenizer_hin','wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2. Seq2Seq LSTM Model - Translation_with_prediction_Attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
