{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5csO-wPPKXmw"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "W0ttJZT3KXmx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80Pcvzu4KXmz"
   },
   "source": [
    "### Read the data\n",
    "<font size=\"2\">Data for this exercise can be downloaded from http://www.manythings.org/anki/</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "vQBFJRquKXm0"
   },
   "outputs": [],
   "source": [
    "#You can use wget to download the file directly\n",
    "!wget http://www.manythings.org/anki/hin-eng.zip --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "E4V6ZdyClsfE"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "JtMmO7f0aJdg"
   },
   "outputs": [],
   "source": [
    "!unzip hin-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "jPUrsgVkaPi7"
   },
   "outputs": [],
   "source": [
    "!cat hin.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "tooO9pGrKXm2"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "\n",
    "#Read the zip file\n",
    "zf = zipfile.ZipFile('hin-eng.zip', 'r')\n",
    "\n",
    "#Extract data from zip file\n",
    "data = ''\n",
    "with zf.open('hin.txt') as readfile:\n",
    "  for line in io.TextIOWrapper(readfile, 'utf-8'):\n",
    "    data += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "fiQ2ROWgKXm3"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "9Ir1xfYwKXm5"
   },
   "outputs": [],
   "source": [
    "data[40000:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6AgsSZ9KXm7"
   },
   "source": [
    "\n",
    "### Extract Source and Target Language pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1Mb8tIyKXm7"
   },
   "outputs": [],
   "source": [
    "#Split by newline character\n",
    "data =  data.split('\\n')\n",
    "\n",
    "#Show some Data\n",
    "data[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apuKzGY4KXm9"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnEw_IMEKXm_"
   },
   "source": [
    "### Separate Source and Target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQMiDL45KXnA"
   },
   "outputs": [],
   "source": [
    "encoder_text = [] #Initialize Source language list\n",
    "decoder_text = [] #Initialize Target language list\n",
    "\n",
    "#Iterate over data\n",
    "for line in data:\n",
    "    try:\n",
    "        in_txt, out_txt,_ = line.split('\\t')\n",
    "        encoder_text.append(in_txt)\n",
    "        \n",
    "        # Add tab '<start>' as 'start sequence in target\n",
    "        # And '<end>' as End\n",
    "        decoder_text.append('<start> ' + out_txt + ' <end>')\n",
    "    except:\n",
    "        pass #ignore data which goes into error        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdOMuGbUKXnC"
   },
   "source": [
    "### Separate Source and Target pairs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8QDZAbKXnD"
   },
   "outputs": [],
   "source": [
    "encoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DduIsYLKXnF"
   },
   "outputs": [],
   "source": [
    "decoder_text[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1BA2RbOVKXnI"
   },
   "source": [
    "### Tokenize Source language sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OiGqsXDKXnI"
   },
   "outputs": [],
   "source": [
    "#Tokenizer for source language\n",
    "encoder_t = tf.keras.preprocessing.text.Tokenizer()\n",
    "encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1576301591346,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "38f6Yl9HKXnK",
    "outputId": "a810b283-e6b6-4a29-a50f-c3184e0e912e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2376"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1576301629389,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "u8fZ-qAJ96Sw",
    "outputId": "4952319e-19a6-4ca1-b422-a89fb7ed1759"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'i': 2,\n",
       " 'to': 3,\n",
       " 'you': 4,\n",
       " 'is': 5,\n",
       " 'a': 6,\n",
       " 'he': 7,\n",
       " 'of': 8,\n",
       " 'in': 9,\n",
       " 'my': 10,\n",
       " 'it': 11,\n",
       " 'me': 12,\n",
       " 'this': 13,\n",
       " 'have': 14,\n",
       " 'she': 15,\n",
       " 'was': 16,\n",
       " 'for': 17,\n",
       " 'are': 18,\n",
       " 'do': 19,\n",
       " 'that': 20,\n",
       " 'his': 21,\n",
       " 'your': 22,\n",
       " 'will': 23,\n",
       " 'what': 24,\n",
       " 'on': 25,\n",
       " 'we': 26,\n",
       " \"don't\": 27,\n",
       " 'at': 28,\n",
       " 'him': 29,\n",
       " 'her': 30,\n",
       " 'not': 31,\n",
       " 'like': 32,\n",
       " 'go': 33,\n",
       " 'with': 34,\n",
       " 'be': 35,\n",
       " 'how': 36,\n",
       " 'and': 37,\n",
       " 'can': 38,\n",
       " \"i'm\": 39,\n",
       " 'has': 40,\n",
       " 'there': 41,\n",
       " 'time': 42,\n",
       " 'know': 43,\n",
       " 'all': 44,\n",
       " 'up': 45,\n",
       " 'they': 46,\n",
       " 'come': 47,\n",
       " 'very': 48,\n",
       " 'as': 49,\n",
       " 'please': 50,\n",
       " 'had': 51,\n",
       " 'from': 52,\n",
       " \"it's\": 53,\n",
       " 'by': 54,\n",
       " 'out': 55,\n",
       " 'am': 56,\n",
       " 'want': 57,\n",
       " 'when': 58,\n",
       " 'did': 59,\n",
       " 'here': 60,\n",
       " 'no': 61,\n",
       " 'been': 62,\n",
       " \"can't\": 63,\n",
       " 'going': 64,\n",
       " 'get': 65,\n",
       " 'take': 66,\n",
       " 'an': 67,\n",
       " 'father': 68,\n",
       " 'book': 69,\n",
       " 'about': 70,\n",
       " 'if': 71,\n",
       " 'one': 72,\n",
       " 'were': 73,\n",
       " 'money': 74,\n",
       " 'india': 75,\n",
       " 'would': 76,\n",
       " 'tom': 77,\n",
       " 'long': 78,\n",
       " 'today': 79,\n",
       " 'where': 80,\n",
       " 'two': 81,\n",
       " 'but': 82,\n",
       " 'day': 83,\n",
       " 'tomorrow': 84,\n",
       " 'must': 85,\n",
       " 'help': 86,\n",
       " \"i'll\": 87,\n",
       " 'us': 88,\n",
       " 'make': 89,\n",
       " 'man': 90,\n",
       " 'live': 91,\n",
       " 'back': 92,\n",
       " 'see': 93,\n",
       " 'english': 94,\n",
       " 'our': 95,\n",
       " 'home': 96,\n",
       " 'car': 97,\n",
       " 'now': 98,\n",
       " 'good': 99,\n",
       " 'who': 100,\n",
       " 'work': 101,\n",
       " 'these': 102,\n",
       " 'yesterday': 103,\n",
       " 'too': 104,\n",
       " \"didn't\": 105,\n",
       " 'should': 106,\n",
       " 'so': 107,\n",
       " 'room': 108,\n",
       " 'made': 109,\n",
       " 'many': 110,\n",
       " 'never': 111,\n",
       " 'house': 112,\n",
       " 'last': 113,\n",
       " 'every': 114,\n",
       " 'mother': 115,\n",
       " 'went': 116,\n",
       " 'speak': 117,\n",
       " 'than': 118,\n",
       " 'much': 119,\n",
       " 'off': 120,\n",
       " 'nothing': 121,\n",
       " 'more': 122,\n",
       " 'again': 123,\n",
       " 'dog': 124,\n",
       " 'some': 125,\n",
       " 'think': 126,\n",
       " 'old': 127,\n",
       " 'tell': 128,\n",
       " 'could': 129,\n",
       " 'people': 130,\n",
       " 'got': 131,\n",
       " 'well': 132,\n",
       " 'may': 133,\n",
       " 'door': 134,\n",
       " 'them': 135,\n",
       " 'always': 136,\n",
       " 'any': 137,\n",
       " 'down': 138,\n",
       " 'turn': 139,\n",
       " 'train': 140,\n",
       " 'children': 141,\n",
       " 'let': 142,\n",
       " 'give': 143,\n",
       " 'call': 144,\n",
       " 'put': 145,\n",
       " \"i've\": 146,\n",
       " 'why': 147,\n",
       " 'school': 148,\n",
       " 'before': 149,\n",
       " 'doctor': 150,\n",
       " 'leave': 151,\n",
       " 'lot': 152,\n",
       " 'teacher': 153,\n",
       " 'into': 154,\n",
       " 'say': 155,\n",
       " 'or': 156,\n",
       " 'tired': 157,\n",
       " 'new': 158,\n",
       " 'happy': 159,\n",
       " 'night': 160,\n",
       " 'next': 161,\n",
       " 'water': 162,\n",
       " 'away': 163,\n",
       " 'left': 164,\n",
       " 'open': 165,\n",
       " 'read': 166,\n",
       " 'believe': 167,\n",
       " 'use': 168,\n",
       " 'ten': 169,\n",
       " 'keep': 170,\n",
       " 'because': 171,\n",
       " 'their': 172,\n",
       " \"let's\": 173,\n",
       " 'answer': 174,\n",
       " 'once': 175,\n",
       " 'year': 176,\n",
       " 'hard': 177,\n",
       " 'saw': 178,\n",
       " \"isn't\": 179,\n",
       " 'problem': 180,\n",
       " 'job': 181,\n",
       " 'true': 182,\n",
       " 'does': 183,\n",
       " 'soon': 184,\n",
       " 'few': 185,\n",
       " 'mary': 186,\n",
       " 'way': 187,\n",
       " 'seen': 188,\n",
       " 'letter': 189,\n",
       " 'both': 190,\n",
       " 'big': 191,\n",
       " 'drive': 192,\n",
       " 'birthday': 193,\n",
       " 'feel': 194,\n",
       " \"that's\": 195,\n",
       " 'cut': 196,\n",
       " 'met': 197,\n",
       " 'watch': 198,\n",
       " 'books': 199,\n",
       " 'years': 200,\n",
       " 'tea': 201,\n",
       " \"couldn't\": 202,\n",
       " 'without': 203,\n",
       " 'japan': 204,\n",
       " 'morning': 205,\n",
       " \"what's\": 206,\n",
       " 'came': 207,\n",
       " 'wrong': 208,\n",
       " 'understand': 209,\n",
       " 'everyone': 210,\n",
       " 'doing': 211,\n",
       " 'girl': 212,\n",
       " 'such': 213,\n",
       " 'three': 214,\n",
       " 'afraid': 215,\n",
       " 'times': 216,\n",
       " 'cannot': 217,\n",
       " 'world': 218,\n",
       " 'love': 219,\n",
       " 'try': 220,\n",
       " \"he's\": 221,\n",
       " 'bed': 222,\n",
       " 'around': 223,\n",
       " 'likes': 224,\n",
       " 'really': 225,\n",
       " 'right': 226,\n",
       " 'after': 227,\n",
       " 'friends': 228,\n",
       " 'lost': 229,\n",
       " 'bought': 230,\n",
       " 'tried': 231,\n",
       " \"i'd\": 232,\n",
       " 'play': 233,\n",
       " 'gave': 234,\n",
       " 'little': 235,\n",
       " 'five': 236,\n",
       " 'other': 237,\n",
       " 'six': 238,\n",
       " 'able': 239,\n",
       " \"won't\": 240,\n",
       " 'month': 241,\n",
       " 'said': 242,\n",
       " 'took': 243,\n",
       " 'coming': 244,\n",
       " 'buy': 245,\n",
       " 'stay': 246,\n",
       " 'early': 247,\n",
       " 'running': 248,\n",
       " 'first': 249,\n",
       " 'meet': 250,\n",
       " 'already': 251,\n",
       " 'news': 252,\n",
       " 'yet': 253,\n",
       " 'wanted': 254,\n",
       " 'box': 255,\n",
       " 'caught': 256,\n",
       " 'looked': 257,\n",
       " 'shoes': 258,\n",
       " 'while': 259,\n",
       " 'week': 260,\n",
       " 'river': 261,\n",
       " 'comes': 262,\n",
       " \"o'clock\": 263,\n",
       " 'own': 264,\n",
       " 'baby': 265,\n",
       " 'better': 266,\n",
       " 'ever': 267,\n",
       " 'between': 268,\n",
       " 'medicine': 269,\n",
       " 'looking': 270,\n",
       " 'usually': 271,\n",
       " 'brother': 272,\n",
       " 'smoking': 273,\n",
       " 'days': 274,\n",
       " 'something': 275,\n",
       " 'fun': 276,\n",
       " 'broke': 277,\n",
       " 'cold': 278,\n",
       " 'knows': 279,\n",
       " 'drink': 280,\n",
       " 'fish': 281,\n",
       " \"we're\": 282,\n",
       " 'study': 283,\n",
       " 'dinner': 284,\n",
       " 'friend': 285,\n",
       " 'eyes': 286,\n",
       " 'bad': 287,\n",
       " 'abroad': 288,\n",
       " 'married': 289,\n",
       " 'small': 290,\n",
       " 'felt': 291,\n",
       " 'ask': 292,\n",
       " 'city': 293,\n",
       " 'health': 294,\n",
       " 'mind': 295,\n",
       " 'just': 296,\n",
       " 'easy': 297,\n",
       " 'walk': 298,\n",
       " 'station': 299,\n",
       " 'coffee': 300,\n",
       " 'difficult': 301,\n",
       " 'almost': 302,\n",
       " \"doesn't\": 303,\n",
       " 'used': 304,\n",
       " 'accident': 305,\n",
       " 'sit': 306,\n",
       " 'boy': 307,\n",
       " 'busy': 308,\n",
       " 'town': 309,\n",
       " \"you're\": 310,\n",
       " 'ill': 311,\n",
       " 'stop': 312,\n",
       " 'mine': 313,\n",
       " 'person': 314,\n",
       " 'name': 315,\n",
       " 'sister': 316,\n",
       " 'life': 317,\n",
       " 'poor': 318,\n",
       " 'died': 319,\n",
       " 'ran': 320,\n",
       " 'party': 321,\n",
       " 'asked': 322,\n",
       " 'happened': 323,\n",
       " 'hair': 324,\n",
       " 'told': 325,\n",
       " 'found': 326,\n",
       " 'mistakes': 327,\n",
       " 'enough': 328,\n",
       " 'tv': 329,\n",
       " 'wait': 330,\n",
       " 'large': 331,\n",
       " 'eight': 332,\n",
       " 'afternoon': 333,\n",
       " 'others': 334,\n",
       " 'london': 335,\n",
       " 'talking': 336,\n",
       " 'rain': 337,\n",
       " 'hours': 338,\n",
       " 'parents': 339,\n",
       " 'possible': 340,\n",
       " 'saying': 341,\n",
       " 'forgot': 342,\n",
       " 'fly': 343,\n",
       " 'done': 344,\n",
       " 'fire': 345,\n",
       " 'swim': 346,\n",
       " 'french': 347,\n",
       " 'flowers': 348,\n",
       " 'clean': 349,\n",
       " 'music': 350,\n",
       " 'heard': 351,\n",
       " 'noise': 352,\n",
       " 'crying': 353,\n",
       " 'nice': 354,\n",
       " 'hurry': 355,\n",
       " 'boys': 356,\n",
       " 'talk': 357,\n",
       " 'sure': 358,\n",
       " 'questions': 359,\n",
       " 'reading': 360,\n",
       " 'write': 361,\n",
       " 'language': 362,\n",
       " 'became': 363,\n",
       " 'each': 364,\n",
       " 'question': 365,\n",
       " 'country': 366,\n",
       " 'king': 367,\n",
       " 'another': 368,\n",
       " 'beautiful': 369,\n",
       " 'die': 370,\n",
       " 'someone': 371,\n",
       " 'food': 372,\n",
       " 'police': 373,\n",
       " 'america': 374,\n",
       " 'desk': 375,\n",
       " 'sorry': 376,\n",
       " 'things': 377,\n",
       " 'bicycle': 378,\n",
       " 'eat': 379,\n",
       " 'care': 380,\n",
       " 'idea': 381,\n",
       " 'slowly': 382,\n",
       " 'instead': 383,\n",
       " 'written': 384,\n",
       " \"you'll\": 385,\n",
       " 'weather': 386,\n",
       " 'behind': 387,\n",
       " 'since': 388,\n",
       " 'difference': 389,\n",
       " 'birds': 390,\n",
       " 'excuse': 391,\n",
       " 'move': 392,\n",
       " 'nobody': 393,\n",
       " 'sick': 394,\n",
       " 'bring': 395,\n",
       " 'free': 396,\n",
       " 'son': 397,\n",
       " 'only': 398,\n",
       " 'look': 399,\n",
       " 'ready': 400,\n",
       " 'story': 401,\n",
       " 'anything': 402,\n",
       " 'along': 403,\n",
       " 'works': 404,\n",
       " 'address': 405,\n",
       " 'born': 406,\n",
       " 'later': 407,\n",
       " 'yours': 408,\n",
       " 'family': 409,\n",
       " \"she's\": 410,\n",
       " 'power': 411,\n",
       " 'which': 412,\n",
       " 'everybody': 413,\n",
       " 'called': 414,\n",
       " 'lives': 415,\n",
       " 'rich': 416,\n",
       " 'kept': 417,\n",
       " 'need': 418,\n",
       " 'waiting': 419,\n",
       " 'sunday': 420,\n",
       " 'rumor': 421,\n",
       " 'size': 422,\n",
       " 'visit': 423,\n",
       " 'alone': 424,\n",
       " 'wherever': 425,\n",
       " 'thing': 426,\n",
       " 'business': 427,\n",
       " 'often': 428,\n",
       " 'forget': 429,\n",
       " 'playing': 430,\n",
       " 'wish': 431,\n",
       " 'bus': 432,\n",
       " 'makes': 433,\n",
       " 'tennis': 434,\n",
       " 'homework': 435,\n",
       " 'wife': 436,\n",
       " 'apples': 437,\n",
       " 'learn': 438,\n",
       " 'window': 439,\n",
       " 'picture': 440,\n",
       " 'watching': 441,\n",
       " 'class': 442,\n",
       " 'interesting': 443,\n",
       " 'raining': 444,\n",
       " 'spoken': 445,\n",
       " 'clothes': 446,\n",
       " 'telephone': 447,\n",
       " 'capital': 448,\n",
       " 'find': 449,\n",
       " 'hear': 450,\n",
       " 'village': 451,\n",
       " 'child': 452,\n",
       " 'longer': 453,\n",
       " 'through': 454,\n",
       " 'whether': 455,\n",
       " 'pay': 456,\n",
       " 'hungry': 457,\n",
       " 'dogs': 458,\n",
       " 'phone': 459,\n",
       " 'hot': 460,\n",
       " 'summer': 461,\n",
       " 'bag': 462,\n",
       " 'wash': 463,\n",
       " 'run': 464,\n",
       " 'guitar': 465,\n",
       " \"where's\": 466,\n",
       " 'began': 467,\n",
       " 'cried': 468,\n",
       " \"haven't\": 469,\n",
       " 'getting': 470,\n",
       " 'hands': 471,\n",
       " 'blue': 472,\n",
       " 'against': 473,\n",
       " 'war': 474,\n",
       " 'matter': 475,\n",
       " 'sleep': 476,\n",
       " 'closed': 477,\n",
       " 'those': 478,\n",
       " 'still': 479,\n",
       " 'television': 480,\n",
       " 'looks': 481,\n",
       " 'seems': 482,\n",
       " 'taking': 483,\n",
       " 'plan': 484,\n",
       " 'apple': 485,\n",
       " 'quickly': 486,\n",
       " 'dress': 487,\n",
       " 'disappointed': 488,\n",
       " 'yourself': 489,\n",
       " 'reap': 490,\n",
       " 'sow': 491,\n",
       " 'anyone': 492,\n",
       " 'lose': 493,\n",
       " 'japanese': 494,\n",
       " 'begins': 495,\n",
       " 'easily': 496,\n",
       " 'decided': 497,\n",
       " 'sky': 498,\n",
       " 'fell': 499,\n",
       " 'studying': 500,\n",
       " 'late': 501,\n",
       " 'sugar': 502,\n",
       " 'rains': 503,\n",
       " 'then': 504,\n",
       " 'minutes': 505,\n",
       " 'air': 506,\n",
       " 'canada': 507,\n",
       " 'larger': 508,\n",
       " 'interested': 509,\n",
       " 'standing': 510,\n",
       " 'changing': 511,\n",
       " 'suddenly': 512,\n",
       " 'europe': 513,\n",
       " 'cup': 514,\n",
       " 'number': 515,\n",
       " 'office': 516,\n",
       " 'meeting': 517,\n",
       " 'set': 518,\n",
       " 'wants': 519,\n",
       " 'grandmother': 520,\n",
       " 'hobby': 521,\n",
       " 'population': 522,\n",
       " 'ship': 523,\n",
       " 'across': 524,\n",
       " 'kind': 525,\n",
       " 'anxious': 526,\n",
       " 'men': 527,\n",
       " 'plane': 528,\n",
       " 'china': 529,\n",
       " 'finish': 530,\n",
       " 'making': 531,\n",
       " 'whoever': 532,\n",
       " 'hand': 533,\n",
       " 'being': 534,\n",
       " 'mountain': 535,\n",
       " 'hospital': 536,\n",
       " 'advice': 537,\n",
       " 'finished': 538,\n",
       " 'bit': 539,\n",
       " 'machine': 540,\n",
       " 'known': 541,\n",
       " 'necessary': 542,\n",
       " 'different': 543,\n",
       " 'arrested': 544,\n",
       " 'england': 545,\n",
       " 'jump': 546,\n",
       " 'laughed': 547,\n",
       " 'sing': 548,\n",
       " \"who's\": 549,\n",
       " 'stood': 550,\n",
       " 'strong': 551,\n",
       " 'cake': 552,\n",
       " 'attend': 553,\n",
       " 'fat': 554,\n",
       " 'history': 555,\n",
       " 'god': 556,\n",
       " 'over': 557,\n",
       " \"we'll\": 558,\n",
       " 'cooked': 559,\n",
       " 'black': 560,\n",
       " 'beauty': 561,\n",
       " 'talks': 562,\n",
       " 'remember': 563,\n",
       " 'april': 564,\n",
       " 'key': 565,\n",
       " 'age': 566,\n",
       " 'whose': 567,\n",
       " 'bank': 568,\n",
       " 'sight': 569,\n",
       " 'truth': 570,\n",
       " 'earth': 571,\n",
       " 'hope': 572,\n",
       " 'mistake': 573,\n",
       " 'worked': 574,\n",
       " 'dark': 575,\n",
       " 'snow': 576,\n",
       " 'started': 577,\n",
       " 'expensive': 578,\n",
       " 'taxi': 579,\n",
       " 'baseball': 580,\n",
       " 'shirt': 581,\n",
       " 'airport': 582,\n",
       " 'angry': 583,\n",
       " 'agree': 584,\n",
       " 'red': 585,\n",
       " 'broken': 586,\n",
       " 'return': 587,\n",
       " 'secret': 588,\n",
       " 'eggs': 589,\n",
       " 'policeman': 590,\n",
       " 'horse': 591,\n",
       " 'swimming': 592,\n",
       " 'close': 593,\n",
       " 'lake': 594,\n",
       " 'knew': 595,\n",
       " 'learned': 596,\n",
       " 'empty': 597,\n",
       " 'woman': 598,\n",
       " 'prefer': 599,\n",
       " 'myself': 600,\n",
       " 'quit': 601,\n",
       " 'rather': 602,\n",
       " '3': 603,\n",
       " 'light': 604,\n",
       " 'arrive': 605,\n",
       " 'milk': 606,\n",
       " 'abandoned': 607,\n",
       " 'tends': 608,\n",
       " 'present': 609,\n",
       " 'chair': 610,\n",
       " 'show': 611,\n",
       " \"hasn't\": 612,\n",
       " 'face': 613,\n",
       " 'four': 614,\n",
       " 'table': 615,\n",
       " \"shouldn't\": 616,\n",
       " 'garden': 617,\n",
       " 'stand': 618,\n",
       " 'explain': 619,\n",
       " 'bath': 620,\n",
       " 'tokyo': 621,\n",
       " '5': 622,\n",
       " 'cars': 623,\n",
       " 'rest': 624,\n",
       " 'dollars': 625,\n",
       " 'might': 626,\n",
       " 'shade': 627,\n",
       " '10': 628,\n",
       " 'cats': 629,\n",
       " 'movie': 630,\n",
       " \"aren't\": 631,\n",
       " 'believes': 632,\n",
       " 'best': 633,\n",
       " 'arrived': 634,\n",
       " 'hardly': 635,\n",
       " 'brought': 636,\n",
       " 'famous': 637,\n",
       " 'great': 638,\n",
       " 'head': 639,\n",
       " 'promise': 640,\n",
       " 'france': 641,\n",
       " 'dream': 642,\n",
       " 'outside': 643,\n",
       " 'speaking': 644,\n",
       " 'africa': 645,\n",
       " 'become': 646,\n",
       " 'result': 647,\n",
       " 'most': 648,\n",
       " 'future': 649,\n",
       " 'students': 650,\n",
       " 'surprised': 651,\n",
       " 'sisters': 652,\n",
       " 'sun': 653,\n",
       " 'bigger': 654,\n",
       " 'having': 655,\n",
       " 'paris': 656,\n",
       " 'trouble': 657,\n",
       " 'pictures': 658,\n",
       " 'older': 659,\n",
       " 'stayed': 660,\n",
       " 'languages': 661,\n",
       " 'doubt': 662,\n",
       " 'covered': 663,\n",
       " 'ordered': 664,\n",
       " 'whole': 665,\n",
       " 'together': 666,\n",
       " 'street': 667,\n",
       " \"there's\": 668,\n",
       " \"wouldn't\": 669,\n",
       " 'uncle': 670,\n",
       " 'amateur': 671,\n",
       " 'cricket': 672,\n",
       " 'player': 673,\n",
       " 'bridge': 674,\n",
       " 'leaving': 675,\n",
       " 'government': 676,\n",
       " 'pass': 677,\n",
       " 'responsible': 678,\n",
       " 'bored': 679,\n",
       " 'wonderful': 680,\n",
       " 'follow': 681,\n",
       " 'shout': 682,\n",
       " 'cat': 683,\n",
       " 'map': 684,\n",
       " 'feet': 685,\n",
       " 'hat': 686,\n",
       " 'husband': 687,\n",
       " 'cook': 688,\n",
       " 'kites': 689,\n",
       " 'teach': 690,\n",
       " 'join': 691,\n",
       " 'rice': 692,\n",
       " 'legs': 693,\n",
       " 'speaks': 694,\n",
       " 'near': 695,\n",
       " 'bird': 696,\n",
       " 'walking': 697,\n",
       " 'turned': 698,\n",
       " 'listen': 699,\n",
       " 'student': 700,\n",
       " 'stolen': 701,\n",
       " 'radio': 702,\n",
       " 'yes': 703,\n",
       " 'admit': 704,\n",
       " 'women': 705,\n",
       " 'sort': 706,\n",
       " 'tall': 707,\n",
       " 'smiled': 708,\n",
       " 'crow': 709,\n",
       " 'win': 710,\n",
       " 'wine': 711,\n",
       " 'working': 712,\n",
       " 'pulled': 713,\n",
       " 'clear': 714,\n",
       " 'trees': 715,\n",
       " 'tax': 716,\n",
       " 'worry': 717,\n",
       " 'success': 718,\n",
       " 'succeed': 719,\n",
       " 'eating': 720,\n",
       " 'meant': 721,\n",
       " 'joke': 722,\n",
       " 'glasses': 723,\n",
       " 'eleven': 724,\n",
       " 'goes': 725,\n",
       " 'accepted': 726,\n",
       " 'offer': 727,\n",
       " 'daughter': 728,\n",
       " 'correct': 729,\n",
       " 'eye': 730,\n",
       " 'ball': 731,\n",
       " 'lived': 732,\n",
       " 'animal': 733,\n",
       " 'fast': 734,\n",
       " 'foot': 735,\n",
       " 'fever': 736,\n",
       " 'wake': 737,\n",
       " '7': 738,\n",
       " 'nine': 739,\n",
       " 'thinking': 740,\n",
       " 'absent': 741,\n",
       " '30': 742,\n",
       " 'shall': 743,\n",
       " 'piano': 744,\n",
       " 'heart': 745,\n",
       " 'showed': 746,\n",
       " 'oil': 747,\n",
       " 'smooth': 748,\n",
       " 'plenty': 749,\n",
       " 'memory': 750,\n",
       " \"you've\": 751,\n",
       " 'glass': 752,\n",
       " 'park': 753,\n",
       " 'arrogant': 754,\n",
       " 'accused': 755,\n",
       " 'important': 756,\n",
       " 'brothers': 757,\n",
       " 'under': 758,\n",
       " 'cancer': 759,\n",
       " 'novel': 760,\n",
       " 'half': 761,\n",
       " 'anymore': 762,\n",
       " 'forest': 763,\n",
       " 'harder': 764,\n",
       " 'rooms': 765,\n",
       " 'road': 766,\n",
       " 'satisfied': 767,\n",
       " 'neighbors': 768,\n",
       " 'plays': 769,\n",
       " 'burning': 770,\n",
       " 'death': 771,\n",
       " 'sleeping': 772,\n",
       " 'account': 773,\n",
       " 'sold': 774,\n",
       " 'travel': 775,\n",
       " 'towel': 776,\n",
       " 'add': 777,\n",
       " 'm': 778,\n",
       " 'herself': 779,\n",
       " 'thank': 780,\n",
       " 'cry': 781,\n",
       " 'twenty': 782,\n",
       " 'protect': 783,\n",
       " 'favorite': 784,\n",
       " 'smoke': 785,\n",
       " 'officer': 786,\n",
       " 'whatever': 787,\n",
       " 'opinions': 788,\n",
       " 'miles': 789,\n",
       " 'boss': 790,\n",
       " 'place': 791,\n",
       " 'feed': 792,\n",
       " 'word': 793,\n",
       " 'order': 794,\n",
       " 'bread': 795,\n",
       " 'explained': 796,\n",
       " 'rule': 797,\n",
       " 'osaka': 798,\n",
       " 'waste': 799,\n",
       " 'voice': 800,\n",
       " 'saved': 801,\n",
       " 'danger': 802,\n",
       " 'store': 803,\n",
       " 'meals': 804,\n",
       " 'words': 805,\n",
       " 'tickets': 806,\n",
       " 'speech': 807,\n",
       " 'game': 808,\n",
       " 'advise': 809,\n",
       " 'pleased': 810,\n",
       " 'allow': 811,\n",
       " 'happen': 812,\n",
       " 'pain': 813,\n",
       " 'italy': 814,\n",
       " 'tree': 815,\n",
       " 'fact': 816,\n",
       " 'butter': 817,\n",
       " 'advantage': 818,\n",
       " 'monday': 819,\n",
       " 'movies': 820,\n",
       " 'trip': 821,\n",
       " 'traffic': 822,\n",
       " 'mail': 823,\n",
       " 'pieces': 824,\n",
       " 'favor': 825,\n",
       " 'flying': 826,\n",
       " 'kite': 827,\n",
       " 'dangerous': 828,\n",
       " 'due': 829,\n",
       " 'illness': 830,\n",
       " 'interpret': 831,\n",
       " 'poem': 832,\n",
       " 'pick': 833,\n",
       " 'borrow': 834,\n",
       " 'subject': 835,\n",
       " 'lie': 836,\n",
       " 'helped': 837,\n",
       " 'tonight': 838,\n",
       " 'wedding': 839,\n",
       " 'fresh': 840,\n",
       " 'promote': 841,\n",
       " 'buried': 842,\n",
       " 'heat': 843,\n",
       " 'until': 844,\n",
       " 'dictionary': 845,\n",
       " 'trust': 846,\n",
       " 'rules': 847,\n",
       " 'ashamed': 848,\n",
       " 'strange': 849,\n",
       " 'wrote': 850,\n",
       " 'temples': 851,\n",
       " 'fifty': 852,\n",
       " 'end': 853,\n",
       " 'starts': 854,\n",
       " 'extent': 855,\n",
       " 'wind': 856,\n",
       " 'leaves': 857,\n",
       " 'computer': 858,\n",
       " 'short': 859,\n",
       " 'prize': 860,\n",
       " 'thief': 861,\n",
       " 'delhi': 862,\n",
       " 'speed': 863,\n",
       " 'breakfast': 864,\n",
       " 'case': 865,\n",
       " 'living': 866,\n",
       " 'depends': 867,\n",
       " 'teaching': 868,\n",
       " 'destroyed': 869,\n",
       " 'catch': 870,\n",
       " 'according': 871,\n",
       " 'front': 872,\n",
       " 'company': 873,\n",
       " 'advised': 874,\n",
       " 'college': 875,\n",
       " 'its': 876,\n",
       " 'sentences': 877,\n",
       " 'passed': 878,\n",
       " 'weeks': 879,\n",
       " 'lights': 880,\n",
       " 'workers': 881,\n",
       " 'museum': 882,\n",
       " 'library': 883,\n",
       " 'answers': 884,\n",
       " 'test': 885,\n",
       " 'ought': 886,\n",
       " 'till': 887,\n",
       " 'couple': 888,\n",
       " 'except': 889,\n",
       " 'largest': 890,\n",
       " 'feeling': 891,\n",
       " 'spent': 892,\n",
       " 'teresa': 893,\n",
       " 'hello': 894,\n",
       " 'cheers': 895,\n",
       " 'ok': 896,\n",
       " 'perfect': 897,\n",
       " 'welcome': 898,\n",
       " 'fine': 899,\n",
       " 'math': 900,\n",
       " 'shot': 901,\n",
       " 'touch': 902,\n",
       " 'atheist': 903,\n",
       " 'congratulations': 904,\n",
       " 'miss': 905,\n",
       " 'reads': 906,\n",
       " 'arabic': 907,\n",
       " 'rude': 908,\n",
       " 'lucky': 909,\n",
       " 'cafe': 910,\n",
       " 'fair': 911,\n",
       " 'fault': 912,\n",
       " 'lack': 913,\n",
       " 'top': 914,\n",
       " 'oranges': 915,\n",
       " 'sign': 916,\n",
       " 'betrayed': 917,\n",
       " 'build': 918,\n",
       " 'nests': 919,\n",
       " 'studied': 920,\n",
       " 'headache': 921,\n",
       " 'loved': 922,\n",
       " 'happiness': 923,\n",
       " 'beach': 924,\n",
       " 'throw': 925,\n",
       " 'breathed': 926,\n",
       " 'deeply': 927,\n",
       " 'simple': 928,\n",
       " 'cousin': 929,\n",
       " 'waited': 930,\n",
       " 'pretty': 931,\n",
       " 'guy': 932,\n",
       " 'enjoyed': 933,\n",
       " 'kids': 934,\n",
       " 'vase': 935,\n",
       " 'pen': 936,\n",
       " 'gym': 937,\n",
       " 'state': 938,\n",
       " 'taste': 939,\n",
       " 'continued': 940,\n",
       " 'eaten': 941,\n",
       " 'ticket': 942,\n",
       " 'green': 943,\n",
       " 'forgive': 944,\n",
       " 'pencil': 945,\n",
       " 'sea': 946,\n",
       " 'consciousness': 947,\n",
       " 'decision': 948,\n",
       " 'shut': 949,\n",
       " 'wore': 950,\n",
       " 'haunted': 951,\n",
       " 'sheets': 952,\n",
       " 'burst': 953,\n",
       " 'feels': 954,\n",
       " 'silk': 955,\n",
       " 'hens': 956,\n",
       " 'bell': 957,\n",
       " 'climbed': 958,\n",
       " 'stairs': 959,\n",
       " 'sharp': 960,\n",
       " 'race': 961,\n",
       " 'boston': 962,\n",
       " 'start': 963,\n",
       " 'swollen': 964,\n",
       " 'hated': 965,\n",
       " 'stubborn': 966,\n",
       " 'nearby': 967,\n",
       " 'missed': 968,\n",
       " 'shouted': 969,\n",
       " \"what're\": 970,\n",
       " 'elevator': 971,\n",
       " 'song': 972,\n",
       " 'earns': 973,\n",
       " 'knocked': 974,\n",
       " 'robbed': 975,\n",
       " 'physics': 976,\n",
       " 'wonder': 977,\n",
       " 'stomach': 978,\n",
       " 'york': 979,\n",
       " 'wears': 980,\n",
       " 'ceased': 981,\n",
       " 'glad': 982,\n",
       " 'lion': 983,\n",
       " 'chairs': 984,\n",
       " 'passport': 985,\n",
       " 'soccer': 986,\n",
       " 'dozen': 987,\n",
       " 'dressed': 988,\n",
       " 'white': 989,\n",
       " 'whichever': 990,\n",
       " 'applies': 991,\n",
       " 'wood': 992,\n",
       " 'cheese': 993,\n",
       " 'thirty': 994,\n",
       " 'fond': 995,\n",
       " 'gun': 996,\n",
       " 'murder': 997,\n",
       " 'seat': 998,\n",
       " 'further': 999,\n",
       " 'cups': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1576301777254,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "UgM11oD9b1kI",
    "outputId": "5ba485df-65b9-4060-9fc3-f19b74903263"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 27, 43], [2, 27, 43], [2, 14, 6, 97], [2, 14, 6, 124], [2, 209]]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert English text to indexes\n",
    "encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers \n",
    "\n",
    "encoder_seq[100:105] #Display some converted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1576301784442,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "cN5DneFYp0nc",
    "outputId": "ba51ce03-2a17-4b4f-df46-2d663f5b848e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't know.\",\n",
       " \"I don't know.\",\n",
       " 'I have a car.',\n",
       " 'I have a dog.',\n",
       " 'I understand.']"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1167,
     "status": "ok",
     "timestamp": 1576301817645,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "kyFL1wvpKXnL",
    "outputId": "b8484042-b2f4-44ad-f0cd-d657dfa68e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length for Source language:  22\n",
      "Source language vocablury size:  2376\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of sentence\n",
    "max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n",
    "print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n",
    "\n",
    "#Source language Vocablury\n",
    "encoder_vocab_size = len(encoder_t.word_index)\n",
    "print('Source language vocablury size: ', encoder_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOmkUnoLKXnN"
   },
   "source": [
    "### Tokenize Target language sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kC_wx4ooBXq"
   },
   "outputs": [],
   "source": [
    "?tf.keras.preprocessing.text.Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLV2B3TXKXnO"
   },
   "outputs": [],
   "source": [
    "#Tokenizer for target language, filters should not <start> and <end>\n",
    "#remove < and > used in Target language sequences\n",
    "decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n",
    "decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1576301927541,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "n9M_6R01KXnP",
    "outputId": "56b2dd25-ffce-459d-b33f-efa9a797465e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length for Target language:  27\n",
      "Target language vocablury size:  2974\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of sentence\n",
    "max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n",
    "print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n",
    "\n",
    "#Target language Vocablury\n",
    "decoder_vocab_size = len(decoder_t.word_index)\n",
    "print('Target language vocablury size: ', decoder_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1576301947877,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "xmzEELcwc2Bg",
    "outputId": "f851f2e4-9c42-4970-9ffb-485aef51c75f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<end>': 2,\n",
       " 'है।': 3,\n",
       " 'में': 4,\n",
       " 'नहीं': 5,\n",
       " 'मैं': 6,\n",
       " 'वह': 7,\n",
       " 'से': 8,\n",
       " 'के': 9,\n",
       " 'मुझे': 10,\n",
       " 'क्या': 11,\n",
       " 'है': 12,\n",
       " 'को': 13,\n",
       " 'हैं।': 14,\n",
       " 'की': 15,\n",
       " 'हो': 16,\n",
       " 'बहुत': 17,\n",
       " 'का': 18,\n",
       " 'उसने': 19,\n",
       " 'पर': 20,\n",
       " 'एक': 21,\n",
       " 'हूँ।': 22,\n",
       " 'तुम': 23,\n",
       " 'था।': 24,\n",
       " 'यह': 25,\n",
       " 'कर': 26,\n",
       " 'लिए': 27,\n",
       " 'मेरे': 28,\n",
       " 'कि': 29,\n",
       " 'और': 30,\n",
       " 'उसे': 31,\n",
       " 'इस': 32,\n",
       " 'हैं': 33,\n",
       " 'भी': 34,\n",
       " 'अपने': 35,\n",
       " 'मेरी': 36,\n",
       " 'मैंने': 37,\n",
       " 'रहा': 38,\n",
       " 'ने': 39,\n",
       " 'पास': 40,\n",
       " 'तो': 41,\n",
       " 'अपनी': 42,\n",
       " 'करने': 43,\n",
       " 'गया।': 44,\n",
       " 'कल': 45,\n",
       " 'ही': 46,\n",
       " 'हम': 47,\n",
       " 'काम': 48,\n",
       " 'कोई': 49,\n",
       " 'उसके': 50,\n",
       " 'तुम्हारे': 51,\n",
       " 'उसकी': 52,\n",
       " 'था': 53,\n",
       " 'साथ': 54,\n",
       " 'घर': 55,\n",
       " 'तुम्हें': 56,\n",
       " 'करना': 57,\n",
       " 'उस': 58,\n",
       " 'थी।': 59,\n",
       " 'मेरा': 60,\n",
       " 'गया': 61,\n",
       " 'सकते': 62,\n",
       " 'समय': 63,\n",
       " 'बात': 64,\n",
       " 'रही': 65,\n",
       " 'पता': 66,\n",
       " 'आप': 67,\n",
       " 'कुछ': 68,\n",
       " 'आज': 69,\n",
       " 'तुम्हे': 70,\n",
       " 'उसको': 71,\n",
       " 'चाहिए।': 72,\n",
       " 'यहाँ': 73,\n",
       " 'अभी': 74,\n",
       " 'बजे': 75,\n",
       " 'तक': 76,\n",
       " 'लगता': 77,\n",
       " 'किताब': 78,\n",
       " 'मुझसे': 79,\n",
       " 'पसंद': 80,\n",
       " 'अच्छा': 81,\n",
       " 'दिया।': 82,\n",
       " 'थे।': 83,\n",
       " 'कभी': 84,\n",
       " 'आ': 85,\n",
       " 'सकता': 86,\n",
       " 'मत': 87,\n",
       " 'हूँ': 88,\n",
       " 'रहे': 89,\n",
       " 'हुई': 90,\n",
       " 'होता': 91,\n",
       " 'दो': 92,\n",
       " 'टॉम': 93,\n",
       " 'अपना': 94,\n",
       " 'किया।': 95,\n",
       " 'जाने': 96,\n",
       " 'करता': 97,\n",
       " 'वे': 98,\n",
       " 'भारत': 99,\n",
       " 'पैसे': 100,\n",
       " 'गाड़ी': 101,\n",
       " 'हो।': 102,\n",
       " 'उससे': 103,\n",
       " 'हुआ': 104,\n",
       " 'मदद': 105,\n",
       " 'न': 106,\n",
       " 'होगा।': 107,\n",
       " 'करते': 108,\n",
       " 'कहाँ': 109,\n",
       " 'हुए': 110,\n",
       " 'उसका': 111,\n",
       " 'ज़्यादा': 112,\n",
       " 'जो': 113,\n",
       " 'साल': 114,\n",
       " 'पहले': 115,\n",
       " 'होती': 116,\n",
       " 'सारे': 117,\n",
       " 'अंग्रेज़ी': 118,\n",
       " 'जाना': 119,\n",
       " 'गए': 120,\n",
       " 'तुम्हारी': 121,\n",
       " 'आपको': 122,\n",
       " 'आदमी': 123,\n",
       " 'किया': 124,\n",
       " 'किसी': 125,\n",
       " 'कम': 126,\n",
       " 'देर': 127,\n",
       " 'गई।': 128,\n",
       " 'जा': 129,\n",
       " 'बार': 130,\n",
       " 'जब': 131,\n",
       " 'बाहर': 132,\n",
       " 'बड़ा': 133,\n",
       " 'बारे': 134,\n",
       " 'अगर': 135,\n",
       " 'हमारे': 136,\n",
       " 'वापस': 137,\n",
       " 'वहाँ': 138,\n",
       " 'सब': 139,\n",
       " 'खाना': 140,\n",
       " 'जाता': 141,\n",
       " 'बंद': 142,\n",
       " 'ये': 143,\n",
       " 'दिया': 144,\n",
       " 'दिन': 145,\n",
       " 'जल्दी': 146,\n",
       " 'फ़ोन': 147,\n",
       " 'कितने': 148,\n",
       " 'रात': 149,\n",
       " 'दी।': 150,\n",
       " 'तुमने': 151,\n",
       " 'करो।': 152,\n",
       " 'सकता।': 153,\n",
       " 'लोग': 154,\n",
       " 'चाहता': 155,\n",
       " 'तरह': 156,\n",
       " 'छोड़': 157,\n",
       " 'हमेशा': 158,\n",
       " 'बारिश': 159,\n",
       " 'लोगों': 160,\n",
       " 'ठीक': 161,\n",
       " 'जवाब': 162,\n",
       " 'तुमसे': 163,\n",
       " 'कैसे': 164,\n",
       " 'हर': 165,\n",
       " 'हमे': 166,\n",
       " 'बच्चे': 167,\n",
       " 'दस': 168,\n",
       " 'उन्होंने': 169,\n",
       " 'स्कूल': 170,\n",
       " 'पापा': 171,\n",
       " 'आता': 172,\n",
       " 'चला': 173,\n",
       " 'खुश': 174,\n",
       " 'अब': 175,\n",
       " 'थे': 176,\n",
       " 'चल': 177,\n",
       " 'गए।': 178,\n",
       " 'क्यों': 179,\n",
       " 'हमने': 180,\n",
       " 'तीन': 181,\n",
       " 'डॉक्टर': 182,\n",
       " 'खतम': 183,\n",
       " 'मौसम': 184,\n",
       " 'देखा।': 185,\n",
       " 'मुश्किल': 186,\n",
       " 'माँ': 187,\n",
       " 'शुरू': 188,\n",
       " 'पानी': 189,\n",
       " 'देखा': 190,\n",
       " 'दो।': 191,\n",
       " 'करती': 192,\n",
       " 'हमारी': 193,\n",
       " 'पिता': 194,\n",
       " 'अच्छी': 195,\n",
       " 'सारी': 196,\n",
       " 'ट्रेन': 197,\n",
       " 'होने': 198,\n",
       " 'सबसे': 199,\n",
       " 'कोशिश': 200,\n",
       " 'अच्छे': 201,\n",
       " 'कुत्ता': 202,\n",
       " 'गई': 203,\n",
       " 'कमरे': 204,\n",
       " 'दोस्त': 205,\n",
       " 'भाई': 206,\n",
       " 'लिया।': 207,\n",
       " 'थोड़ी': 208,\n",
       " 'थोड़ा': 209,\n",
       " 'या': 210,\n",
       " 'चिट्ठी': 211,\n",
       " 'थक': 212,\n",
       " 'ले': 213,\n",
       " 'साफ़': 214,\n",
       " 'फिरसे': 215,\n",
       " 'तुम्हारा': 216,\n",
       " 'नहीं।': 217,\n",
       " 'रहता': 218,\n",
       " 'कब': 219,\n",
       " 'जल्द': 220,\n",
       " 'मन': 221,\n",
       " 'लड़की': 222,\n",
       " 'पाँच': 223,\n",
       " 'करनी': 224,\n",
       " 'जाती': 225,\n",
       " 'चाहते': 226,\n",
       " 'देना': 227,\n",
       " 'बिना': 228,\n",
       " 'सुबह': 229,\n",
       " 'जन्मदिन': 230,\n",
       " 'यकीन': 231,\n",
       " 'वाला': 232,\n",
       " 'बस': 233,\n",
       " 'नौकरी': 234,\n",
       " 'टीवी': 235,\n",
       " 'बाद': 236,\n",
       " 'कहा': 237,\n",
       " 'छः': 238,\n",
       " 'करी।': 239,\n",
       " 'जापान': 240,\n",
       " 'माफ़': 241,\n",
       " 'प्यार': 242,\n",
       " 'दोनो': 243,\n",
       " 'सभी': 244,\n",
       " 'शहर': 245,\n",
       " 'आपकी': 246,\n",
       " 'पढ़': 247,\n",
       " 'आवाज़': 248,\n",
       " 'रोज़': 249,\n",
       " 'नाम': 250,\n",
       " 'पीछे': 251,\n",
       " 'जाएगा।': 252,\n",
       " 'लिया': 253,\n",
       " 'किताबें': 254,\n",
       " 'दरवाज़े': 255,\n",
       " 'सच': 256,\n",
       " 'हफ़्ते': 257,\n",
       " 'चाय': 258,\n",
       " 'वाले': 259,\n",
       " 'चाहिए': 260,\n",
       " 'खाने': 261,\n",
       " 'वजह': 262,\n",
       " 'सही': 263,\n",
       " 'चुका': 264,\n",
       " 'आने': 265,\n",
       " 'ज़रूरत': 266,\n",
       " 'सोच': 267,\n",
       " 'मुझपर': 268,\n",
       " 'इनसान': 269,\n",
       " 'विदेश': 270,\n",
       " 'पूरी': 271,\n",
       " 'हाथ': 272,\n",
       " 'जानता': 273,\n",
       " 'पिताजी': 274,\n",
       " 'बड़े': 275,\n",
       " 'हुआ।': 276,\n",
       " 'शादी': 277,\n",
       " 'टीचर': 278,\n",
       " 'कपड़े': 279,\n",
       " 'पिछले': 280,\n",
       " 'दे': 281,\n",
       " 'नदी': 282,\n",
       " 'दूसरे': 283,\n",
       " 'होते': 284,\n",
       " 'कमरा': 285,\n",
       " 'देख': 286,\n",
       " 'आपके': 287,\n",
       " 'मेज़': 288,\n",
       " 'लगा': 289,\n",
       " 'आमतौर': 290,\n",
       " 'सिगरेट': 291,\n",
       " 'महीने': 292,\n",
       " 'धीरे': 293,\n",
       " 'बच्चों': 294,\n",
       " 'कौन': 295,\n",
       " 'ग़लत': 296,\n",
       " 'कृपया': 297,\n",
       " 'थी': 298,\n",
       " 'चीज़': 299,\n",
       " 'तैयार': 300,\n",
       " 'उम्र': 301,\n",
       " 'लड़के': 302,\n",
       " 'मिलने': 303,\n",
       " 'रहते': 304,\n",
       " 'इंतेज़ार': 305,\n",
       " 'इस्तेमाल': 306,\n",
       " 'चलाना': 307,\n",
       " 'खो': 308,\n",
       " 'मिलना': 309,\n",
       " 'होगा': 310,\n",
       " 'सेव': 311,\n",
       " 'मिला।': 312,\n",
       " 'इतना': 313,\n",
       " 'उनकी': 314,\n",
       " 'काफ़ी': 315,\n",
       " 'इन': 316,\n",
       " 'कितनी': 317,\n",
       " 'समझ': 318,\n",
       " 'फ़ायदा': 319,\n",
       " 'उनके': 320,\n",
       " 'अगले': 321,\n",
       " 'अंदर': 322,\n",
       " 'जाओ।': 323,\n",
       " 'भूल': 324,\n",
       " 'आग': 325,\n",
       " 'लगी': 326,\n",
       " 'आया।': 327,\n",
       " 'लग': 328,\n",
       " 'हुई।': 329,\n",
       " 'करो': 330,\n",
       " 'बहन': 331,\n",
       " '।': 332,\n",
       " 'आसान': 333,\n",
       " 'जूते': 334,\n",
       " 'जहाँ': 335,\n",
       " 'लगभग': 336,\n",
       " 'आदत': 337,\n",
       " 'पीना': 338,\n",
       " 'ना': 339,\n",
       " 'आठ': 340,\n",
       " 'दोपहर': 341,\n",
       " 'दिनों': 342,\n",
       " 'क्योंकि': 343,\n",
       " 'दुनिया': 344,\n",
       " 'गाँव': 345,\n",
       " 'आपका': 346,\n",
       " 'कीजिए।': 347,\n",
       " 'कैसा': 348,\n",
       " 'कुत्ते': 349,\n",
       " 'पैसों': 350,\n",
       " 'आराम': 351,\n",
       " 'मज़ाक': 352,\n",
       " 'याद': 353,\n",
       " 'खुशी': 354,\n",
       " 'बन': 355,\n",
       " 'उन': 356,\n",
       " 'जैसा': 357,\n",
       " 'पड़ी।': 358,\n",
       " 'कितना': 359,\n",
       " 'आए': 360,\n",
       " 'भरोसा': 361,\n",
       " 'घड़ी': 362,\n",
       " 'पुलिस': 363,\n",
       " 'होंगे।': 364,\n",
       " 'पार्टी': 365,\n",
       " 'स्टेशन': 366,\n",
       " 'कॉफ़ी': 367,\n",
       " 'सवाल': 368,\n",
       " 'अक्सर': 369,\n",
       " 'मिल': 370,\n",
       " 'सकती।': 371,\n",
       " 'खबर': 372,\n",
       " 'दवाई': 373,\n",
       " 'सो': 374,\n",
       " 'मम्मी': 375,\n",
       " 'लंदन': 376,\n",
       " 'साईकल': 377,\n",
       " 'फ़र्क': 378,\n",
       " 'लगती': 379,\n",
       " 'अकेले': 380,\n",
       " 'सलाह': 381,\n",
       " 'बता': 382,\n",
       " 'चलो': 383,\n",
       " 'तैरना': 384,\n",
       " 'आपसे': 385,\n",
       " 'करूँगा।': 386,\n",
       " 'बीमार': 387,\n",
       " 'मौत': 388,\n",
       " 'संगीत': 389,\n",
       " 'पढ़ाई': 390,\n",
       " 'शायद': 391,\n",
       " 'आया': 392,\n",
       " 'करी': 393,\n",
       " 'मुलाकात': 394,\n",
       " 'ग़लती': 395,\n",
       " 'चालू': 396,\n",
       " 'ली।': 397,\n",
       " 'विश्वास': 398,\n",
       " 'जितना': 399,\n",
       " 'लम्बा': 400,\n",
       " 'कीजिएगा': 401,\n",
       " 'लेना': 402,\n",
       " 'पेड़': 403,\n",
       " 'हमें': 404,\n",
       " 'डब्बे': 405,\n",
       " 'जान': 406,\n",
       " 'बताया': 407,\n",
       " 'ख़याल': 408,\n",
       " 'सकते।': 409,\n",
       " 'पड़ेगी।': 410,\n",
       " 'रखना': 411,\n",
       " 'बाल': 412,\n",
       " 'ऐसी': 413,\n",
       " 'तेज़': 414,\n",
       " 'राजा': 415,\n",
       " 'उन्हें': 416,\n",
       " 'छोटी': 417,\n",
       " 'पुराने': 418,\n",
       " 'मर': 419,\n",
       " 'ढूँढ': 420,\n",
       " 'सैर': 421,\n",
       " 'चाह्ता': 422,\n",
       " 'समस्या': 423,\n",
       " 'तस्वीर': 424,\n",
       " 'नई': 425,\n",
       " 'सका।': 426,\n",
       " 'बीच': 427,\n",
       " 'अचानक': 428,\n",
       " 'मानो': 429,\n",
       " 'दूर': 430,\n",
       " 'लिखी': 431,\n",
       " 'देने': 432,\n",
       " 'जाकर': 433,\n",
       " 'होगी।': 434,\n",
       " 'कहना': 435,\n",
       " 'बर्दाश्त': 436,\n",
       " 'अलग': 437,\n",
       " 'निकल': 438,\n",
       " 'भूख': 439,\n",
       " 'तू': 440,\n",
       " 'देखने': 441,\n",
       " 'दरवाज़ा': 442,\n",
       " 'इसे': 443,\n",
       " 'मछलियाँ': 444,\n",
       " 'हमारा': 445,\n",
       " 'बिस्तर': 446,\n",
       " 'पैर': 447,\n",
       " 'पतंग': 448,\n",
       " 'शोर': 449,\n",
       " 'फिर': 450,\n",
       " 'कहानी': 451,\n",
       " 'दर्द': 452,\n",
       " 'विद्यार्थी': 453,\n",
       " 'चोरी': 454,\n",
       " 'आँखें': 455,\n",
       " 'आएगा।': 456,\n",
       " 'सकती': 457,\n",
       " 'पैदा': 458,\n",
       " 'परिवार': 459,\n",
       " 'सुंदर': 460,\n",
       " 'आती': 461,\n",
       " 'करके': 462,\n",
       " 'बुरी': 463,\n",
       " 'गर्मी': 464,\n",
       " 'जाए।': 465,\n",
       " 'देखना': 466,\n",
       " 'आसमान': 467,\n",
       " 'लगाकर': 468,\n",
       " 'काट': 469,\n",
       " 'रविवार': 470,\n",
       " 'बज': 471,\n",
       " 'दीजिए।': 472,\n",
       " 'रंग': 473,\n",
       " 'अफ़वाह': 474,\n",
       " 'नाप': 475,\n",
       " 'ज़िन्दगी': 476,\n",
       " 'जानवर': 477,\n",
       " 'भाग': 478,\n",
       " 'खाली': 479,\n",
       " 'देश': 480,\n",
       " 'आसानी': 481,\n",
       " 'काश': 482,\n",
       " 'डर': 483,\n",
       " 'चीनी': 484,\n",
       " 'टेनिस': 485,\n",
       " 'दोनों': 486,\n",
       " 'होमवर्क': 487,\n",
       " 'जंगल': 488,\n",
       " 'अध्यापक': 489,\n",
       " 'पीने': 490,\n",
       " 'हवा': 491,\n",
       " 'जाते': 492,\n",
       " 'खिड़की': 493,\n",
       " 'दुर्घटना': 494,\n",
       " 'सफ़र': 495,\n",
       " 'ऐसा': 496,\n",
       " 'पूरे': 497,\n",
       " 'वादा': 498,\n",
       " 'इसके': 499,\n",
       " 'बजाय': 500,\n",
       " 'सड़क': 501,\n",
       " 'बोली': 502,\n",
       " 'बड़ी': 503,\n",
       " 'भाषा': 504,\n",
       " 'राजधानी': 505,\n",
       " 'रहना': 506,\n",
       " 'जैसे': 507,\n",
       " 'इतने': 508,\n",
       " 'ज़िम्मेदार': 509,\n",
       " 'अंतर': 510,\n",
       " 'बच्चा': 511,\n",
       " 'मशीन': 512,\n",
       " 'वैसा': 513,\n",
       " 'लगते': 514,\n",
       " 'आओ।': 515,\n",
       " 'लो।': 516,\n",
       " 'फूल': 517,\n",
       " 'खरीदना': 518,\n",
       " 'आऊँगा।': 519,\n",
       " 'गरम': 520,\n",
       " 'ज़रूरी': 521,\n",
       " 'आई': 522,\n",
       " 'सुनाई': 523,\n",
       " 'गिटार': 524,\n",
       " 'बिजली': 525,\n",
       " 'बारी': 526,\n",
       " 'रहें': 527,\n",
       " 'खराब': 528,\n",
       " 'सच्चाई': 529,\n",
       " 'जानते': 530,\n",
       " 'जंग': 531,\n",
       " 'रहती': 532,\n",
       " 'किसने': 533,\n",
       " 'सा': 534,\n",
       " 'i': 535,\n",
       " 'छोटा': 536,\n",
       " 'चुके': 537,\n",
       " 'अमीर': 538,\n",
       " 'आओगे': 539,\n",
       " 'पढ़ना': 540,\n",
       " 'बना': 541,\n",
       " 'कामयाब': 542,\n",
       " 'सहमत': 543,\n",
       " 'पीठ': 544,\n",
       " 'मिला': 545,\n",
       " 'फ़ैसला': 546,\n",
       " 'निराश': 547,\n",
       " 'चुकी': 548,\n",
       " 'अफ़सर': 549,\n",
       " 'गरीब': 550,\n",
       " 'विज्ञान': 551,\n",
       " 'लम्बी': 552,\n",
       " 'झील': 553,\n",
       " 'पूरा': 554,\n",
       " 'चहिए।': 555,\n",
       " 'औरत': 556,\n",
       " 'जाऊँगा।': 557,\n",
       " 'साढ़े': 558,\n",
       " 'बजाना': 559,\n",
       " 'वाली': 560,\n",
       " 'अजीब': 561,\n",
       " 'ग़लतियाँ': 562,\n",
       " 'पहुँच': 563,\n",
       " 'बोल': 564,\n",
       " 'खेलना': 565,\n",
       " 'उसपर': 566,\n",
       " 'इससे': 567,\n",
       " 'सामने': 568,\n",
       " 'खड़े': 569,\n",
       " 'लगाया।': 570,\n",
       " 'बीमारी': 571,\n",
       " 'किस': 572,\n",
       " 'कनाडा': 573,\n",
       " 'आना': 574,\n",
       " 'सीखना': 575,\n",
       " 'डॉलर': 576,\n",
       " 'उठा': 577,\n",
       " 'दिलचस्पी': 578,\n",
       " 'बुराई': 579,\n",
       " 'फ़िल्म': 580,\n",
       " 'क्लास': 581,\n",
       " 'दिलचस्प': 582,\n",
       " 'रुक': 583,\n",
       " 'आखिरकार': 584,\n",
       " 'बोलना': 585,\n",
       " 'नम्बर': 586,\n",
       " 'सौ': 587,\n",
       " 'असली': 588,\n",
       " 'सुनकर': 589,\n",
       " 'जाएगी।': 590,\n",
       " 'शौक': 591,\n",
       " 'जहाज़': 592,\n",
       " 'रहने': 593,\n",
       " 'करोगे': 594,\n",
       " 'विषय': 595,\n",
       " 'जितनी': 596,\n",
       " 'चीन': 597,\n",
       " 'स्वास्थ्य': 598,\n",
       " 'पढ़ने': 599,\n",
       " 'पहाड़': 600,\n",
       " 'लिख': 601,\n",
       " 'पाया।': 602,\n",
       " 'देखभाल': 603,\n",
       " 'छोटे': 604,\n",
       " 'पा': 605,\n",
       " 'पहचान': 606,\n",
       " 'तब': 607,\n",
       " 'मज़े': 608,\n",
       " 'पेट': 609,\n",
       " 'चलें': 610,\n",
       " 'मत।': 611,\n",
       " 'खड़ा': 612,\n",
       " 'कैसी': 613,\n",
       " 'फ़्रानसीसी': 614,\n",
       " 'पता।': 615,\n",
       " 'बरफ़': 616,\n",
       " 'गिर': 617,\n",
       " 'मुफ़्त': 618,\n",
       " 'नीचे': 619,\n",
       " 'उड़': 620,\n",
       " 'लड़का': 621,\n",
       " 'कमी': 622,\n",
       " 'इतिहास': 623,\n",
       " 'रहूँगा।': 624,\n",
       " 'भगवान': 625,\n",
       " 'करता।': 626,\n",
       " 'बस्ता': 627,\n",
       " 'पहनी': 628,\n",
       " 'मूँह': 629,\n",
       " 'बक': 630,\n",
       " 'ऊपर': 631,\n",
       " 'लम्बे': 632,\n",
       " 'आस': 633,\n",
       " 'पड़ोस': 634,\n",
       " 'अप्रैल': 635,\n",
       " 'चाबी': 636,\n",
       " 'लगा।': 637,\n",
       " 'बैंक': 638,\n",
       " 'मिलेंगे।': 639,\n",
       " 'कौनसा': 640,\n",
       " 'सवालों': 641,\n",
       " 'महसूस': 642,\n",
       " 'दिखने': 643,\n",
       " 'खरीदी।': 644,\n",
       " 'जीत': 645,\n",
       " 'चाहूँगा।': 646,\n",
       " 'रही।': 647,\n",
       " 'पड़ेगा।': 648,\n",
       " 'चिंता': 649,\n",
       " 'की।': 650,\n",
       " 'योजना': 651,\n",
       " 'खा': 652,\n",
       " 'मछली': 653,\n",
       " 'खुला': 654,\n",
       " 'ग्यारह': 655,\n",
       " 'लाल': 656,\n",
       " 'ड्रेस': 657,\n",
       " 'ओर': 658,\n",
       " 'राज़': 659,\n",
       " 'प्रस्ताव': 660,\n",
       " 'स्वीकार': 661,\n",
       " 'सारा': 662,\n",
       " 'आता।': 663,\n",
       " 'नफ़रत': 664,\n",
       " 'कहीं': 665,\n",
       " 'लगाई।': 666,\n",
       " 'परेशान': 667,\n",
       " 'आएगा': 668,\n",
       " 'भला': 669,\n",
       " 'गाना': 670,\n",
       " 'जापानी': 671,\n",
       " 'सात': 672,\n",
       " 'खुद': 673,\n",
       " 'बत्ती': 674,\n",
       " 'दूध': 675,\n",
       " 'मेहनत': 676,\n",
       " 'तरफ़': 677,\n",
       " 'सके': 678,\n",
       " 'दूँगा।': 679,\n",
       " 'कुरसी': 680,\n",
       " 'आई।': 681,\n",
       " 'डब्बा': 682,\n",
       " 'खोल': 683,\n",
       " 'संतुष्ट': 684,\n",
       " 'जी': 685,\n",
       " 'कप': 686,\n",
       " 'सोने': 687,\n",
       " 'सेहत': 688,\n",
       " 'पत्नी': 689,\n",
       " 'मिनट': 690,\n",
       " 'लेने': 691,\n",
       " 'टोक्यो': 692,\n",
       " 'हाँ': 693,\n",
       " 'कठिन': 694,\n",
       " 'अटैची': 695,\n",
       " 'रो': 696,\n",
       " 'पसंदीता': 697,\n",
       " 'बदलने': 698,\n",
       " 'भूलना।': 699,\n",
       " 'मील': 700,\n",
       " 'बिलकुल': 701,\n",
       " 'मे': 702,\n",
       " 'शब्द': 703,\n",
       " 'हिसाब': 704,\n",
       " 'घंटे': 705,\n",
       " 'यूरोप': 706,\n",
       " 'नियम': 707,\n",
       " 'पार': 708,\n",
       " 'सपना': 709,\n",
       " 'नगर': 710,\n",
       " 'होतीं': 711,\n",
       " 'दुकान': 712,\n",
       " 'हमसे': 713,\n",
       " 'आते': 714,\n",
       " 'चाहती': 715,\n",
       " 'टिकटें': 716,\n",
       " 'अमेरिका': 717,\n",
       " 'अफ़्रीका': 718,\n",
       " 'बेटे': 719,\n",
       " 'पकड़': 720,\n",
       " 'हद': 721,\n",
       " 'इसलिए': 722,\n",
       " 'रवाना': 723,\n",
       " 'इरादा': 724,\n",
       " 'जाऊँगी।': 725,\n",
       " 'लिखा': 726,\n",
       " 'बेहतर': 727,\n",
       " 'बहनें': 728,\n",
       " 'आजकल': 729,\n",
       " 'ढूँढने': 730,\n",
       " 'विमान': 731,\n",
       " 'सुन': 732,\n",
       " 'पहली': 733,\n",
       " 'सामान': 734,\n",
       " 'केवल': 735,\n",
       " 'पैरिस': 736,\n",
       " 'कई': 737,\n",
       " 'ख़रीद': 738,\n",
       " 'चोर': 739,\n",
       " 'दोस्तों': 740,\n",
       " 'रह': 741,\n",
       " 'मुताबिक': 742,\n",
       " 'क्रिकेट': 743,\n",
       " 'शौकिया': 744,\n",
       " 'खिलाड़ी': 745,\n",
       " 'कर्मचारियों': 746,\n",
       " 'ब्रिज': 747,\n",
       " 'अम्रीका': 748,\n",
       " 'देते': 749,\n",
       " 'सरकार': 750,\n",
       " 'परीक्षा': 751,\n",
       " 'वाह': 752,\n",
       " 'जाओ': 753,\n",
       " 'भर': 754,\n",
       " 'पंछी': 755,\n",
       " 'बोर': 756,\n",
       " 'ठंड': 757,\n",
       " 'मालूम': 758,\n",
       " 'गाते': 759,\n",
       " 'बैठिए।': 760,\n",
       " 'नया': 761,\n",
       " 'केक': 762,\n",
       " 'मुबारक': 763,\n",
       " 'समझता': 764,\n",
       " 'मान': 765,\n",
       " 'व्यस्थ': 766,\n",
       " 'बिल्ली': 767,\n",
       " 'सकतीं': 768,\n",
       " 'नक्शा': 769,\n",
       " 'गोली': 770,\n",
       " 'नए': 771,\n",
       " 'धोओ।': 772,\n",
       " 'पागल': 773,\n",
       " 'टोपी': 774,\n",
       " 'पति': 775,\n",
       " 'उल्टी': 776,\n",
       " 'नसीब': 777,\n",
       " 'रोना': 778,\n",
       " 'सिखा': 779,\n",
       " 'चावल': 780,\n",
       " 'बोलता': 781,\n",
       " 'कौनसी': 782,\n",
       " 'नीली': 783,\n",
       " 'शादीशुदा': 784,\n",
       " 'रेडियो': 785,\n",
       " 'वो': 786,\n",
       " 'महंगी': 787,\n",
       " 'रेलगाड़ी': 788,\n",
       " 'कौआ': 789,\n",
       " 'तोड़': 790,\n",
       " 'बनाया': 791,\n",
       " 'पुरानी': 792,\n",
       " 'बताने': 793,\n",
       " 'शराब': 794,\n",
       " 'बेसबॉल': 795,\n",
       " 'लिखना': 796,\n",
       " 'कमीज़': 797,\n",
       " 'टैक्स': 798,\n",
       " 'पेनसिल': 799,\n",
       " 'समुंदर': 800,\n",
       " 'कामयाबी': 801,\n",
       " 'गुस्सा': 802,\n",
       " 'उधार': 803,\n",
       " 'होना': 804,\n",
       " 'प्रतीक्षा': 805,\n",
       " 'ज़ुकाम': 806,\n",
       " 'पहने': 807,\n",
       " 'भूत': 808,\n",
       " 'लगतीं': 809,\n",
       " 'तेज़ी': 810,\n",
       " 'रख': 811,\n",
       " 'अंडे': 812,\n",
       " 'व्यापार': 813,\n",
       " 'थोड़े': 814,\n",
       " 'हमको': 815,\n",
       " 'घोड़े': 816,\n",
       " 'उनका': 817,\n",
       " 'छलाँग': 818,\n",
       " 'इसको': 819,\n",
       " 'गेंद': 820,\n",
       " 'बैठ': 821,\n",
       " 'बताओ': 822,\n",
       " 'छूट': 823,\n",
       " 'उनको': 824,\n",
       " 'जैसी': 825,\n",
       " 'बोलो।': 826,\n",
       " 'लेता': 827,\n",
       " 'खटखटाया।': 828,\n",
       " 'डाला।': 829,\n",
       " 'बुखार': 830,\n",
       " 'उठता': 831,\n",
       " 'नौ': 832,\n",
       " 'ठंडा': 833,\n",
       " 'पियानो': 834,\n",
       " 'तेल': 835,\n",
       " 'उतना': 836,\n",
       " 'निर्णय': 837,\n",
       " 'फ़ुटबॉल': 838,\n",
       " 'इलज़ाम': 839,\n",
       " 'गिलास': 840,\n",
       " 'बजने': 841,\n",
       " 'लकड़ी': 842,\n",
       " 'चार': 843,\n",
       " 'कैंसर': 844,\n",
       " 'उपन्यास': 845,\n",
       " 'मुलाक़ात': 846,\n",
       " 'टैक्सी': 847,\n",
       " 'ध्यान': 848,\n",
       " 'इनकार': 849,\n",
       " 'कीमत': 850,\n",
       " 'किनारे': 851,\n",
       " 'सज़ा': 852,\n",
       " 'गाड़ियाँ': 853,\n",
       " 'दिखाई': 854,\n",
       " 'होती।': 855,\n",
       " 'मुसीबत': 856,\n",
       " 'देखकर': 857,\n",
       " 'छाया': 858,\n",
       " 'धन्यवाद।': 859,\n",
       " 'बनी': 860,\n",
       " 'रोने': 861,\n",
       " 'पड़ा।': 862,\n",
       " 'बीस': 863,\n",
       " 'रक्षा': 864,\n",
       " 'जगह': 865,\n",
       " 'होगी': 866,\n",
       " 'फूलों': 867,\n",
       " 'खाते': 868,\n",
       " 'छोड़ने': 869,\n",
       " 'पड़ता।': 870,\n",
       " 'समान': 871,\n",
       " 'बॉस': 872,\n",
       " 'सर': 873,\n",
       " 'चोट': 874,\n",
       " 'दोगे': 875,\n",
       " 'अगली': 876,\n",
       " 'बर्ताव': 877,\n",
       " 'ओसाका': 878,\n",
       " 'बर्बादी': 879,\n",
       " 'धीमी': 880,\n",
       " 'बचा': 881,\n",
       " 'लिए।': 882,\n",
       " 'मना': 883,\n",
       " 'खेलने': 884,\n",
       " 'चाहेंगे': 885,\n",
       " 'दफ़्तर': 886,\n",
       " 'सुथरा': 887,\n",
       " 'भाषण': 888,\n",
       " 'खेल': 889,\n",
       " 'खूबसूरत': 890,\n",
       " 'नतीजे': 891,\n",
       " 'खेत': 892,\n",
       " 'नानी': 893,\n",
       " 'सीधे': 894,\n",
       " 'इटली': 895,\n",
       " 'अलावा': 896,\n",
       " 'जनसंख्या': 897,\n",
       " 'सी': 898,\n",
       " 'चीज़ें': 899,\n",
       " 'मक्खन': 900,\n",
       " 'उठाया।': 901,\n",
       " 'सोमवार': 902,\n",
       " 'घंटों': 903,\n",
       " 'जाता।': 904,\n",
       " 'सपने': 905,\n",
       " 'डाक': 906,\n",
       " 'मानते': 907,\n",
       " 'उनसे': 908,\n",
       " 'सोते': 909,\n",
       " 'पत्र': 910,\n",
       " 'खड़ी': 911,\n",
       " 'तुमको': 912,\n",
       " 'बेचैन': 913,\n",
       " 'कविता': 914,\n",
       " 'निकालते': 915,\n",
       " 'छत': 916,\n",
       " 'रहा।': 917,\n",
       " 'सूरज': 918,\n",
       " 'बातचीत': 919,\n",
       " 'विश्व': 920,\n",
       " 'कब्रिस्तान': 921,\n",
       " 'स्टॉप': 922,\n",
       " 'ऐसे': 923,\n",
       " 'देता': 924,\n",
       " 'जल्दबाज़ी': 925,\n",
       " 'अखबार': 926,\n",
       " 'पालन': 927,\n",
       " 'रूप': 928,\n",
       " 'उत्तर': 929,\n",
       " 'कहा।': 930,\n",
       " 'शर्म': 931,\n",
       " 'पचास': 932,\n",
       " 'तस्वीरें': 933,\n",
       " 'अस्पताल': 934,\n",
       " 'कम्प्यूटर': 935,\n",
       " 'इतनी': 936,\n",
       " 'दिल्ली': 937,\n",
       " 'मीटिंग': 938,\n",
       " 'चलती': 939,\n",
       " 'उठते': 940,\n",
       " 'वसीयत': 941,\n",
       " 'जानना': 942,\n",
       " 'हैरान': 943,\n",
       " 'जेब': 944,\n",
       " 'पकड़ा': 945,\n",
       " 'मौके': 946,\n",
       " 'बुलाया': 947,\n",
       " 'कम्पनी': 948,\n",
       " 'कॉलेज': 949,\n",
       " 'जाया': 950,\n",
       " 'चाहे': 951,\n",
       " 'जाए': 952,\n",
       " 'लायक': 953,\n",
       " 'देगी।': 954,\n",
       " 'कहने': 955,\n",
       " 'पाया': 956,\n",
       " 'राज़ी': 957,\n",
       " 'बत्तियाँ': 958,\n",
       " 'पहचानता': 959,\n",
       " 'इंग्लैंड': 960,\n",
       " 'बूढ़ा': 961,\n",
       " 'थीं।': 962,\n",
       " 'जिसे': 963,\n",
       " 'दिख': 964,\n",
       " 'रास्ते': 965,\n",
       " 'पुस्तकालय': 966,\n",
       " 'माता': 967,\n",
       " 'जिससे': 968,\n",
       " 'सोचता': 969,\n",
       " 'पड़ता': 970,\n",
       " 'टेरेसा': 971,\n",
       " 'समझे': 972,\n",
       " 'करना।': 973,\n",
       " 'मौज': 974,\n",
       " 'बेहोश': 975,\n",
       " 'शाबाश': 976,\n",
       " 'किसको': 977,\n",
       " 'किसे': 978,\n",
       " 'पीछा': 979,\n",
       " 'तैर': 980,\n",
       " 'ताकतवर': 981,\n",
       " 'गणित': 982,\n",
       " 'जाना।': 983,\n",
       " 'हार': 984,\n",
       " 'खोलो।': 985,\n",
       " 'आईए।': 986,\n",
       " 'दोबारा': 987,\n",
       " 'दाढ़ी': 988,\n",
       " 'हों': 989,\n",
       " 'चुकीं': 990,\n",
       " 'करेंगे।': 991,\n",
       " 'आना।': 992,\n",
       " 'भागते': 993,\n",
       " 'अरबी': 994,\n",
       " 'बदतमीज़': 995,\n",
       " 'दौड़ने': 996,\n",
       " 'काला': 997,\n",
       " 'कैफ़े': 998,\n",
       " 'आसपास': 999,\n",
       " 'हसीना': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_t.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hi_fC8V3KXnR"
   },
   "source": [
    "### Compare different sentences length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaoE7nULKXnS"
   },
   "outputs": [],
   "source": [
    "#Source Language sentences\n",
    "print('Length for sentence number 100: ', len(encoder_seq[100]))\n",
    "print('Length for sentence number 2000: ', len(encoder_seq[2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFRd3s8XKXnV"
   },
   "outputs": [],
   "source": [
    "#Target Language sentences\n",
    "print('Length for sentence number 100: ', len(decoder_seq[100]))\n",
    "print('Length for sentence number 2000: ', len(decoder_seq[2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-IatvBFKXnY"
   },
   "source": [
    "### How do we make it same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNZ8AeLKKXnZ"
   },
   "source": [
    "### Padding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfKDl8IAKXna"
   },
   "outputs": [],
   "source": [
    "#Source sentences\n",
    "encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n",
    "                                                                   maxlen=max_encoder_seq_length, #22\n",
    "                                                                   padding='pre')\n",
    "\n",
    "#Target Sentences\n",
    "decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, \n",
    "                                                                   maxlen=max_decoder_seq_length, #27\n",
    "                                                                   padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1576303692517,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "ZLTwqyLyKXnc",
    "outputId": "2e9f066b-b5bc-4f2c-8ee6-881c55defddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data shape:  (2785, 22)\n",
      "Target data shape:  (2785, 27)\n"
     ]
    }
   ],
   "source": [
    "print('Source data shape: ', encoder_input_data.shape)\n",
    "print('Target data shape: ', decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHIXCliIKXne"
   },
   "outputs": [],
   "source": [
    "encoder_text[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgBriKXSKXnf"
   },
   "outputs": [],
   "source": [
    "encoder_input_data[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJMPcCflKXnh"
   },
   "outputs": [],
   "source": [
    "decoder_text[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QokbLugoKXnj"
   },
   "outputs": [],
   "source": [
    "decoder_input_data[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZoH9-bJKXnk"
   },
   "source": [
    "#### Integer to Word converter for Decoder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuoP4YMeKXnl"
   },
   "outputs": [],
   "source": [
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3983,
     "status": "ok",
     "timestamp": 1576304685251,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "yVOpq75gKXnm",
    "outputId": "7a8ce172-9207-47e7-a437-60bfb3694021"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'की'"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word_decoder[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPTsEs-DKXno"
   },
   "source": [
    "### Building Decoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2164,
     "status": "ok",
     "timestamp": 1576304697553,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "T0Edu4F4KXnp",
    "outputId": "f8440ac6-b5bc-4edd-baee-355bf61a24e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2785, 27)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtrzQgsDKXns"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Initialize array\n",
    "decoder_target_data = np.zeros((decoder_input_data.shape[0], \n",
    "                                decoder_input_data.shape[1]))\n",
    "\n",
    "#Shift Target output by one word\n",
    "for i in range(decoder_input_data.shape[0]):\n",
    "    for j in range(1,decoder_input_data.shape[1]):\n",
    "        decoder_target_data[i][j-1] = decoder_input_data[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVjADS08KXnt"
   },
   "outputs": [],
   "source": [
    "#decoder_t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5V8wz3XKXnv"
   },
   "outputs": [],
   "source": [
    "#<start> yeh kitab hai <end>\n",
    "#Yeh kitab hai <end> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1576304741195,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "gL9a-mGTKXn2",
    "outputId": "af542674-2fe0-45bd-d292-9a07f3c1ac75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 752,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1576304747044,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "R-norMzYKXn5",
    "outputId": "8a90fbb1-c256-4663-e380-62398bbbe260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([752.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHH_em9TKXn6"
   },
   "source": [
    "#### Convert target data in one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUXNoSeHKXn7"
   },
   "outputs": [],
   "source": [
    "#Initialize one hot encoding array\n",
    "decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], #number of sentences\n",
    "                                   decoder_input_data.shape[1], #Number of words in each sentence\n",
    "                                   len(decoder_t.word_index)+1)) #Vocab size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1576304816290,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "YvDD6DZrKXn9",
    "outputId": "6c1c5b46-1781-4516-822a-34e40704c577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2785, 27, 2975)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5h-PeIGKXoA"
   },
   "outputs": [],
   "source": [
    "#Build one hot encoded array\n",
    "for i in range(decoder_target_data.shape[0]):\n",
    "    for j in range(decoder_target_data.shape[1]):\n",
    "        decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n",
    "                                                                     num_classes=len(decoder_t.word_index)+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Emzjo90KXoB"
   },
   "outputs": [],
   "source": [
    "decoder_target_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOAOZrxBgK5c"
   },
   "outputs": [],
   "source": [
    "decoder_target_one_hot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6BNPWZ_KXoD"
   },
   "source": [
    "### Building the Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q05uAVLXKXoD"
   },
   "outputs": [],
   "source": [
    "#Define config parameters\n",
    "encoder_embedding_size = 50\n",
    "decoder_embedding_size = 50\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9M9eJGmSKXoF"
   },
   "source": [
    "#### Build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJIqwk7aKkJ9"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1576306561384,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "x5P1hzBqKXoG",
    "outputId": "98ac3831-f6f5-4c7c-95da-158fad7ee2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "#Input Layer\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "\n",
    "#Embedding layer\n",
    "encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, \n",
    "                                              encoder_embedding_size)\n",
    "\n",
    "#Get embedding layer output by feeding inputs\n",
    "encoder_embedding_output = encoder_embedding(encoder_inputs)\n",
    "\n",
    "#LSTM Layer and its output\n",
    "x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n",
    "\n",
    "#Build a list to feed Decoder - Sentence Embedding\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrcqxcfhKXoH"
   },
   "outputs": [],
   "source": [
    "encoder_embedding_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJvG6HRdKXoM"
   },
   "source": [
    "#### Build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LQEt7zPKXoM"
   },
   "outputs": [],
   "source": [
    "#Decode input - padded Target sentences\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "\n",
    "#Decoder Embedding layer\n",
    "decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, \n",
    "                                              decoder_embedding_size)\n",
    "\n",
    "#Embedding layer output\n",
    "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
    "\n",
    "#Decoder RNN\n",
    "decoder_rnn = tf.keras.layers.LSTM(rnn_units, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True)\n",
    "\n",
    "#Decoder RNN Output, State initialization from Encoder states\n",
    "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
    "x,_,_ = decoder_rnn(decoder_embedding_output, \n",
    "                    initial_state=encoder_states)\n",
    "\n",
    "#Output Layer\n",
    "decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, #+1 to make sure one-hot encoding works for highest index value\n",
    "                                      activation='softmax')\n",
    "\n",
    "#Output of Dense layer\n",
    "decoder_outputs = decoder_dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MP3Xbx6v3qT"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byZkwGJNKXoR"
   },
   "outputs": [],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kabGUQ4KXoT"
   },
   "source": [
    "### Build Model using both Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkJyiM7uKXoT"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n",
    "                              decoder_outputs) #Output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1576306893481,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "A5IvOy0tKXoW",
    "outputId": "471f6d78-fe3e-42de-9bd7-08e308664bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/truediv:0' shape=(?, ?, 2975) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-Yfmp3AKXoY"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I30VxT7LKXoa"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1576306940342,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "WM-iPyu_Jbix",
    "outputId": "dec52a86-cdbf-4d44-f0fe-19aa373d5cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     118850      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     148750      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 314368      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  314368      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2975)   764575      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,660,911\n",
      "Trainable params: 1,660,911\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608593,
     "status": "ok",
     "timestamp": 1576307646220,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "W-uw8R3_KXoa",
    "outputId": "51617748-c4fa-4b7f-b4e4-2330583a796f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2228 samples, validate on 557 samples\n",
      "Epoch 1/20\n",
      "2228/2228 [==============================] - 33s 15ms/sample - loss: 3.7562 - val_loss: 2.9727\n",
      "Epoch 2/20\n",
      "2228/2228 [==============================] - 31s 14ms/sample - loss: 1.6351 - val_loss: 2.9699\n",
      "Epoch 3/20\n",
      "2228/2228 [==============================] - 31s 14ms/sample - loss: 1.5915 - val_loss: 3.0044\n",
      "Epoch 4/20\n",
      "2228/2228 [==============================] - 33s 15ms/sample - loss: 1.5544 - val_loss: 3.0222\n",
      "Epoch 5/20\n",
      "2228/2228 [==============================] - 31s 14ms/sample - loss: 1.5034 - val_loss: 2.8632\n",
      "Epoch 6/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.4410 - val_loss: 2.7229\n",
      "Epoch 7/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.3990 - val_loss: 2.7271\n",
      "Epoch 8/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.3702 - val_loss: 2.7269\n",
      "Epoch 9/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.3474 - val_loss: 2.7417\n",
      "Epoch 10/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.3277 - val_loss: 2.7043\n",
      "Epoch 11/20\n",
      "2228/2228 [==============================] - 29s 13ms/sample - loss: 1.3096 - val_loss: 2.6976\n",
      "Epoch 12/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.2944 - val_loss: 2.6804\n",
      "Epoch 13/20\n",
      "2228/2228 [==============================] - 31s 14ms/sample - loss: 1.2801 - val_loss: 2.6479\n",
      "Epoch 14/20\n",
      "2228/2228 [==============================] - 30s 14ms/sample - loss: 1.2658 - val_loss: 2.6692\n",
      "Epoch 15/20\n",
      "2228/2228 [==============================] - 30s 14ms/sample - loss: 1.2530 - val_loss: 2.6271\n",
      "Epoch 16/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.2398 - val_loss: 2.6485\n",
      "Epoch 17/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.2265 - val_loss: 2.6665\n",
      "Epoch 18/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.2140 - val_loss: 2.6532\n",
      "Epoch 19/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.2024 - val_loss: 2.6516\n",
      "Epoch 20/20\n",
      "2228/2228 [==============================] - 30s 13ms/sample - loss: 1.1912 - val_loss: 2.6967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc11c1465f8>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], \n",
    "          decoder_target_one_hot,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDZlu731KXob"
   },
   "source": [
    "### Save the model for later reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpUOjtksKXoc"
   },
   "outputs": [],
   "source": [
    "model.save('seq2seq_training_translation.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guuaYKaDKXod"
   },
   "source": [
    "# Building Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-tXkDaqKXod"
   },
   "source": [
    "### Build the Encoder Model to predict Encoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdM2QenRKXod"
   },
   "outputs": [],
   "source": [
    "encoder_model = tf.keras.models.Model(encoder_inputs, #Padded input sequences\n",
    "                                      encoder_states) #Hidden state and Cell state at last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jj07QPsc941I"
   },
   "outputs": [],
   "source": [
    "encoder_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBvy3uDnKXof"
   },
   "source": [
    "### Build the Decoder Model \n",
    "<p/>\n",
    "\n",
    "<ol><li>Define Input for both 'h' state and 'c' state initialization </li>\n",
    "<li>Get Decoder RNN outputs along with h and c state</li>\n",
    "<li>Get Decoder Dense layer output</li>\n",
    "        <li>Build Model</li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ohsoa5J_KXof"
   },
   "source": [
    "##### Step 1 - Define Input for both 'h' state and 'c' state initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNlm9ufvKXoh"
   },
   "outputs": [],
   "source": [
    "#Hidden state input\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n",
    "\n",
    "#Cell state input\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n",
    "\n",
    "#Putting it together\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzbTg44oKXoi"
   },
   "source": [
    "##### Step 2 - Get Decoder RNN outputs along with h and c state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVHzmr1hKXoi"
   },
   "outputs": [],
   "source": [
    "#Get Embedding layer output\n",
    "x = decoder_embedding(decoder_inputs)\n",
    "\n",
    "#We will use the layer which we trained earlier\n",
    "rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n",
    "\n",
    "#Why do we need this?\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gX884-sKXoj"
   },
   "source": [
    "##### Step 3 - Get Decoder Dense layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lj9ZkJh0KXoj"
   },
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_dense(rnn_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HiEPMqnKXok"
   },
   "source": [
    "##### Step 4 - Build Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExV0PWSPKXol"
   },
   "outputs": [],
   "source": [
    "decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs,  #Model inputs\n",
    "                                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnKbxenGKXom"
   },
   "source": [
    "# Predicting output from Seq2Seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFsy3KR7KXon"
   },
   "source": [
    "##### Build a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIwVWxXXKXon"
   },
   "outputs": [],
   "source": [
    "decoder_t.word_index['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nR2H6c3YKXop"
   },
   "outputs": [],
   "source": [
    "int_to_word_decoder[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEG8fmnbKXop"
   },
   "outputs": [],
   "source": [
    "def decode_sentence(input_sequence):\n",
    "    \n",
    "    #Get the encoder state values - Sentence embedding\n",
    "    decoder_initial_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    num_of_predictions = 0\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
    "                                                        decoder_initial_states_value)\n",
    "        \n",
    "        #Get the predicted word index with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter index\n",
    "        predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or num_of_predictions > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "        \n",
    "        num_of_predictions += 1\n",
    "        \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value for decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jtZM8iaKXoq"
   },
   "source": [
    "##### Call Prediction function on a random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1515,
     "status": "ok",
     "timestamp": 1576308757256,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "perGUle1KXor",
    "outputId": "7c8e2d6b-b153-4264-ea3e-ea6f56064011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "Input sentence:  He has many history books.\n",
      "Predicted sentence:  मुझे एक एक लिए बहुत नहीं है।\n",
      "--------\n",
      "Input sentence:  He hesitated for a moment.\n",
      "Predicted sentence:  मुझे बहुत बहुत है।\n",
      "--------\n",
      "Input sentence:  He is one of my neighbors.\n",
      "Predicted sentence:  मुझे अपने एक लिए बहुत नहीं है।\n",
      "--------\n",
      "Input sentence:  He likes his school a lot.\n",
      "Predicted sentence:  मुझे एक एक लिए बहुत नहीं है।\n",
      "--------\n",
      "Input sentence:  He makes fun of everybody.\n",
      "Predicted sentence:  मुझे एक बहुत बहुत है।\n"
     ]
    }
   ],
   "source": [
    "#Generate a random number\n",
    "start_num = np.random.randint(0, high=len(encoder_text) - 10)\n",
    "\n",
    "#Predict model output for 5 sentences\n",
    "for i in range(start_num, start_num + 5):\n",
    "    input_seq = encoder_input_data[i : i+1]\n",
    "    predicted_sentence = decode_sentence(input_seq)\n",
    "    print('--------')\n",
    "    print ('Input sentence: ', encoder_text[i])\n",
    "    print ('Predicted sentence: ', predicted_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqi_-4Y0KXos"
   },
   "source": [
    "##### Save encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TbJoYhJKXos"
   },
   "outputs": [],
   "source": [
    "#Compile models to avoid error\n",
    "encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "\n",
    "#Save the models\n",
    "encoder_model.save('seq2seq_encoder_eng_hin.hd5')  #Encoder model\n",
    "decoder_model.save('seq2seq_decoder_eng_hin.hd5')  #Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skLA1matKXot"
   },
   "source": [
    "##### Save encoder and decoder tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCLkBUL7KXou"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(encoder_t,open('encoder_tokenizer_eng','wb'))\n",
    "pickle.dump(decoder_t,open('decoder_tokenizer_hin','wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1. Seq2Seq LSTM Model - Translation_with_prediction.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
