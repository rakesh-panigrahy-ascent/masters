{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5csO-wPPKXmw"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "W0ttJZT3KXmx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80Pcvzu4KXmz"
   },
   "source": [
    "### Read the data\n",
    "<font size=\"2\">Data for this exercise can be downloaded from http://www.manythings.org/anki/</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "vQBFJRquKXm0"
   },
   "outputs": [],
   "source": [
    "#You can use wget to download the file directly\n",
    "!wget http://www.manythings.org/anki/hin-eng.zip --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "E4V6ZdyClsfE"
   },
   "outputs": [],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "JtMmO7f0aJdg"
   },
   "outputs": [],
   "source": [
    "!unzip hin-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "jPUrsgVkaPi7"
   },
   "outputs": [],
   "source": [
    "!cat hin.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "tooO9pGrKXm2"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "\n",
    "#Read the zip file\n",
    "zf = zipfile.ZipFile('data/hin-eng.zip', 'r')\n",
    "\n",
    "#Extract data from zip file\n",
    "data = ''\n",
    "with zf.open('hin.txt') as readfile:\n",
    "  for line in io.TextIOWrapper(readfile, 'utf-8'):\n",
    "    data += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "fiQ2ROWgKXm3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430654"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "9Ir1xfYwKXm5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"minshirui) & #482431 (minshirui)\\nIt's not my fault.\\tमेरी ग़लती नहीं है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #321324 (CK) & #609869 (minshirui)\\nIt's starting now.\\tशुरू हो रहा है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #33137 (CK) & #480236 (minshirui)\\nMy bag was stolen.\\tमेरा बस्ता चोरी हो गया था।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #35155 (CK) & #588618 (minshirui)\\nMy eyes are tired.\\tमेरी आँखें थक गईं हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #507513 (CK) & #588532 (minshirui)\\nNo one's in sight.\\tआसपास कोई नहीं है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2091110 (CK) & #3216498 (anubhav93)\\nPut your hands up!\\tहाथ ऊपर करो!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #265926 (CK) & #443082 (minshirui)\\nShe began to sing.\\tवह गाने लगी।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #312881 (CK) & #514032 (minshirui)\\nShe has blue eyes.\\tउसकी नीली आँखें हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #472087 (CK) & #588558 (minshirui)\\nShe isn't married.\\tवह शादीशुदा नहीं है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #313424 (CK) & #498107 (minshirui)\\nTell me the truth.\\tमुझे सच्चाई बताओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #321441 (CK) & #505259 (minshirui)\\nThat was my fault.\\tवह मेरी ग़लती थी।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2648438 (CK) & #450969 (minshirui)\\nThe earth rotates.\\tपृथ्वी घूमती है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #277131 (CM) & #516620 (minshirui)\\nTom may invite us.\\tटॉम हमें आमंत्रित कर सकता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #8590150 (CK) & #8889314 (simranbansal)\\nTry it once again.\\tएक बार फिरसे कोशिश करो।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #31497 (CK) & #505400 (minshirui)\\nTry it once again.\\tएक बार और प्रयत्न करो।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #31497 (CK) & #505401 (minshirui)\\nTurn on the radio.\\tरेडियो को चालू करो।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #29763 (CK) & #588613 (minshirui)\\nWe don't know her.\\tहम उसे नहीं जानते हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #439337 (CK) & #483800 (minshirui)\\nWe don't know him.\\tहम उसे नहीं जानते हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #383016 (CK) & #483800 (minshirui)\\nWe have good news.\\tहमारे पास खुशखबर है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #66695 (CK) & #516840 (minshirui)\\nWe're against war.\\tहम जंग के ख़िलाफ़ हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #8066849 (CK) & #451241 (minshirui)\\nWe're against war.\\tहम युद्ध का विरोध करते हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #8066849 (CK) & #451242 (minshirui)\\nWhat is happiness?\\tखुशी क्या होती है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #404565 (telsfbay) & #505276 (minshirui)\\nWhat is happiness?\\tसुख क्या होता है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #404565 (telsfbay) & #505277 (minshirui)\\nWhat is your name?\\tआपका नाम क्या है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #70623 (sacredceltic) & #443217 (minshirui)\\nWhat's the matter?\\tमुश्किल क्या है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #394894 (Dorenda) & #485557 (minshirui)\\nWhen did you meet?\\tआप कब मिले?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2273929 (CK) & #10270852 (simranbansal)\\nWhen did you meet?\\tतू कब मिला?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2273929 (CK) & #10270853 (simranbansal)\\nWhere do you live?\\tआप कहाँ रहते हैं?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #370708 (saeb) & #451337 (minshirui)\\nWhere do you live?\\tतुम कहाँ रहते हो?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #370708 (saeb) & #451338 (minshirui)\\nWhere do you live?\\tतू कहाँ रहता है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #370708 (saeb) & #451339 (minshirui)\\nWhere do you live?\\tतुम कहाँ रहती हो?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #370708 (saeb) & #451340 (minshirui)\\nWhere do you live?\\tतू कहाँ रहती है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #370708 (saeb) & #451341 (minshirui)\\nWhere is the book?\\tवह किताब कहाँ है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #43928 (CK) & #4907692 (yashtib1995)\\nWhere's the beach?\\tसमुद्र तट कहां है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5899588 (CK) & #4907679 (yashtib1995)\\nWho made this pie?\\tयह पाय किसने बनाई है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #276192 (CK) & #511171 (minshirui)\\nYes. That's right.\\tहाँ। यह सही है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433817 (CK) & #588551 (minshirui)\\nYou are in my way.\\tतू मेरे रास्ते में आ रहा है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1296 (CK) & #11371146 (Sorcien)\\nYou have to leave.\\tतुम्हें जाना होगा।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #454043 (mamat) & #483902 (minshirui)\\nAre you busy today?\\tतुम आज बिज़ी हो क्या?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #242434 (CK) & #477703 (minshirui)\\nAre you busy today?\\tतुम्हारे पास आज समय है क्या?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #242434 (CK) & #477704 (minshirui)\\nCan we have a talk?\\tहम बात कर सकते हैं क्या?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #63863 (CM) & #487402 (minshirui)\\nCome along with us.\\tहमारे साथ आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433695 (CK) & #485546 (minshirui)\\nDid you sleep well?\\tतुम अच्छे से सोये क्या?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #434494 (lukaszpp) & #483777 (minshirui)\\nDo you remember me?\\tतुम्हें मैं याद हूँ क्या?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #250327 (CK) & #476344 (minshirui)\\nDon't give up hope.\\tउम्मीद मत छोड़ो।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #20606 (brauliobezerra) & #475989 (minshirui)\\nDon't throw stones.\\tपत्थर मत फेंको।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #272226 (CK) & #505359 (minshirui)\\nEveryone likes her.\\tउसे सब पसंद करते हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #430471 (CM) & #451280 (minshirui)\\nEveryone likes him.\\tउसे सब पसंद करते हैं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #451282 (minshirui) & #451280 (minshirui)\\nEveryone was saved.\\tसब बच गए।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #8980662 (CK) & #11370721 (Sorcien)\\nEveryone was saved.\\tसभी को बचा लिया गया।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #8980662 (CK) & #11370726 (Sorcien)\\nHave you gone nuts?\\tतेरी अकल घास चरने गई है क्या?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #487626 (minshirui) & #487624 (minshirui)\\nHe breathed deeply.\\tउसने गहरी साँस ली।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #299963 (CK) & #483855 (minshirui)\\nHe closed his eyes.\\tउसने अपनी आँखें बंद करीं।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #304198 (CK) & #488886 (minshirui)\\nHe cried and cried.\\tवह रोया और और रोया।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #295239 (CH) & #484148 (minshirui)\\nHe is a simple man.\\tवह साधा आदमी है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2915476 (sabretou) & #3538145 (nurendra)\\nHe is sure to come.\\tवह ज़रूर आएगा।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #289676 (CK) & #486351 (minshirui)\\nHe isn't my cousin.\\tवह मेरा चचेरा भाई नहीं है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #297738 (CK) & #463380 (minshirui)\\nHe isn't my cousin.\\tवह मेरा ममेरा भाई नहीं है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #297738 (CK) & #463381 (minshirui)\\nHe waited his turn.\\tउसने अपनी बारी का इंतेज़ार किया।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #298772 (CK) & #506493 (minshirui)\\nHe works at a bank.\\tवह बैंक में काम करता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #416365 (phrasemix) & #515396 (minshirui)\\nHe's a good person.\\tवह अच्छा इनसान है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2368 (CK) & #588590 (minshirui)\\nI admit my mistake.\\tमैं अपनी ग़लती मानता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #258278 (CK) & #511740 (minshirui)\\nI can read English.\\tमैं अंग्रेज़ी पढ़ सकता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #867128 (verogc) & #449349 (minshirui)\\nI can read English.\\tमैं अंग्रेज़ी पढ़ सकती हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #867128 (verogc) & #449350 (minshirui)\\nI can't believe it!\\tमुझे विश्वास नहीं होता!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2076 (Swift) & #482442 (minshirui)\\nI do what I'm told.\\tमैं वही करता हूं जो मुझे बताया जाता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2315148 (CK) & #8889248 (simranbansal)\\nI do what I'm told.\\tमैं वही करती हूं जो मुझे बताया जाता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2315148 (CK) & #8889249 (simranbansal)\\nI heard him go out.\\tमैंने उसके बाहर जाने की आवाज़ सुनी।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #283847 (CK) & #506459 (minshirui)\\nI know her address.\\tमुझे उसका पता पता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #309397 (CK) & #483991 (minshirui)\\nI know his address.\\tमुझे उसका पता पता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #260661 (CK) & #483991 (minshirui)\\nI know those women.\\tमैं उन औरतों को जानता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #395050 (CK) & #588628 (minshirui)\\nI know your father.\\tमैं तुम्हारे पिताजी को जानता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #257093 (CK) & #588516 (minshirui)\\nI sort of like him.\\tमुझे वह अच्छा सा लगता है।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #33013 (CK) & #486312 (minshirui)\\nI still don't know.\\tमुझे अभी भी नहीं पता।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #952376 (CK) & #446708 (minshirui)\\nI was born in 1960.\\tमैं १९६० में पैदा हुआ था।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #252429 (CK) & #450024 (minshirui)\\nI was born in 1979.\\tमैं १९७९ में पैदा हुआ था।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #252438 (CK) & #498196 (minshirui)\\nI was very thirsty.\\tमैं बहुत प्यासा था।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5859331 (CK) & #8889230 (simranbansal)\\nI was very thirsty.\\tमैं बहुत प्यासा थी।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5859331 (CK) & #8889231 (simranbansal)\\nI watch television.\\tमैं टीवी देखता हूँ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #39164 (CK) & #588571 (minshirui)\\nI worked all night.\\tमैंने पूरी रात काम किया।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #278741 (CK) & #457082 (minshirui)\\nI worked all night.\\tमैंने रातभर काम किया।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #278741 (CK) & #457083 (minshirui)\\nI'll see you later.\\tबाद में मिलेंगे।\\tCC-BY 2.0 (France) Attribution:\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[40000:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6AgsSZ9KXm7"
   },
   "source": [
    "\n",
    "### Extract Source and Target Language pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1Mb8tIyKXm7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We promised.\\tहमने वादा किया।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2107668 (CK) & #8876370 (simranbansal)',\n",
       " \"What's this?\\tयह क्या है?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #413821 (CK) & #443158 (minshirui)\",\n",
       " 'Are you sick?\\tक्या तुम बीमार हो?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #434252 (lukaszpp) & #518699 (minshirui)',\n",
       " 'Bring him in.\\tउसको अंदर ले आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #307895 (CK) & #475932 (minshirui)',\n",
       " 'Come with us.\\tहमारे साथ आओ।\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433696 (CK) & #485546 (minshirui)']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split by newline character\n",
    "data =  data.split('\\n')\n",
    "\n",
    "#Show some Data\n",
    "data[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apuKzGY4KXm9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2981"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnEw_IMEKXm_"
   },
   "source": [
    "### Separate Source and Target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQMiDL45KXnA"
   },
   "outputs": [],
   "source": [
    "encoder_text = [] #Initialize Source language list\n",
    "decoder_text = [] #Initialize Target language list\n",
    "\n",
    "#Iterate over data\n",
    "for line in data:\n",
    "    try:\n",
    "        in_txt, out_txt,_ = line.split('\\t')\n",
    "        encoder_text.append(in_txt)\n",
    "        \n",
    "        # Add tab '<start>' as 'start sequence in target\n",
    "        # And '<end>' as End\n",
    "        decoder_text.append('<start> ' + out_txt + ' <end>')\n",
    "    except:\n",
    "        pass #ignore data which goes into error        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdOMuGbUKXnC"
   },
   "source": [
    "### Separate Source and Target pairs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7K8QDZAbKXnD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We promised.',\n",
       " \"What's this?\",\n",
       " 'Are you sick?',\n",
       " 'Bring him in.',\n",
       " 'Come with us.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DduIsYLKXnF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> हमने वादा किया। <end>',\n",
       " '<start> यह क्या है? <end>',\n",
       " '<start> क्या तुम बीमार हो? <end>',\n",
       " '<start> उसको अंदर ले आओ। <end>',\n",
       " '<start> हमारे साथ आओ। <end>']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_text[100:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1BA2RbOVKXnI"
   },
   "source": [
    "### Tokenize Source language sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OiGqsXDKXnI"
   },
   "outputs": [],
   "source": [
    "#Tokenizer for source language\n",
    "encoder_t = tf.keras.preprocessing.text.Tokenizer()\n",
    "encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1576301591346,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "38f6Yl9HKXnK",
    "outputId": "a810b283-e6b6-4a29-a50f-c3184e0e912e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2410"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1576301629389,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "u8fZ-qAJ96Sw",
    "outputId": "4952319e-19a6-4ca1-b422-a89fb7ed1759"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'i': 2,\n",
       " 'to': 3,\n",
       " 'you': 4,\n",
       " 'a': 5,\n",
       " 'is': 6,\n",
       " 'he': 7,\n",
       " 'of': 8,\n",
       " 'in': 9,\n",
       " 'it': 10,\n",
       " 'my': 11,\n",
       " 'do': 12,\n",
       " 'have': 13,\n",
       " 'me': 14,\n",
       " 'this': 15,\n",
       " 'was': 16,\n",
       " 'that': 17,\n",
       " 'she': 18,\n",
       " 'for': 19,\n",
       " 'are': 20,\n",
       " 'his': 21,\n",
       " 'what': 22,\n",
       " 'your': 23,\n",
       " \"don't\": 24,\n",
       " 'tom': 25,\n",
       " 'we': 26,\n",
       " 'on': 27,\n",
       " 'at': 28,\n",
       " 'will': 29,\n",
       " 'like': 30,\n",
       " 'him': 31,\n",
       " 'her': 32,\n",
       " 'go': 33,\n",
       " 'not': 34,\n",
       " 'be': 35,\n",
       " \"i'm\": 36,\n",
       " 'with': 37,\n",
       " 'how': 38,\n",
       " 'know': 39,\n",
       " 'can': 40,\n",
       " 'and': 41,\n",
       " 'has': 42,\n",
       " 'up': 43,\n",
       " 'there': 44,\n",
       " 'all': 45,\n",
       " 'time': 46,\n",
       " 'very': 47,\n",
       " 'they': 48,\n",
       " \"it's\": 49,\n",
       " 'come': 50,\n",
       " 'want': 51,\n",
       " 'as': 52,\n",
       " 'did': 53,\n",
       " 'here': 54,\n",
       " 'from': 55,\n",
       " 'had': 56,\n",
       " 'please': 57,\n",
       " 'when': 58,\n",
       " 'an': 59,\n",
       " \"can't\": 60,\n",
       " 'by': 61,\n",
       " 'out': 62,\n",
       " 'about': 63,\n",
       " 'going': 64,\n",
       " 'one': 65,\n",
       " 'no': 66,\n",
       " 'get': 67,\n",
       " \"didn't\": 68,\n",
       " 'been': 69,\n",
       " 'am': 70,\n",
       " 'take': 71,\n",
       " 'would': 72,\n",
       " 'if': 73,\n",
       " 'father': 74,\n",
       " 'were': 75,\n",
       " 'day': 76,\n",
       " \"i'll\": 77,\n",
       " 'but': 78,\n",
       " 'book': 79,\n",
       " 'now': 80,\n",
       " 'see': 81,\n",
       " 'money': 82,\n",
       " 'us': 83,\n",
       " 'make': 84,\n",
       " 'help': 85,\n",
       " 'today': 86,\n",
       " 'long': 87,\n",
       " 'two': 88,\n",
       " 'live': 89,\n",
       " 'tomorrow': 90,\n",
       " 'home': 91,\n",
       " 'man': 92,\n",
       " 'good': 93,\n",
       " 'india': 94,\n",
       " 'who': 95,\n",
       " 'must': 96,\n",
       " 'think': 97,\n",
       " 'where': 98,\n",
       " 'our': 99,\n",
       " 'back': 100,\n",
       " 'never': 101,\n",
       " 'so': 102,\n",
       " 'car': 103,\n",
       " 'work': 104,\n",
       " 'should': 105,\n",
       " 'much': 106,\n",
       " 'too': 107,\n",
       " 'these': 108,\n",
       " 'english': 109,\n",
       " 'mary': 110,\n",
       " 'yesterday': 111,\n",
       " 'made': 112,\n",
       " 'house': 113,\n",
       " 'many': 114,\n",
       " 'room': 115,\n",
       " 'every': 116,\n",
       " 'old': 117,\n",
       " 'any': 118,\n",
       " 'than': 119,\n",
       " 'got': 120,\n",
       " 'give': 121,\n",
       " 'may': 122,\n",
       " 'nothing': 123,\n",
       " 'tell': 124,\n",
       " 'always': 125,\n",
       " 'more': 126,\n",
       " 'again': 127,\n",
       " 'why': 128,\n",
       " 'mother': 129,\n",
       " 'went': 130,\n",
       " 'last': 131,\n",
       " 'off': 132,\n",
       " 'dog': 133,\n",
       " 'door': 134,\n",
       " 'could': 135,\n",
       " 'them': 136,\n",
       " \"i've\": 137,\n",
       " 'speak': 138,\n",
       " 'well': 139,\n",
       " 'some': 140,\n",
       " 'people': 141,\n",
       " 'children': 142,\n",
       " 'leave': 143,\n",
       " 'down': 144,\n",
       " 'call': 145,\n",
       " 'train': 146,\n",
       " 'before': 147,\n",
       " 'let': 148,\n",
       " 'new': 149,\n",
       " \"you're\": 150,\n",
       " 'lot': 151,\n",
       " \"isn't\": 152,\n",
       " 'job': 153,\n",
       " 'night': 154,\n",
       " 'put': 155,\n",
       " 'way': 156,\n",
       " 'say': 157,\n",
       " 'away': 158,\n",
       " 'happy': 159,\n",
       " 'doctor': 160,\n",
       " 'turn': 161,\n",
       " 'right': 162,\n",
       " 'doing': 163,\n",
       " 'teacher': 164,\n",
       " 'into': 165,\n",
       " 'school': 166,\n",
       " 'or': 167,\n",
       " 'everyone': 168,\n",
       " 'believe': 169,\n",
       " 'next': 170,\n",
       " 'three': 171,\n",
       " 'ever': 172,\n",
       " 'their': 173,\n",
       " \"let's\": 174,\n",
       " 'answer': 175,\n",
       " 'tired': 176,\n",
       " \"what's\": 177,\n",
       " 'drive': 178,\n",
       " 'open': 179,\n",
       " 'read': 180,\n",
       " \"that's\": 181,\n",
       " 'true': 182,\n",
       " 'use': 183,\n",
       " 'ten': 184,\n",
       " 'play': 185,\n",
       " 'water': 186,\n",
       " 'letter': 187,\n",
       " 'lost': 188,\n",
       " 'left': 189,\n",
       " 'year': 190,\n",
       " 'watch': 191,\n",
       " 'really': 192,\n",
       " 'yet': 193,\n",
       " \"i'd\": 194,\n",
       " 'need': 195,\n",
       " 'few': 196,\n",
       " 'keep': 197,\n",
       " \"couldn't\": 198,\n",
       " 'seen': 199,\n",
       " 'because': 200,\n",
       " 'something': 201,\n",
       " 'once': 202,\n",
       " 'wrong': 203,\n",
       " 'understand': 204,\n",
       " 'big': 205,\n",
       " 'hard': 206,\n",
       " 'feel': 207,\n",
       " 'saw': 208,\n",
       " 'cut': 209,\n",
       " 'problem': 210,\n",
       " 'meet': 211,\n",
       " 'met': 212,\n",
       " 'does': 213,\n",
       " 'little': 214,\n",
       " 'while': 215,\n",
       " 'other': 216,\n",
       " 'such': 217,\n",
       " 'soon': 218,\n",
       " 'tea': 219,\n",
       " 'afraid': 220,\n",
       " 'without': 221,\n",
       " 'looking': 222,\n",
       " 'times': 223,\n",
       " \"won't\": 224,\n",
       " 'said': 225,\n",
       " 'world': 226,\n",
       " 'coming': 227,\n",
       " \"he's\": 228,\n",
       " 'both': 229,\n",
       " 'came': 230,\n",
       " 'try': 231,\n",
       " 'after': 232,\n",
       " 'told': 233,\n",
       " 'friends': 234,\n",
       " 'books': 235,\n",
       " 'girl': 236,\n",
       " \"doesn't\": 237,\n",
       " 'used': 238,\n",
       " 'japan': 239,\n",
       " 'alone': 240,\n",
       " 'love': 241,\n",
       " \"we're\": 242,\n",
       " 'bed': 243,\n",
       " 'ask': 244,\n",
       " 'around': 245,\n",
       " 'likes': 246,\n",
       " 'life': 247,\n",
       " 'already': 248,\n",
       " 'talking': 249,\n",
       " 'bought': 250,\n",
       " 'wanted': 251,\n",
       " 'mind': 252,\n",
       " 'gave': 253,\n",
       " 'years': 254,\n",
       " \"o'clock\": 255,\n",
       " 'able': 256,\n",
       " 'brother': 257,\n",
       " 'morning': 258,\n",
       " 'knows': 259,\n",
       " 'birthday': 260,\n",
       " 'buy': 261,\n",
       " 'early': 262,\n",
       " 'running': 263,\n",
       " 'friend': 264,\n",
       " 'first': 265,\n",
       " 'news': 266,\n",
       " 'tried': 267,\n",
       " 'another': 268,\n",
       " 'caught': 269,\n",
       " 'just': 270,\n",
       " 'easy': 271,\n",
       " 'looked': 272,\n",
       " 'river': 273,\n",
       " 'party': 274,\n",
       " 'comes': 275,\n",
       " 'station': 276,\n",
       " 'own': 277,\n",
       " 'six': 278,\n",
       " 'between': 279,\n",
       " 'usually': 280,\n",
       " 'smoking': 281,\n",
       " 'wants': 282,\n",
       " 'days': 283,\n",
       " 'month': 284,\n",
       " 'saying': 285,\n",
       " 'fun': 286,\n",
       " 'broke': 287,\n",
       " 'cold': 288,\n",
       " 'drink': 289,\n",
       " 'things': 290,\n",
       " 'stay': 291,\n",
       " 'study': 292,\n",
       " 'look': 293,\n",
       " 'person': 294,\n",
       " 'name': 295,\n",
       " 'bad': 296,\n",
       " 'anything': 297,\n",
       " 'abroad': 298,\n",
       " 'married': 299,\n",
       " 'talk': 300,\n",
       " 'small': 301,\n",
       " 'felt': 302,\n",
       " 'city': 303,\n",
       " 'sister': 304,\n",
       " 'box': 305,\n",
       " 'health': 306,\n",
       " 'waiting': 307,\n",
       " 'shoes': 308,\n",
       " 'week': 309,\n",
       " 'walk': 310,\n",
       " 'five': 311,\n",
       " 'happened': 312,\n",
       " 'hair': 313,\n",
       " 'asked': 314,\n",
       " 'coffee': 315,\n",
       " 'difficult': 316,\n",
       " 'almost': 317,\n",
       " 'tv': 318,\n",
       " 'medicine': 319,\n",
       " 'accident': 320,\n",
       " 'cannot': 321,\n",
       " 'hours': 322,\n",
       " 'took': 323,\n",
       " 'done': 324,\n",
       " 'boy': 325,\n",
       " 'busy': 326,\n",
       " 'town': 327,\n",
       " 'only': 328,\n",
       " 'dinner': 329,\n",
       " 'stop': 330,\n",
       " 'mine': 331,\n",
       " 'nice': 332,\n",
       " 'hurry': 333,\n",
       " 'eyes': 334,\n",
       " 'sure': 335,\n",
       " 'questions': 336,\n",
       " 'rain': 337,\n",
       " 'found': 338,\n",
       " 'better': 339,\n",
       " 'mistakes': 340,\n",
       " 'enough': 341,\n",
       " 'wait': 342,\n",
       " 'food': 343,\n",
       " 'die': 344,\n",
       " 'someone': 345,\n",
       " 'baby': 346,\n",
       " 'watching': 347,\n",
       " 'eight': 348,\n",
       " 'afternoon': 349,\n",
       " 'idea': 350,\n",
       " 'failed': 351,\n",
       " 'exam': 352,\n",
       " \"you'll\": 353,\n",
       " 'parents': 354,\n",
       " 'kind': 355,\n",
       " 'possible': 356,\n",
       " 'forgot': 357,\n",
       " 'fly': 358,\n",
       " 'fire': 359,\n",
       " 'swim': 360,\n",
       " 'sit': 361,\n",
       " 'nobody': 362,\n",
       " 'fish': 363,\n",
       " 'hot': 364,\n",
       " 'ill': 365,\n",
       " 'heard': 366,\n",
       " 'noise': 367,\n",
       " 'ready': 368,\n",
       " 'story': 369,\n",
       " \"haven't\": 370,\n",
       " 'sleep': 371,\n",
       " 'works': 372,\n",
       " 'later': 373,\n",
       " 'kept': 374,\n",
       " 'reading': 375,\n",
       " 'wish': 376,\n",
       " 'language': 377,\n",
       " 'poor': 378,\n",
       " 'died': 379,\n",
       " 'became': 380,\n",
       " 'ran': 381,\n",
       " 'each': 382,\n",
       " 'bus': 383,\n",
       " 'anyone': 384,\n",
       " 'quit': 385,\n",
       " 'picture': 386,\n",
       " 'question': 387,\n",
       " 'king': 388,\n",
       " 'beautiful': 389,\n",
       " 'large': 390,\n",
       " 'police': 391,\n",
       " 'others': 392,\n",
       " 'desk': 393,\n",
       " 'sorry': 394,\n",
       " 'bicycle': 395,\n",
       " 'care': 396,\n",
       " 'everything': 397,\n",
       " 'slowly': 398,\n",
       " 'written': 399,\n",
       " 'anxious': 400,\n",
       " 'hear': 401,\n",
       " 'since': 402,\n",
       " 'difference': 403,\n",
       " 'birds': 404,\n",
       " 'move': 405,\n",
       " 'sick': 406,\n",
       " 'bring': 407,\n",
       " 'flowers': 408,\n",
       " 'free': 409,\n",
       " 'son': 410,\n",
       " 'clean': 411,\n",
       " 'phone': 412,\n",
       " 'summer': 413,\n",
       " 'music': 414,\n",
       " 'run': 415,\n",
       " 'black': 416,\n",
       " 'talks': 417,\n",
       " 'boys': 418,\n",
       " 'getting': 419,\n",
       " 'along': 420,\n",
       " 'address': 421,\n",
       " 'still': 422,\n",
       " 'born': 423,\n",
       " 'yours': 424,\n",
       " 'looks': 425,\n",
       " 'expensive': 426,\n",
       " 'family': 427,\n",
       " \"she's\": 428,\n",
       " 'power': 429,\n",
       " 'which': 430,\n",
       " 'everybody': 431,\n",
       " 'lives': 432,\n",
       " 'rich': 433,\n",
       " 'write': 434,\n",
       " 'fever': 435,\n",
       " 'sunday': 436,\n",
       " 'hand': 437,\n",
       " 'rumor': 438,\n",
       " 'size': 439,\n",
       " 'wherever': 440,\n",
       " 'thing': 441,\n",
       " 'forget': 442,\n",
       " 'country': 443,\n",
       " 'playing': 444,\n",
       " 'might': 445,\n",
       " 'outside': 446,\n",
       " 'makes': 447,\n",
       " 'tennis': 448,\n",
       " \"shouldn't\": 449,\n",
       " 'homework': 450,\n",
       " 'wife': 451,\n",
       " 'minutes': 452,\n",
       " 'learn': 453,\n",
       " 'window': 454,\n",
       " 'standing': 455,\n",
       " 'class': 456,\n",
       " 'best': 457,\n",
       " 'interesting': 458,\n",
       " 'suddenly': 459,\n",
       " 'instead': 460,\n",
       " 'clothes': 461,\n",
       " 'telephone': 462,\n",
       " 'australia': 463,\n",
       " 'weather': 464,\n",
       " \"wouldn't\": 465,\n",
       " 'surprised': 466,\n",
       " 'men': 467,\n",
       " 'behind': 468,\n",
       " 'village': 469,\n",
       " 'longer': 470,\n",
       " 'through': 471,\n",
       " 'whether': 472,\n",
       " 'pay': 473,\n",
       " 'excuse': 474,\n",
       " 'smiled': 475,\n",
       " 'dogs': 476,\n",
       " 'over': 477,\n",
       " 'bag': 478,\n",
       " 'wash': 479,\n",
       " 'crying': 480,\n",
       " \"where's\": 481,\n",
       " 'began': 482,\n",
       " 'cried': 483,\n",
       " 'bank': 484,\n",
       " 'hands': 485,\n",
       " 'blue': 486,\n",
       " 'against': 487,\n",
       " 'war': 488,\n",
       " 'matter': 489,\n",
       " 'saved': 490,\n",
       " 'closed': 491,\n",
       " 'television': 492,\n",
       " 'seems': 493,\n",
       " 'taking': 494,\n",
       " 'called': 495,\n",
       " 'baseball': 496,\n",
       " 'working': 497,\n",
       " 'tokyo': 498,\n",
       " 'yourself': 499,\n",
       " 'angry': 500,\n",
       " 'plan': 501,\n",
       " 'eating': 502,\n",
       " 'apple': 503,\n",
       " 'expect': 504,\n",
       " 'quickly': 505,\n",
       " 'dress': 506,\n",
       " 'return': 507,\n",
       " 'disappointed': 508,\n",
       " 'eggs': 509,\n",
       " 'visit': 510,\n",
       " 'reap': 511,\n",
       " 'sow': 512,\n",
       " 'lose': 513,\n",
       " 'knew': 514,\n",
       " 'business': 515,\n",
       " 'begins': 516,\n",
       " 'anymore': 517,\n",
       " 'decided': 518,\n",
       " 'sky': 519,\n",
       " 'fell': 520,\n",
       " 'studying': 521,\n",
       " 'present': 522,\n",
       " 'late': 523,\n",
       " \"hasn't\": 524,\n",
       " 'sugar': 525,\n",
       " 'rains': 526,\n",
       " 'then': 527,\n",
       " 'explain': 528,\n",
       " 'movie': 529,\n",
       " 'air': 530,\n",
       " \"aren't\": 531,\n",
       " 'apples': 532,\n",
       " 'interested': 533,\n",
       " 'thank': 534,\n",
       " 'raining': 535,\n",
       " 'brought': 536,\n",
       " 'europe': 537,\n",
       " 'cup': 538,\n",
       " 'number': 539,\n",
       " 'office': 540,\n",
       " 'america': 541,\n",
       " 'set': 542,\n",
       " 'grandmother': 543,\n",
       " 'hobby': 544,\n",
       " 'capital': 545,\n",
       " \"there's\": 546,\n",
       " 'across': 547,\n",
       " 'find': 548,\n",
       " 'finish': 549,\n",
       " 'making': 550,\n",
       " 'heat': 551,\n",
       " 'whoever': 552,\n",
       " 'strange': 553,\n",
       " 'stayed': 554,\n",
       " 'being': 555,\n",
       " 'mountain': 556,\n",
       " 'trouble': 557,\n",
       " 'older': 558,\n",
       " 'hospital': 559,\n",
       " 'london': 560,\n",
       " 'finished': 561,\n",
       " 'child': 562,\n",
       " 'bit': 563,\n",
       " 'eat': 564,\n",
       " 'known': 565,\n",
       " 'necessary': 566,\n",
       " 'arrested': 567,\n",
       " 'jump': 568,\n",
       " 'laughed': 569,\n",
       " 'sing': 570,\n",
       " 'hungry': 571,\n",
       " \"who's\": 572,\n",
       " 'stood': 573,\n",
       " 'strong': 574,\n",
       " 'cake': 575,\n",
       " 'attend': 576,\n",
       " 'fat': 577,\n",
       " 'history': 578,\n",
       " 'god': 579,\n",
       " \"we'll\": 580,\n",
       " 'cooked': 581,\n",
       " 'guitar': 582,\n",
       " 'anybody': 583,\n",
       " 'beauty': 584,\n",
       " 'fault': 585,\n",
       " 'age': 586,\n",
       " 'teach': 587,\n",
       " 'join': 588,\n",
       " 'remember': 589,\n",
       " 'april': 590,\n",
       " 'key': 591,\n",
       " 'whose': 592,\n",
       " 'listen': 593,\n",
       " 'sight': 594,\n",
       " 'truth': 595,\n",
       " 'earth': 596,\n",
       " 'hope': 597,\n",
       " 'mistake': 598,\n",
       " 'those': 599,\n",
       " 'women': 600,\n",
       " 'worked': 601,\n",
       " 'snow': 602,\n",
       " 'started': 603,\n",
       " 'thief': 604,\n",
       " 'shirt': 605,\n",
       " 'clear': 606,\n",
       " 'airport': 607,\n",
       " 'agree': 608,\n",
       " 'nine': 609,\n",
       " 'foot': 610,\n",
       " 'broken': 611,\n",
       " 'secret': 612,\n",
       " 'policeman': 613,\n",
       " 'horse': 614,\n",
       " 'lake': 615,\n",
       " 'game': 616,\n",
       " 'empty': 617,\n",
       " 'woman': 618,\n",
       " 'prefer': 619,\n",
       " 'myself': 620,\n",
       " 'rather': 621,\n",
       " '3': 622,\n",
       " 'light': 623,\n",
       " 'often': 624,\n",
       " 'arrive': 625,\n",
       " 'memory': 626,\n",
       " \"you've\": 627,\n",
       " 'milk': 628,\n",
       " 'abandoned': 629,\n",
       " 'easily': 630,\n",
       " 'tends': 631,\n",
       " 'show': 632,\n",
       " 'face': 633,\n",
       " 'four': 634,\n",
       " 'table': 635,\n",
       " 'novel': 636,\n",
       " 'stand': 637,\n",
       " 'bath': 638,\n",
       " 'harder': 639,\n",
       " '5': 640,\n",
       " '10': 641,\n",
       " 'team': 642,\n",
       " \"we've\": 643,\n",
       " 'least': 644,\n",
       " 'larger': 645,\n",
       " 'death': 646,\n",
       " 'cars': 647,\n",
       " 'rest': 648,\n",
       " 'dollars': 649,\n",
       " 'm': 650,\n",
       " 'shade': 651,\n",
       " 'depends': 652,\n",
       " 'cats': 653,\n",
       " 'changing': 654,\n",
       " 'believes': 655,\n",
       " 'opinions': 656,\n",
       " 'arrived': 657,\n",
       " 'dead': 658,\n",
       " 'famous': 659,\n",
       " 'great': 660,\n",
       " 'head': 661,\n",
       " 'promise': 662,\n",
       " 'canada': 663,\n",
       " 'french': 664,\n",
       " 'spoken': 665,\n",
       " 'dream': 666,\n",
       " 'danger': 667,\n",
       " 'speaking': 668,\n",
       " \"tom's\": 669,\n",
       " 'wedding': 670,\n",
       " 'meeting': 671,\n",
       " 'africa': 672,\n",
       " 'result': 673,\n",
       " 'happen': 674,\n",
       " 'most': 675,\n",
       " 'population': 676,\n",
       " 'ship': 677,\n",
       " \"should've\": 678,\n",
       " 'monday': 679,\n",
       " 'thought': 680,\n",
       " 'future': 681,\n",
       " 'students': 682,\n",
       " 'sisters': 683,\n",
       " 'dangerous': 684,\n",
       " 'pick': 685,\n",
       " 'plane': 686,\n",
       " 'college': 687,\n",
       " 'china': 688,\n",
       " 'bigger': 689,\n",
       " 'having': 690,\n",
       " 'pictures': 691,\n",
       " 'languages': 692,\n",
       " 'doubt': 693,\n",
       " 'advice': 694,\n",
       " 'covered': 695,\n",
       " 'whole': 696,\n",
       " 'street': 697,\n",
       " 'machine': 698,\n",
       " 'uncle': 699,\n",
       " 'amateur': 700,\n",
       " 'cricket': 701,\n",
       " 'player': 702,\n",
       " 'different': 703,\n",
       " 'bridge': 704,\n",
       " 'supposed': 705,\n",
       " 'cost': 706,\n",
       " 'government': 707,\n",
       " 'pass': 708,\n",
       " 'responsible': 709,\n",
       " 'bored': 710,\n",
       " 'wonderful': 711,\n",
       " 'follow': 712,\n",
       " 'shout': 713,\n",
       " 'promised': 714,\n",
       " 'cat': 715,\n",
       " 'map': 716,\n",
       " 'shot': 717,\n",
       " 'feet': 718,\n",
       " 'waited': 719,\n",
       " 'hat': 720,\n",
       " 'husband': 721,\n",
       " 'cook': 722,\n",
       " 'kites': 723,\n",
       " 'carefully': 724,\n",
       " 'rice': 725,\n",
       " 'legs': 726,\n",
       " 'speaks': 727,\n",
       " 'near': 728,\n",
       " 'thirsty': 729,\n",
       " 'bird': 730,\n",
       " 'list': 731,\n",
       " 'walking': 732,\n",
       " 'turned': 733,\n",
       " 'student': 734,\n",
       " 'stolen': 735,\n",
       " 'radio': 736,\n",
       " 'yes': 737,\n",
       " 'gone': 738,\n",
       " 'simple': 739,\n",
       " 'admit': 740,\n",
       " 'sort': 741,\n",
       " 'tall': 742,\n",
       " 'dark': 743,\n",
       " 'suitcase': 744,\n",
       " 'pretty': 745,\n",
       " 'crow': 746,\n",
       " 'entered': 747,\n",
       " 'continued': 748,\n",
       " 'eaten': 749,\n",
       " 'win': 750,\n",
       " 'wine': 751,\n",
       " 'ticket': 752,\n",
       " 'pulled': 753,\n",
       " 'trees': 754,\n",
       " 'tax': 755,\n",
       " 'jog': 756,\n",
       " 'worry': 757,\n",
       " 'lunch': 758,\n",
       " 'meant': 759,\n",
       " 'joke': 760,\n",
       " 'injured': 761,\n",
       " 'glasses': 762,\n",
       " 'eleven': 763,\n",
       " 'shut': 764,\n",
       " 'red': 765,\n",
       " 'goes': 766,\n",
       " 'accepted': 767,\n",
       " 'offer': 768,\n",
       " 'boston': 769,\n",
       " 'daughter': 770,\n",
       " 'correct': 771,\n",
       " 'ahead': 772,\n",
       " 'eye': 773,\n",
       " 'close': 774,\n",
       " 'ball': 775,\n",
       " 'lived': 776,\n",
       " 'stubborn': 777,\n",
       " 'wears': 778,\n",
       " \"what're\": 779,\n",
       " 'animal': 780,\n",
       " 'fast': 781,\n",
       " 'learned': 782,\n",
       " 'robbed': 783,\n",
       " 'wake': 784,\n",
       " '7': 785,\n",
       " \"wasn't\": 786,\n",
       " 'thinking': 787,\n",
       " 'absent': 788,\n",
       " '30': 789,\n",
       " 'shall': 790,\n",
       " 'piano': 791,\n",
       " 'heart': 792,\n",
       " 'showed': 793,\n",
       " 'oil': 794,\n",
       " 'smooth': 795,\n",
       " 'kill': 796,\n",
       " 'plenty': 797,\n",
       " 'yen': 798,\n",
       " 'bother': 799,\n",
       " 'glass': 800,\n",
       " 'park': 801,\n",
       " 'arrogant': 802,\n",
       " 'accused': 803,\n",
       " 'complaining': 804,\n",
       " 'chair': 805,\n",
       " 'swimming': 806,\n",
       " 'sent': 807,\n",
       " 'important': 808,\n",
       " 'brothers': 809,\n",
       " 'garden': 810,\n",
       " 'under': 811,\n",
       " 'thirty': 812,\n",
       " 'cancer': 813,\n",
       " 'half': 814,\n",
       " 'forest': 815,\n",
       " 'taxi': 816,\n",
       " 'rooms': 817,\n",
       " 'road': 818,\n",
       " 'neighbors': 819,\n",
       " 'sleeping': 820,\n",
       " 'sold': 821,\n",
       " 'travel': 822,\n",
       " 'club': 823,\n",
       " 'towel': 824,\n",
       " 'herself': 825,\n",
       " 'reason': 826,\n",
       " 'cry': 827,\n",
       " 'twenty': 828,\n",
       " 'protect': 829,\n",
       " 'favorite': 830,\n",
       " 'smoke': 831,\n",
       " 'officer': 832,\n",
       " 'whatever': 833,\n",
       " 'miles': 834,\n",
       " 'following': 835,\n",
       " 'items': 836,\n",
       " 'hardly': 837,\n",
       " 'place': 838,\n",
       " 'feed': 839,\n",
       " 'word': 840,\n",
       " 'order': 841,\n",
       " 'somewhere': 842,\n",
       " 'france': 843,\n",
       " 'explained': 844,\n",
       " 'rule': 845,\n",
       " 'waste': 846,\n",
       " 'else': 847,\n",
       " 'voice': 848,\n",
       " 'allowed': 849,\n",
       " 'store': 850,\n",
       " 'brush': 851,\n",
       " 'teeth': 852,\n",
       " 'meals': 853,\n",
       " 'words': 854,\n",
       " 'tickets': 855,\n",
       " 'speech': 856,\n",
       " 'become': 857,\n",
       " 'forever': 858,\n",
       " 'advise': 859,\n",
       " 'pleased': 860,\n",
       " 'allow': 861,\n",
       " 'pain': 862,\n",
       " 'safety': 863,\n",
       " 'tree': 864,\n",
       " 'worse': 865,\n",
       " 'confident': 866,\n",
       " 'send': 867,\n",
       " 'butter': 868,\n",
       " 'advantage': 869,\n",
       " 'movies': 870,\n",
       " 'trip': 871,\n",
       " 'traffic': 872,\n",
       " 'mail': 873,\n",
       " 'pieces': 874,\n",
       " 'flying': 875,\n",
       " 'kite': 876,\n",
       " 'due': 877,\n",
       " 'illness': 878,\n",
       " 'interpret': 879,\n",
       " 'poem': 880,\n",
       " 'borrow': 881,\n",
       " 'subject': 882,\n",
       " 'lie': 883,\n",
       " 'helped': 884,\n",
       " 'tonight': 885,\n",
       " 'sun': 886,\n",
       " 'even': 887,\n",
       " 'fresh': 888,\n",
       " 'vegetables': 889,\n",
       " 'promote': 890,\n",
       " 'buried': 891,\n",
       " 'lying': 892,\n",
       " 'until': 893,\n",
       " 'president': 894,\n",
       " 'trust': 895,\n",
       " 'rules': 896,\n",
       " 'killed': 897,\n",
       " 'ashamed': 898,\n",
       " 'wrote': 899,\n",
       " 'temples': 900,\n",
       " 'fifty': 901,\n",
       " 'past': 902,\n",
       " 'end': 903,\n",
       " 'extent': 904,\n",
       " 'wind': 905,\n",
       " 'leaving': 906,\n",
       " 'leaves': 907,\n",
       " 'computer': 908,\n",
       " 'short': 909,\n",
       " 'prize': 910,\n",
       " 'message': 911,\n",
       " 'point': 912,\n",
       " 'speed': 913,\n",
       " 'breakfast': 914,\n",
       " 'case': 915,\n",
       " 'living': 916,\n",
       " 'teaching': 917,\n",
       " 'destroyed': 918,\n",
       " 'catch': 919,\n",
       " 'chance': 920,\n",
       " 'according': 921,\n",
       " 'front': 922,\n",
       " 'together': 923,\n",
       " 'company': 924,\n",
       " 'advised': 925,\n",
       " 'far': 926,\n",
       " 'its': 927,\n",
       " 'staying': 928,\n",
       " 'passed': 929,\n",
       " 'ordered': 930,\n",
       " 'workers': 931,\n",
       " 'museum': 932,\n",
       " 'library': 933,\n",
       " 'answers': 934,\n",
       " 'test': 935,\n",
       " 'ought': 936,\n",
       " 'till': 937,\n",
       " 'couple': 938,\n",
       " 'except': 939,\n",
       " 'largest': 940,\n",
       " 'feeling': 941,\n",
       " 'spent': 942,\n",
       " 'teresa': 943,\n",
       " 'duck': 944,\n",
       " 'hello': 945,\n",
       " 'cheers': 946,\n",
       " 'ok': 947,\n",
       " 'won': 948,\n",
       " 'perfect': 949,\n",
       " 'welcome': 950,\n",
       " 'fine': 951,\n",
       " 'math': 952,\n",
       " 'touch': 953,\n",
       " 'atheist': 954,\n",
       " 'congratulations': 955,\n",
       " 'miss': 956,\n",
       " 'rude': 957,\n",
       " 'lucky': 958,\n",
       " 'fair': 959,\n",
       " 'lack': 960,\n",
       " 'choose': 961,\n",
       " 'top': 962,\n",
       " 'oranges': 963,\n",
       " 'sign': 964,\n",
       " 'betrayed': 965,\n",
       " 'build': 966,\n",
       " 'nests': 967,\n",
       " 'sleepy': 968,\n",
       " 'headache': 969,\n",
       " 'loved': 970,\n",
       " 'happiness': 971,\n",
       " 'throw': 972,\n",
       " 'breathed': 973,\n",
       " 'deeply': 974,\n",
       " 'cousin': 975,\n",
       " 'toes': 976,\n",
       " 'guy': 977,\n",
       " \"mary's\": 978,\n",
       " 'enjoyed': 979,\n",
       " 'kids': 980,\n",
       " 'vase': 981,\n",
       " 'pen': 982,\n",
       " 'gym': 983,\n",
       " 'state': 984,\n",
       " 'taste': 985,\n",
       " 'green': 986,\n",
       " 'forgive': 987,\n",
       " 'pencil': 988,\n",
       " 'sea': 989,\n",
       " 'succeed': 990,\n",
       " 'noon': 991,\n",
       " 'consciousness': 992,\n",
       " 'decision': 993,\n",
       " 'wore': 994,\n",
       " 'haunted': 995,\n",
       " 'sheets': 996,\n",
       " 'burst': 997,\n",
       " 'feels': 998,\n",
       " 'silk': 999,\n",
       " 'beer': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1576301777254,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "UgM11oD9b1kI",
    "outputId": "5ba485df-65b9-4060-9fc3-f19b74903263"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 714], [177, 15], [20, 4, 406], [407, 31, 9], [50, 37, 83]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert English text to indexes\n",
    "encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers \n",
    "\n",
    "encoder_seq[100:105] #Display some converted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1576301784442,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "cN5DneFYp0nc",
    "outputId": "ba51ce03-2a17-4b4f-df46-2d663f5b848e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We promised.',\n",
       " \"What's this?\",\n",
       " 'Are you sick?',\n",
       " 'Bring him in.',\n",
       " 'Come with us.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_text[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1167,
     "status": "ok",
     "timestamp": 1576301817645,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "kyFL1wvpKXnL",
    "outputId": "b8484042-b2f4-44ad-f0cd-d657dfa68e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length for Source language:  22\n",
      "Source language vocablury size:  2410\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of sentence\n",
    "max_encoder_seq_length = max([len(txt) for txt in encoder_seq])\n",
    "print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n",
    "\n",
    "#Source language Vocablury\n",
    "encoder_vocab_size = len(encoder_t.word_index)\n",
    "print('Source language vocablury size: ', encoder_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOmkUnoLKXnN"
   },
   "source": [
    "### Tokenize Target language sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_kC_wx4ooBXq"
   },
   "outputs": [],
   "source": [
    "?tf.keras.preprocessing.text.Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLV2B3TXKXnO"
   },
   "outputs": [],
   "source": [
    "#Tokenizer for target language, filters should not <start> and <end>\n",
    "#remove < and > used in Target language sequences\n",
    "decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "decoder_t.fit_on_texts(decoder_text) #Fit it on target sentences\n",
    "decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1576301927541,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "n9M_6R01KXnP",
    "outputId": "56b2dd25-ffce-459d-b33f-efa9a797465e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length for Target language:  27\n",
      "Target language vocablury size:  3048\n"
     ]
    }
   ],
   "source": [
    "#Maximum length of sentence\n",
    "max_decoder_seq_length = max([len(txt) for txt in decoder_seq])\n",
    "print('Maximum sentence length for Target language: ', max_decoder_seq_length)\n",
    "\n",
    "#Target language Vocablury\n",
    "decoder_vocab_size = len(decoder_t.word_index)\n",
    "print('Target language vocablury size: ', decoder_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1576301947877,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "xmzEELcwc2Bg",
    "outputId": "f851f2e4-9c42-4970-9ffb-485aef51c75f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<end>': 2,\n",
       " 'है।': 3,\n",
       " 'नहीं': 4,\n",
       " 'में': 5,\n",
       " 'मैं': 6,\n",
       " 'वह': 7,\n",
       " 'से': 8,\n",
       " 'मुझे': 9,\n",
       " 'क्या': 10,\n",
       " 'है': 11,\n",
       " 'के': 12,\n",
       " 'को': 13,\n",
       " 'की': 14,\n",
       " 'हैं।': 15,\n",
       " 'हो': 16,\n",
       " 'बहुत': 17,\n",
       " 'एक': 18,\n",
       " 'का': 19,\n",
       " 'पर': 20,\n",
       " 'तुम': 21,\n",
       " 'उसने': 22,\n",
       " 'था।': 23,\n",
       " 'हूँ।': 24,\n",
       " 'यह': 25,\n",
       " 'कर': 26,\n",
       " 'लिए': 27,\n",
       " 'कि': 28,\n",
       " 'टॉम': 29,\n",
       " 'मेरे': 30,\n",
       " 'हैं': 31,\n",
       " 'तुम्हें': 32,\n",
       " 'और': 33,\n",
       " 'ने': 34,\n",
       " 'भी': 35,\n",
       " 'अपने': 36,\n",
       " 'इस': 37,\n",
       " 'उसे': 38,\n",
       " 'मेरी': 39,\n",
       " 'रहा': 40,\n",
       " 'मैंने': 41,\n",
       " 'करने': 42,\n",
       " 'तो': 43,\n",
       " 'अपनी': 44,\n",
       " 'ही': 45,\n",
       " 'पास': 46,\n",
       " 'हम': 47,\n",
       " 'आप': 48,\n",
       " 'गया।': 49,\n",
       " 'था': 50,\n",
       " 'कल': 51,\n",
       " 'काम': 52,\n",
       " 'करना': 53,\n",
       " 'कोई': 54,\n",
       " 'उसके': 55,\n",
       " 'बात': 56,\n",
       " 'साथ': 57,\n",
       " 'घर': 58,\n",
       " 'तुम्हारे': 59,\n",
       " 'उसकी': 60,\n",
       " 'पता': 61,\n",
       " 'उस': 62,\n",
       " 'कुछ': 63,\n",
       " 'गया': 64,\n",
       " 'समय': 65,\n",
       " 'मेरा': 66,\n",
       " 'सकते': 67,\n",
       " 'थी।': 68,\n",
       " 'अभी': 69,\n",
       " 'रही': 70,\n",
       " 'रहे': 71,\n",
       " 'कभी': 72,\n",
       " 'लगता': 73,\n",
       " 'यहाँ': 74,\n",
       " 'किया।': 75,\n",
       " 'तक': 76,\n",
       " 'बजे': 77,\n",
       " 'आ': 78,\n",
       " 'हूँ': 79,\n",
       " 'सकता': 80,\n",
       " 'किसी': 81,\n",
       " 'आज': 82,\n",
       " 'चाहिए।': 83,\n",
       " 'मत': 84,\n",
       " 'अच्छा': 85,\n",
       " 'उसको': 86,\n",
       " 'हुई': 87,\n",
       " 'करता': 88,\n",
       " 'पसंद': 89,\n",
       " 'दिया।': 90,\n",
       " 'थे।': 91,\n",
       " 'मुझसे': 92,\n",
       " 'करते': 93,\n",
       " 'मदद': 94,\n",
       " '।': 95,\n",
       " 'जो': 96,\n",
       " 'होता': 97,\n",
       " 'चाहता': 98,\n",
       " 'किताब': 99,\n",
       " 'हुआ': 100,\n",
       " 'वे': 101,\n",
       " 'जाने': 102,\n",
       " 'दो': 103,\n",
       " 'ज़्यादा': 104,\n",
       " 'पैसे': 105,\n",
       " 'अपना': 106,\n",
       " 'सब': 107,\n",
       " 'हुए': 108,\n",
       " 'उससे': 109,\n",
       " 'गाड़ी': 110,\n",
       " 'हो।': 111,\n",
       " 'पहले': 112,\n",
       " 'होगा।': 113,\n",
       " 'आपको': 114,\n",
       " 'भारत': 115,\n",
       " 'उसका': 116,\n",
       " 'जाना': 117,\n",
       " 'किया': 118,\n",
       " 'कम': 119,\n",
       " 'कहाँ': 120,\n",
       " 'जा': 121,\n",
       " 'न': 122,\n",
       " 'गए': 123,\n",
       " 'होती': 124,\n",
       " 'बारे': 125,\n",
       " 'सारे': 126,\n",
       " 'जब': 127,\n",
       " 'तुम्हारी': 128,\n",
       " 'आदमी': 129,\n",
       " 'अंग्रेज़ी': 130,\n",
       " 'दिन': 131,\n",
       " 'बाहर': 132,\n",
       " 'अब': 133,\n",
       " 'साल': 134,\n",
       " 'देर': 135,\n",
       " 'जाता': 136,\n",
       " 'ये': 137,\n",
       " 'बार': 138,\n",
       " 'दिया': 139,\n",
       " 'गई।': 140,\n",
       " 'हमारे': 141,\n",
       " 'वापस': 142,\n",
       " 'फ़ोन': 143,\n",
       " 'वहाँ': 144,\n",
       " 'रात': 145,\n",
       " 'खाना': 146,\n",
       " 'तुमने': 147,\n",
       " 'हमेशा': 148,\n",
       " 'अगर': 149,\n",
       " 'तुमसे': 150,\n",
       " 'कैसे': 151,\n",
       " 'हमने': 152,\n",
       " 'सकता।': 153,\n",
       " 'बड़ा': 154,\n",
       " 'जल्दी': 155,\n",
       " 'क्यों': 156,\n",
       " 'बंद': 157,\n",
       " 'छोड़': 158,\n",
       " 'तीन': 159,\n",
       " 'करो।': 160,\n",
       " 'जवाब': 161,\n",
       " 'कितने': 162,\n",
       " 'दी।': 163,\n",
       " 'तरह': 164,\n",
       " 'चला': 165,\n",
       " 'थे': 166,\n",
       " 'गए।': 167,\n",
       " 'करती': 168,\n",
       " 'चल': 169,\n",
       " 'हर': 170,\n",
       " 'हमे': 171,\n",
       " 'दस': 172,\n",
       " 'बारिश': 173,\n",
       " 'देखा': 174,\n",
       " 'उन्होंने': 175,\n",
       " 'चाहते': 176,\n",
       " 'लोगों': 177,\n",
       " 'सबसे': 178,\n",
       " 'आता': 179,\n",
       " 'लोग': 180,\n",
       " 'स्कूल': 181,\n",
       " 'पापा': 182,\n",
       " 'दो।': 183,\n",
       " 'डॉक्टर': 184,\n",
       " 'खुश': 185,\n",
       " 'कमरे': 186,\n",
       " 'देखा।': 187,\n",
       " 'माँ': 188,\n",
       " 'नौकरी': 189,\n",
       " 'हमारी': 190,\n",
       " 'कहा': 191,\n",
       " 'अच्छी': 192,\n",
       " 'चाहिए': 193,\n",
       " 'ठीक': 194,\n",
       " 'अच्छे': 195,\n",
       " 'कुत्ता': 196,\n",
       " 'खतम': 197,\n",
       " 'सभी': 198,\n",
       " 'थी': 199,\n",
       " 'वाला': 200,\n",
       " 'दोस्त': 201,\n",
       " 'मुश्किल': 202,\n",
       " 'कोशिश': 203,\n",
       " 'शुरू': 204,\n",
       " 'कब': 205,\n",
       " 'भाई': 206,\n",
       " 'बच्चे': 207,\n",
       " 'पिता': 208,\n",
       " 'सारी': 209,\n",
       " 'ट्रेन': 210,\n",
       " 'करनी': 211,\n",
       " 'होने': 212,\n",
       " 'चिट्ठी': 213,\n",
       " 'ले': 214,\n",
       " 'रहता': 215,\n",
       " 'हमें': 216,\n",
       " 'लिया': 217,\n",
       " 'बाद': 218,\n",
       " 'थोड़ा': 219,\n",
       " 'पानी': 220,\n",
       " 'थोड़ी': 221,\n",
       " 'जल्द': 222,\n",
       " 'गई': 223,\n",
       " 'आपकी': 224,\n",
       " 'यकीन': 225,\n",
       " 'मौसम': 226,\n",
       " 'फिरसे': 227,\n",
       " 'टीवी': 228,\n",
       " 'ज़रूरत': 229,\n",
       " 'मन': 230,\n",
       " 'लड़की': 231,\n",
       " 'ना': 232,\n",
       " 'सच': 233,\n",
       " 'लिया।': 234,\n",
       " 'मैरी': 235,\n",
       " 'बिना': 236,\n",
       " 'लगा': 237,\n",
       " 'या': 238,\n",
       " 'चुका': 239,\n",
       " 'थक': 240,\n",
       " 'आने': 241,\n",
       " 'लग': 242,\n",
       " 'साफ़': 243,\n",
       " 'रोज़': 244,\n",
       " 'तुम्हारा': 245,\n",
       " 'नहीं।': 246,\n",
       " 'नाम': 247,\n",
       " 'जानता': 248,\n",
       " 'बड़े': 249,\n",
       " 'ऐसा': 250,\n",
       " 'जाएगा।': 251,\n",
       " 'पाँच': 252,\n",
       " 'देख': 253,\n",
       " 'वाले': 254,\n",
       " 'देना': 255,\n",
       " 'इन': 256,\n",
       " 'कितनी': 257,\n",
       " 'करी।': 258,\n",
       " 'माफ़': 259,\n",
       " 'कौन': 260,\n",
       " 'प्यार': 261,\n",
       " 'दोनो': 262,\n",
       " 'समझ': 263,\n",
       " 'शहर': 264,\n",
       " 'आवाज़': 265,\n",
       " 'मिलने': 266,\n",
       " 'शादी': 267,\n",
       " 'किताबें': 268,\n",
       " 'दरवाज़े': 269,\n",
       " 'दे': 270,\n",
       " 'इतना': 271,\n",
       " 'जाती': 272,\n",
       " 'चाय': 273,\n",
       " 'आदत': 274,\n",
       " 'जापान': 275,\n",
       " 'खाने': 276,\n",
       " 'सुबह': 277,\n",
       " 'वजह': 278,\n",
       " 'बच्चों': 279,\n",
       " 'सही': 280,\n",
       " 'सोच': 281,\n",
       " 'मुझपर': 282,\n",
       " 'हूं।': 283,\n",
       " 'बस': 284,\n",
       " 'चीज़': 285,\n",
       " 'इनसान': 286,\n",
       " 'तैयार': 287,\n",
       " 'पीछे': 288,\n",
       " 'विदेश': 289,\n",
       " 'हाथ': 290,\n",
       " 'रहते': 291,\n",
       " 'इंतेज़ार': 292,\n",
       " 'पढ़': 293,\n",
       " 'पिताजी': 294,\n",
       " 'चलाना': 295,\n",
       " 'खो': 296,\n",
       " 'टीचर': 297,\n",
       " 'हफ़्ते': 298,\n",
       " 'दूसरे': 299,\n",
       " 'काफ़ी': 300,\n",
       " 'छः': 301,\n",
       " 'आपके': 302,\n",
       " 'मेज़': 303,\n",
       " 'आमतौर': 304,\n",
       " 'सिगरेट': 305,\n",
       " 'महीने': 306,\n",
       " 'अंदर': 307,\n",
       " 'लगी': 308,\n",
       " 'तू': 309,\n",
       " 'कैसा': 310,\n",
       " 'आया।': 311,\n",
       " 'ग़लत': 312,\n",
       " 'कृपया': 313,\n",
       " 'जन्मदिन': 314,\n",
       " 'उम्र': 315,\n",
       " 'हुई।': 316,\n",
       " 'लड़के': 317,\n",
       " 'बताया': 318,\n",
       " 'इस्तेमाल': 319,\n",
       " 'हुआ।': 320,\n",
       " 'गर्मी': 321,\n",
       " 'मिलना': 322,\n",
       " 'बहन': 323,\n",
       " 'दोपहर': 324,\n",
       " 'आसान': 325,\n",
       " 'कपड़े': 326,\n",
       " 'मिला।': 327,\n",
       " 'पिछले': 328,\n",
       " 'नदी': 329,\n",
       " 'पार्टी': 330,\n",
       " 'उनकी': 331,\n",
       " 'परेशान': 332,\n",
       " 'होते': 333,\n",
       " 'अकेले': 334,\n",
       " 'धीरे': 335,\n",
       " 'परीक्षा': 336,\n",
       " 'उनके': 337,\n",
       " 'अगले': 338,\n",
       " 'आपका': 339,\n",
       " 'भूल': 340,\n",
       " 'आग': 341,\n",
       " 'आपसे': 342,\n",
       " 'पूरी': 343,\n",
       " 'करो': 344,\n",
       " 'जानते': 345,\n",
       " 'जैसा': 346,\n",
       " 'कितना': 347,\n",
       " 'देखना': 348,\n",
       " 'होगा': 349,\n",
       " 'भरोसा': 350,\n",
       " 'सेव': 351,\n",
       " 'घड़ी': 352,\n",
       " 'जहाँ': 353,\n",
       " 'स्टेशन': 354,\n",
       " 'कमरा': 355,\n",
       " 'लगभग': 356,\n",
       " 'पीना': 357,\n",
       " 'खबर': 358,\n",
       " 'मर': 359,\n",
       " 'होगी।': 360,\n",
       " 'आठ': 361,\n",
       " 'दिनों': 362,\n",
       " 'फ़र्क': 363,\n",
       " 'दूर': 364,\n",
       " 'देने': 365,\n",
       " 'फ़ायदा': 366,\n",
       " 'क्योंकि': 367,\n",
       " 'दुनिया': 368,\n",
       " 'गाँव': 369,\n",
       " 'चलो': 370,\n",
       " 'कीजिए।': 371,\n",
       " 'वैसा': 372,\n",
       " 'आया': 373,\n",
       " 'आराम': 374,\n",
       " 'पढ़ाई': 375,\n",
       " 'मज़ाक': 376,\n",
       " 'याद': 377,\n",
       " 'शायद': 378,\n",
       " 'बन': 379,\n",
       " 'ग़लती': 380,\n",
       " 'विश्वास': 381,\n",
       " 'वो': 382,\n",
       " 'आए': 383,\n",
       " 'जान': 384,\n",
       " 'जाकर': 385,\n",
       " 'जूते': 386,\n",
       " 'पुलिस': 387,\n",
       " 'होंगे।': 388,\n",
       " 'बाल': 389,\n",
       " 'ऐसी': 390,\n",
       " 'कॉफ़ी': 391,\n",
       " 'तस्वीर': 392,\n",
       " 'सवाल': 393,\n",
       " 'मिल': 394,\n",
       " 'सकती।': 395,\n",
       " 'उन्हें': 396,\n",
       " 'सो': 397,\n",
       " 'सका।': 398,\n",
       " 'साईकल': 399,\n",
       " 'लगती': 400,\n",
       " 'अचानक': 401,\n",
       " 'जैसे': 402,\n",
       " 'बता': 403,\n",
       " 'जाओ।': 404,\n",
       " 'निकल': 405,\n",
       " 'कुत्ते': 406,\n",
       " 'वादा': 407,\n",
       " 'बीमार': 408,\n",
       " 'मौत': 409,\n",
       " 'देखने': 410,\n",
       " 'दरवाज़ा': 411,\n",
       " 'पैसों': 412,\n",
       " 'पैर': 413,\n",
       " 'फिर': 414,\n",
       " 'खुशी': 415,\n",
       " 'कहानी': 416,\n",
       " 'करी': 417,\n",
       " 'मुलाकात': 418,\n",
       " 'चालू': 419,\n",
       " 'मिला': 420,\n",
       " 'आएगा।': 421,\n",
       " 'उन': 422,\n",
       " 'जितना': 423,\n",
       " 'लम्बा': 424,\n",
       " 'आती': 425,\n",
       " 'कीजिएगा': 426,\n",
       " 'लेना': 427,\n",
       " 'काश': 428,\n",
       " 'पेड़': 429,\n",
       " 'ख़याल': 430,\n",
       " 'रविवार': 431,\n",
       " 'हवा': 432,\n",
       " 'सकते।': 433,\n",
       " 'रखना': 434,\n",
       " 'तेज़': 435,\n",
       " 'भाग': 436,\n",
       " 'अजीब': 437,\n",
       " 'राजा': 438,\n",
       " 'डर': 439,\n",
       " 'छोटी': 440,\n",
       " 'दवाई': 441,\n",
       " 'पुराने': 442,\n",
       " 'समस्या': 443,\n",
       " 'सैर': 444,\n",
       " 'चाहती': 445,\n",
       " 'नई': 446,\n",
       " 'बीच': 447,\n",
       " 'पड़ी।': 448,\n",
       " 'इसके': 449,\n",
       " 'मानो': 450,\n",
       " 'लिखी': 451,\n",
       " 'सलाह': 452,\n",
       " 'रहना': 453,\n",
       " 'मम्मी': 454,\n",
       " 'कहना': 455,\n",
       " 'इतने': 456,\n",
       " 'बर्दाश्त': 457,\n",
       " 'अलग': 458,\n",
       " 'अकेला': 459,\n",
       " 'तैरना': 460,\n",
       " 'लो।': 461,\n",
       " 'इसे': 462,\n",
       " 'हमारा': 463,\n",
       " 'बिस्तर': 464,\n",
       " 'करूँगा।': 465,\n",
       " 'संगीत': 466,\n",
       " 'पतंग': 467,\n",
       " 'ध्यान': 468,\n",
       " 'शोर': 469,\n",
       " 'खराब': 470,\n",
       " 'दर्द': 471,\n",
       " 'विद्यार्थी': 472,\n",
       " 'चोरी': 473,\n",
       " 'उम्मीद': 474,\n",
       " 'ली।': 475,\n",
       " 'सकती': 476,\n",
       " 'पैदा': 477,\n",
       " 'परिवार': 478,\n",
       " 'चुके': 479,\n",
       " 'करके': 480,\n",
       " 'बुरी': 481,\n",
       " 'आना': 482,\n",
       " 'जाए।': 483,\n",
       " 'आसमान': 484,\n",
       " 'डब्बे': 485,\n",
       " 'लगाकर': 486,\n",
       " 'बुखार': 487,\n",
       " 'दीजिए।': 488,\n",
       " 'रंग': 489,\n",
       " 'अफ़वाह': 490,\n",
       " 'नाप': 491,\n",
       " 'पड़ेगी।': 492,\n",
       " 'ज़िन्दगी': 493,\n",
       " 'कहीं': 494,\n",
       " 'जानवर': 495,\n",
       " 'खाली': 496,\n",
       " 'अक्सर': 497,\n",
       " 'बोल': 498,\n",
       " 'खेलना': 499,\n",
       " 'चीनी': 500,\n",
       " 'टेनिस': 501,\n",
       " 'दोनों': 502,\n",
       " 'होमवर्क': 503,\n",
       " 'जी': 504,\n",
       " 'जंगल': 505,\n",
       " 'अध्यापक': 506,\n",
       " 'पीने': 507,\n",
       " 'ढूँढ': 508,\n",
       " 'किस': 509,\n",
       " 'जाते': 510,\n",
       " 'खिड़की': 511,\n",
       " 'दुर्घटना': 512,\n",
       " 'पूरे': 513,\n",
       " 'सड़क': 514,\n",
       " 'असफल': 515,\n",
       " 'पा': 516,\n",
       " 'जाएगी।': 517,\n",
       " 'भाषा': 518,\n",
       " 'ऑस्ट्रेलिया': 519,\n",
       " 'ऐसे': 520,\n",
       " 'ज़िम्मेदार': 521,\n",
       " 'अंतर': 522,\n",
       " 'रह': 523,\n",
       " 'बच्चा': 524,\n",
       " 'भूख': 525,\n",
       " 'नया': 526,\n",
       " 'खड़ा': 527,\n",
       " 'लगते': 528,\n",
       " 'आओ।': 529,\n",
       " 'फूल': 530,\n",
       " 'मछलियाँ': 531,\n",
       " 'खरीदना': 532,\n",
       " 'आऊँगा।': 533,\n",
       " 'करता।': 534,\n",
       " 'गरम': 535,\n",
       " 'ज़रूरी': 536,\n",
       " 'आई': 537,\n",
       " 'सुनाई': 538,\n",
       " 'बूढ़ा': 539,\n",
       " 'बारी': 540,\n",
       " 'रहें': 541,\n",
       " 'बैंक': 542,\n",
       " 'आँखें': 543,\n",
       " 'सच्चाई': 544,\n",
       " 'जंग': 545,\n",
       " 'रहती': 546,\n",
       " 'किसने': 547,\n",
       " 'वही': 548,\n",
       " 'सा': 549,\n",
       " 'i': 550,\n",
       " 'छोटा': 551,\n",
       " 'सुंदर': 552,\n",
       " 'चोर': 553,\n",
       " 'कौनसा': 554,\n",
       " 'कह': 555,\n",
       " 'सवालों': 556,\n",
       " 'दिखने': 557,\n",
       " 'अमीर': 558,\n",
       " 'यहां': 559,\n",
       " 'बेसबॉल': 560,\n",
       " 'आओगे': 561,\n",
       " 'पढ़ना': 562,\n",
       " 'टोक्यो': 563,\n",
       " 'गुस्सा': 564,\n",
       " 'की।': 565,\n",
       " 'सहमत': 566,\n",
       " 'पीठ': 567,\n",
       " 'काट': 568,\n",
       " 'जाऊँगा।': 569,\n",
       " 'फ़ैसला': 570,\n",
       " 'बज': 571,\n",
       " 'निराश': 572,\n",
       " 'अफ़सर': 573,\n",
       " 'गरीब': 574,\n",
       " 'हमको': 575,\n",
       " 'विज्ञान': 576,\n",
       " 'आगे': 577,\n",
       " 'लम्बी': 578,\n",
       " 'झील': 579,\n",
       " 'पूरा': 580,\n",
       " 'चहिए।': 581,\n",
       " 'औरत': 582,\n",
       " 'साढ़े': 583,\n",
       " 'बजाना': 584,\n",
       " 'वाली': 585,\n",
       " 'ग़लतियाँ': 586,\n",
       " 'पहुँच': 587,\n",
       " 'सौ': 588,\n",
       " 'देश': 589,\n",
       " 'आसानी': 590,\n",
       " 'उसपर': 591,\n",
       " 'इससे': 592,\n",
       " 'सामने': 593,\n",
       " 'खड़े': 594,\n",
       " 'लगाया।': 595,\n",
       " 'बीमारी': 596,\n",
       " 'मिनट': 597,\n",
       " 'रहने': 598,\n",
       " 'फ़िल्म': 599,\n",
       " 'कीमत': 600,\n",
       " 'सीखना': 601,\n",
       " 'दी': 602,\n",
       " 'डॉलर': 603,\n",
       " 'उठा': 604,\n",
       " 'सफ़र': 605,\n",
       " 'दिलचस्पी': 606,\n",
       " 'रूप': 607,\n",
       " 'क्लास': 608,\n",
       " 'दिलचस्प': 609,\n",
       " 'रुक': 610,\n",
       " 'हिसाब': 611,\n",
       " 'बजाय': 612,\n",
       " 'खिलाड़ी': 613,\n",
       " 'नम्बर': 614,\n",
       " 'लिए।': 615,\n",
       " 'मना': 616,\n",
       " 'असली': 617,\n",
       " 'बड़ी': 618,\n",
       " 'आते': 619,\n",
       " 'सुनकर': 620,\n",
       " 'शौक': 621,\n",
       " 'राजधानी': 622,\n",
       " 'दोस्तों': 623,\n",
       " 'करोगे': 624,\n",
       " 'जितनी': 625,\n",
       " 'स्वास्थ्य': 626,\n",
       " 'कई': 627,\n",
       " 'पहाड़': 628,\n",
       " 'लंदन': 629,\n",
       " 'पाया।': 630,\n",
       " 'पढ़ने': 631,\n",
       " 'देखभाल': 632,\n",
       " 'छोटे': 633,\n",
       " 'मशीन': 634,\n",
       " 'पहचान': 635,\n",
       " 'तब': 636,\n",
       " 'जाओ': 637,\n",
       " 'हार': 638,\n",
       " 'मज़े': 639,\n",
       " 'पेट': 640,\n",
       " 'भर': 641,\n",
       " 'चलें': 642,\n",
       " 'मत।': 643,\n",
       " 'ली': 644,\n",
       " 'कैसी': 645,\n",
       " 'पता।': 646,\n",
       " 'समझता': 647,\n",
       " 'बरफ़': 648,\n",
       " 'गिर': 649,\n",
       " 'मुफ़्त': 650,\n",
       " 'नीचे': 651,\n",
       " 'उड़': 652,\n",
       " 'लड़का': 653,\n",
       " 'कमी': 654,\n",
       " 'इतिहास': 655,\n",
       " 'रहूँगा।': 656,\n",
       " 'भगवान': 657,\n",
       " 'बस्ता': 658,\n",
       " 'पागल': 659,\n",
       " 'पहनी': 660,\n",
       " 'गिटार': 661,\n",
       " 'बक': 662,\n",
       " 'बिजली': 663,\n",
       " 'ऊपर': 664,\n",
       " 'आस': 665,\n",
       " 'पड़ोस': 666,\n",
       " 'अप्रैल': 667,\n",
       " 'चाबी': 668,\n",
       " 'हूं': 669,\n",
       " 'लगा।': 670,\n",
       " 'पुरानी': 671,\n",
       " 'चीज़ें': 672,\n",
       " 'रास्ते': 673,\n",
       " 'बचा': 674,\n",
       " 'मिलेंगे।': 675,\n",
       " 'महंगा': 676,\n",
       " 'चली': 677,\n",
       " 'महसूस': 678,\n",
       " 'पढ़ा': 679,\n",
       " 'जीत': 680,\n",
       " 'चाहूँगा।': 681,\n",
       " 'रही।': 682,\n",
       " 'पड़ेगा।': 683,\n",
       " 'चिंता': 684,\n",
       " 'उधार': 685,\n",
       " 'कामयाब': 686,\n",
       " 'होना': 687,\n",
       " 'योजना': 688,\n",
       " 'खा': 689,\n",
       " 'नौ': 690,\n",
       " 'खुला': 691,\n",
       " 'ग्यारह': 692,\n",
       " 'ड्रेस': 693,\n",
       " 'ओर': 694,\n",
       " 'राज़': 695,\n",
       " 'अंडे': 696,\n",
       " 'चुकी': 697,\n",
       " 'प्रस्ताव': 698,\n",
       " 'स्वीकार': 699,\n",
       " 'सारा': 700,\n",
       " 'बना': 701,\n",
       " 'इसको': 702,\n",
       " 'नफ़रत': 703,\n",
       " 'उनको': 704,\n",
       " 'खेल': 705,\n",
       " 'आएगा': 706,\n",
       " 'गाना': 707,\n",
       " 'डाला।': 708,\n",
       " 'सात': 709,\n",
       " 'खुद': 710,\n",
       " 'बत्ती': 711,\n",
       " 'दूध': 712,\n",
       " 'मेहनत': 713,\n",
       " 'तरफ़': 714,\n",
       " 'शिकायत': 715,\n",
       " 'सके': 716,\n",
       " 'दूँगा।': 717,\n",
       " 'आई।': 718,\n",
       " 'डब्बा': 719,\n",
       " 'खोल': 720,\n",
       " 'उपन्यास': 721,\n",
       " 'कप': 722,\n",
       " 'सोने': 723,\n",
       " 'कठिन': 724,\n",
       " 'सेहत': 725,\n",
       " 'पत्नी': 726,\n",
       " 'कहा।': 727,\n",
       " 'लेने': 728,\n",
       " 'इनकार': 729,\n",
       " 'मुझ': 730,\n",
       " 'बुराई': 731,\n",
       " 'अटैची': 732,\n",
       " 'रो': 733,\n",
       " 'पसंदीता': 734,\n",
       " 'भूलना।': 735,\n",
       " 'छोड़ने': 736,\n",
       " 'राय': 737,\n",
       " 'मील': 738,\n",
       " 'बिलकुल': 739,\n",
       " 'पड़ता।': 740,\n",
       " 'सीधे': 741,\n",
       " 'मे': 742,\n",
       " 'शब्द': 743,\n",
       " 'घंटे': 744,\n",
       " 'आखिरकार': 745,\n",
       " 'कनाडा': 746,\n",
       " 'यूरोप': 747,\n",
       " 'नियम': 748,\n",
       " 'पार': 749,\n",
       " 'बोली': 750,\n",
       " 'बोलना': 751,\n",
       " 'सपना': 752,\n",
       " 'नगर': 753,\n",
       " 'दुकान': 754,\n",
       " 'चाहेंगे': 755,\n",
       " 'हमसे': 756,\n",
       " 'टिकटें': 757,\n",
       " 'अमेरिका': 758,\n",
       " 'अफ़्रीका': 759,\n",
       " 'बेटे': 760,\n",
       " 'पकड़': 761,\n",
       " 'हद': 762,\n",
       " 'इसलिए': 763,\n",
       " 'जहाज़': 764,\n",
       " 'इरादा': 765,\n",
       " 'सोते': 766,\n",
       " 'सोमवार': 767,\n",
       " 'घंटों': 768,\n",
       " 'लिखा': 769,\n",
       " 'बेहतर': 770,\n",
       " 'बहनें': 771,\n",
       " 'आजकल': 772,\n",
       " 'बेचैन': 773,\n",
       " 'ढूँढने': 774,\n",
       " 'विषय': 775,\n",
       " 'विमान': 776,\n",
       " 'कॉलेज': 777,\n",
       " 'विश्व': 778,\n",
       " 'सुन': 779,\n",
       " 'चीन': 780,\n",
       " 'सामान': 781,\n",
       " 'पालन': 782,\n",
       " 'केवल': 783,\n",
       " 'ख़रीद': 784,\n",
       " 'लायक': 785,\n",
       " 'मुताबिक': 786,\n",
       " 'सुनने': 787,\n",
       " 'क्रिकेट': 788,\n",
       " 'शौकिया': 789,\n",
       " 'कर्मचारियों': 790,\n",
       " 'बनाने': 791,\n",
       " 'ब्रिज': 792,\n",
       " 'देते': 793,\n",
       " 'सरकार': 794,\n",
       " 'पड़ता': 795,\n",
       " 'वाह': 796,\n",
       " 'धन्यवाद': 797,\n",
       " 'करना।': 798,\n",
       " 'पंछी': 799,\n",
       " 'लेकिन': 800,\n",
       " 'बोर': 801,\n",
       " 'ठंड': 802,\n",
       " 'गाते': 803,\n",
       " 'बैठिए।': 804,\n",
       " 'मुस्कुराया।': 805,\n",
       " 'ताकतवर': 806,\n",
       " 'केक': 807,\n",
       " 'झूठ': 808,\n",
       " 'मुबारक': 809,\n",
       " 'मान': 810,\n",
       " 'चीजों': 811,\n",
       " 'व्यस्त': 812,\n",
       " 'बिल्ली': 813,\n",
       " 'सकतीं': 814,\n",
       " 'नक्शा': 815,\n",
       " 'गोली': 816,\n",
       " 'नए': 817,\n",
       " 'हों': 818,\n",
       " 'धोओ।': 819,\n",
       " 'पूछ': 820,\n",
       " 'इंतज़ार': 821,\n",
       " 'टोपी': 822,\n",
       " 'पति': 823,\n",
       " 'उल्टी': 824,\n",
       " 'नसीब': 825,\n",
       " 'काला': 826,\n",
       " 'सिखा': 827,\n",
       " 'चावल': 828,\n",
       " 'मूँह': 829,\n",
       " 'लम्बे': 830,\n",
       " 'कौनसी': 831,\n",
       " 'नींद': 832,\n",
       " 'नीली': 833,\n",
       " 'शादीशुदा': 834,\n",
       " 'बताओ।': 835,\n",
       " 'रेडियो': 836,\n",
       " 'मिले': 837,\n",
       " 'औरतों': 838,\n",
       " 'महंगी': 839,\n",
       " 'रेलगाड़ी': 840,\n",
       " 'कौआ': 841,\n",
       " 'तोड़': 842,\n",
       " 'बनाया': 843,\n",
       " 'खरीदी।': 844,\n",
       " 'बताने': 845,\n",
       " 'शराब': 846,\n",
       " 'टिकट': 847,\n",
       " 'कमीज़': 848,\n",
       " 'टैक्स': 849,\n",
       " 'पेनसिल': 850,\n",
       " 'जॉगिंग': 851,\n",
       " 'समुंदर': 852,\n",
       " 'प्रतीक्षा': 853,\n",
       " 'ज़ुकाम': 854,\n",
       " 'बारह': 855,\n",
       " 'मछली': 856,\n",
       " 'लाल': 857,\n",
       " 'पहने': 858,\n",
       " 'भूत': 859,\n",
       " 'लगतीं': 860,\n",
       " 'तेज़ी': 861,\n",
       " 'रख': 862,\n",
       " 'व्यापार': 863,\n",
       " 'थोड़े': 864,\n",
       " 'घोड़े': 865,\n",
       " 'उनका': 866,\n",
       " 'छलाँग': 867,\n",
       " 'जाऊं': 868,\n",
       " 'गेंद': 869,\n",
       " 'बताओ': 870,\n",
       " 'छूट': 871,\n",
       " 'लगाई।': 872,\n",
       " 'जैसी': 873,\n",
       " 'भला': 874,\n",
       " 'गलत': 875,\n",
       " 'मजबूर': 876,\n",
       " 'बोलो।': 877,\n",
       " 'लेता': 878,\n",
       " 'खटखटाया।': 879,\n",
       " 'चुरा': 880,\n",
       " 'उठता': 881,\n",
       " 'ठंडा': 882,\n",
       " 'काले': 883,\n",
       " 'पियानो': 884,\n",
       " 'तेल': 885,\n",
       " 'उतना': 886,\n",
       " 'वैसे': 887,\n",
       " 'येन': 888,\n",
       " 'निर्णय': 889,\n",
       " 'फ़ुटबॉल': 890,\n",
       " 'इलज़ाम': 891,\n",
       " 'गिलास': 892,\n",
       " 'बजने': 893,\n",
       " 'कुरसी': 894,\n",
       " 'लकड़ी': 895,\n",
       " 'चार': 896,\n",
       " 'देखते': 897,\n",
       " 'आपने': 898,\n",
       " 'कैंसर': 899,\n",
       " 'संतुष्ट': 900,\n",
       " 'मुलाक़ात': 901,\n",
       " 'टैक्सी': 902,\n",
       " 'टीम': 903,\n",
       " 'हाँ': 904,\n",
       " 'सज़ा': 905,\n",
       " 'गाड़ियाँ': 906,\n",
       " 'दिखाई': 907,\n",
       " 'होती।': 908,\n",
       " 'मुसीबत': 909,\n",
       " 'क्लब': 910,\n",
       " 'शाम': 911,\n",
       " 'देखकर': 912,\n",
       " 'छाया': 913,\n",
       " 'निर्भर': 914,\n",
       " 'धन्यवाद।': 915,\n",
       " 'बनी': 916,\n",
       " 'रोने': 917,\n",
       " 'पड़ा।': 918,\n",
       " 'बीस': 919,\n",
       " 'रक्षा': 920,\n",
       " 'करवाना': 921,\n",
       " 'बदलने': 922,\n",
       " 'जगह': 923,\n",
       " 'जरूरत': 924,\n",
       " 'समान': 925,\n",
       " 'सर': 926,\n",
       " 'चोट': 927,\n",
       " 'दोगे': 928,\n",
       " 'अगली': 929,\n",
       " 'आता।': 930,\n",
       " 'बर्ताव': 931,\n",
       " 'खूबसूरत': 932,\n",
       " 'बर्बादी': 933,\n",
       " 'धीमी': 934,\n",
       " 'खेलने': 935,\n",
       " 'दफ़्तर': 936,\n",
       " 'सुथरा': 937,\n",
       " 'भाषण': 938,\n",
       " 'नतीजे': 939,\n",
       " 'खेत': 940,\n",
       " 'नानी': 941,\n",
       " 'अलावा': 942,\n",
       " 'बढ़': 943,\n",
       " 'रवाना': 944,\n",
       " 'छोड़ना': 945,\n",
       " 'खड़ी': 946,\n",
       " 'सी': 947,\n",
       " 'मक्खन': 948,\n",
       " 'जाता।': 949,\n",
       " 'जाऊँगी।': 950,\n",
       " 'सपने': 951,\n",
       " 'डाक': 952,\n",
       " 'मानते': 953,\n",
       " 'उनसे': 954,\n",
       " 'पत्र': 955,\n",
       " 'तुमको': 956,\n",
       " 'खतरनाक': 957,\n",
       " 'कविता': 958,\n",
       " 'निकालते': 959,\n",
       " 'व्यक्ति': 960,\n",
       " 'भोजन': 961,\n",
       " 'छत': 962,\n",
       " 'रहा।': 963,\n",
       " 'बातचीत': 964,\n",
       " 'होतीं': 965,\n",
       " 'कब्रिस्तान': 966,\n",
       " 'पहली': 967,\n",
       " 'बाज़ार': 968,\n",
       " 'स्टॉप': 969,\n",
       " 'देता': 970,\n",
       " 'जल्दबाज़ी': 971,\n",
       " 'अखबार': 972,\n",
       " 'उत्तर': 973,\n",
       " 'शर्म': 974,\n",
       " 'पचास': 975,\n",
       " 'तस्वीरें': 976,\n",
       " 'अस्पताल': 977,\n",
       " 'कम्प्यूटर': 978,\n",
       " 'लिख': 979,\n",
       " 'इतनी': 980,\n",
       " 'संदेश': 981,\n",
       " 'खाते': 982,\n",
       " 'उठते': 983,\n",
       " 'वसीयत': 984,\n",
       " 'शक': 985,\n",
       " 'जानना': 986,\n",
       " 'हैरान': 987,\n",
       " 'जेब': 988,\n",
       " 'पकड़ा': 989,\n",
       " 'मौके': 990,\n",
       " 'बुलाया': 991,\n",
       " 'कम्पनी': 992,\n",
       " 'जाया': 993,\n",
       " 'जिससे': 994,\n",
       " 'पछतावा': 995,\n",
       " 'चाहे': 996,\n",
       " 'जाए': 997,\n",
       " 'देगी।': 998,\n",
       " 'कहने': 999,\n",
       " 'पाया': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_t.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hi_fC8V3KXnR"
   },
   "source": [
    "### Compare different sentences length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XaoE7nULKXnS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length for sentence number 100:  2\n",
      "Length for sentence number 2000:  8\n"
     ]
    }
   ],
   "source": [
    "#Source Language sentences\n",
    "print('Length for sentence number 100: ', len(encoder_seq[100]))\n",
    "print('Length for sentence number 2000: ', len(encoder_seq[2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFRd3s8XKXnV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length for sentence number 100:  5\n",
      "Length for sentence number 2000:  13\n"
     ]
    }
   ],
   "source": [
    "#Target Language sentences\n",
    "print('Length for sentence number 100: ', len(decoder_seq[100]))\n",
    "print('Length for sentence number 2000: ', len(decoder_seq[2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('We promised.', '<start> हमने वादा किया। <end>')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_text[100], decoder_text[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-IatvBFKXnY"
   },
   "source": [
    "### How do we make it same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNZ8AeLKKXnZ"
   },
   "source": [
    "### Padding the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfKDl8IAKXna"
   },
   "outputs": [],
   "source": [
    "#Source sentences\n",
    "encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq, \n",
    "                                                                   maxlen=max_encoder_seq_length, #22\n",
    "                                                                   padding='pre')\n",
    "\n",
    "#Target Sentences\n",
    "decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq, \n",
    "                                                                   maxlen=max_decoder_seq_length, #27\n",
    "                                                                   padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1576303692517,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "ZLTwqyLyKXnc",
    "outputId": "2e9f066b-b5bc-4f2c-8ee6-881c55defddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source data shape:  (2980, 22)\n",
      "Target data shape:  (2980, 27)\n"
     ]
    }
   ],
   "source": [
    "print('Source data shape: ', encoder_input_data.shape)\n",
    "print('Target data shape: ', decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHIXCliIKXne"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A man must work.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_text[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgBriKXSKXnf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   5,  92,  96, 104])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJMPcCflKXnh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> एक आदमी के लिए काम करना ज़रूरी है। <end>'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_text[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QokbLugoKXnj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  18, 129,  12,  27,  52,  53, 536,   3,   2,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZoH9-bJKXnk"
   },
   "source": [
    "#### Integer to Word converter for Decoder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IuoP4YMeKXnl"
   },
   "outputs": [],
   "source": [
    "int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3983,
     "status": "ok",
     "timestamp": 1576304685251,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "yVOpq75gKXnm",
    "outputId": "7a8ce172-9207-47e7-a437-60bfb3694021"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'हैं।'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word_decoder[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPTsEs-DKXno"
   },
   "source": [
    "### Building Decoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2164,
     "status": "ok",
     "timestamp": 1576304697553,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "T0Edu4F4KXnp",
    "outputId": "f8440ac6-b5bc-4edd-baee-355bf61a24e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980, 27)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtrzQgsDKXns"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Initialize array\n",
    "decoder_target_data = np.zeros((decoder_input_data.shape[0], \n",
    "                                decoder_input_data.shape[1]))\n",
    "\n",
    "#Shift Target output by one word\n",
    "for i in range(decoder_input_data.shape[0]):\n",
    "    for j in range(1,decoder_input_data.shape[1]):\n",
    "        decoder_target_data[i][j-1] = decoder_input_data[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVjADS08KXnt"
   },
   "outputs": [],
   "source": [
    "#decoder_t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5V8wz3XKXnv"
   },
   "outputs": [],
   "source": [
    "#<start> yeh kitab hai <end>\n",
    "#Yeh kitab hai <end> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1576304741195,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "gL9a-mGTKXn2",
    "outputId": "af542674-2fe0-45bd-d292-9a07f3c1ac75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 796,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1576304747044,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "R-norMzYKXn5",
    "outputId": "8a90fbb1-c256-4663-e380-62398bbbe260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([796.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHH_em9TKXn6"
   },
   "source": [
    "#### Convert target data in one hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUXNoSeHKXn7"
   },
   "outputs": [],
   "source": [
    "#Initialize one hot encoding array\n",
    "decoder_target_one_hot = np.zeros((decoder_input_data.shape[0], #number of sentences\n",
    "                                   decoder_input_data.shape[1], #Number of words in each sentence\n",
    "                                   len(decoder_t.word_index)+1)) #Vocab size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1576304816290,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "YvDD6DZrKXn9",
    "outputId": "6c1c5b46-1781-4516-822a-34e40704c577"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_one_hot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5h-PeIGKXoA"
   },
   "outputs": [],
   "source": [
    "#Build one hot encoded array\n",
    "for i in range(decoder_target_data.shape[0]):\n",
    "    for j in range(decoder_target_data.shape[1]):\n",
    "        decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n",
    "                                                                     num_classes=len(decoder_t.word_index)+1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_one_hot[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Emzjo90KXoB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980, 27, 3049)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eOAOZrxBgK5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 3049)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_one_hot[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6BNPWZ_KXoD"
   },
   "source": [
    "### Building the Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q05uAVLXKXoD"
   },
   "outputs": [],
   "source": [
    "#Define config parameters\n",
    "encoder_embedding_size = 50\n",
    "decoder_embedding_size = 50\n",
    "rnn_units = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9M9eJGmSKXoF"
   },
   "source": [
    "#### Build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJIqwk7aKkJ9"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1576306561384,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "x5P1hzBqKXoG",
    "outputId": "98ac3831-f6f5-4c7c-95da-158fad7ee2fc"
   },
   "outputs": [],
   "source": [
    "#Input Layer\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "\n",
    "#Embedding layer\n",
    "encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, \n",
    "                                              encoder_embedding_size)\n",
    "\n",
    "#Get embedding layer output by feeding inputs\n",
    "encoder_embedding_output = encoder_embedding(encoder_inputs)\n",
    "\n",
    "#LSTM Layer and its output\n",
    "x, state_h, state_c = tf.keras.layers.LSTM(rnn_units,return_state=True)(encoder_embedding_output)\n",
    "\n",
    "#Build a list to feed Decoder - Sentence Embedding\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrcqxcfhKXoH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 50) dtype=float32 (created by layer 'embedding_1')>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_embedding_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EJvG6HRdKXoM"
   },
   "source": [
    "#### Build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LQEt7zPKXoM"
   },
   "outputs": [],
   "source": [
    "#Decode input - padded Target sentences\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "\n",
    "#Decoder Embedding layer\n",
    "decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1, \n",
    "                                              decoder_embedding_size)\n",
    "\n",
    "#Embedding layer output\n",
    "decoder_embedding_output = decoder_embedding(decoder_inputs)\n",
    "\n",
    "#Decoder RNN\n",
    "decoder_rnn = tf.keras.layers.LSTM(rnn_units, \n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True, )\n",
    "\n",
    "#Decoder RNN Output, State initialization from Encoder states\n",
    "#Output will be all hidden sequences, last 'h' state and last 'c' state\n",
    "x,_,_ = decoder_rnn(decoder_embedding_output, \n",
    "                    initial_state=encoder_states)\n",
    "\n",
    "#Output Layer\n",
    "decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, #+1 to make sure one-hot encoding works for highest index value\n",
    "                                      activation='softmax')\n",
    "\n",
    "#Output of Dense layer\n",
    "decoder_outputs = decoder_dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MP3Xbx6v3qT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 256) dtype=float32 (created by layer 'lstm_2')>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byZkwGJNKXoR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 3049) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kabGUQ4KXoT"
   },
   "source": [
    "### Build Model using both Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkJyiM7uKXoT"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #2 Inputs to the model\n",
    "                              decoder_outputs) #Output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 827,
     "status": "ok",
     "timestamp": 1576306893481,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "A5IvOy0tKXoW",
    "outputId": "471f6d78-fe3e-42de-9bd7-08e308664bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 3049) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-Yfmp3AKXoY"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I30VxT7LKXoa"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1576306940342,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "WM-iPyu_Jbix",
    "outputId": "dec52a86-cdbf-4d44-f0fe-19aa373d5cd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 50)     120550      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 50)     152450      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 256),        314368      ['embedding_1[0][0]']            \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, None, 256),  314368      ['embedding_2[0][0]',            \n",
      "                                 (None, 256),                     'lstm_1[0][1]',                 \n",
      "                                 (None, 256)]                     'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 3049)   783593      ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,685,329\n",
      "Trainable params: 1,685,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608593,
     "status": "ok",
     "timestamp": 1576307646220,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "W-uw8R3_KXoa",
    "outputId": "51617748-c4fa-4b7f-b4e4-2330583a796f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 21s 347ms/step - loss: 3.5548 - val_loss: 2.9802\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 11s 296ms/step - loss: 1.6434 - val_loss: 3.0564\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 1.6018 - val_loss: 3.0613\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 11s 298ms/step - loss: 1.5723 - val_loss: 3.0543\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 1.5231 - val_loss: 2.9090\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 11s 288ms/step - loss: 1.4488 - val_loss: 2.7706\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 1.4008 - val_loss: 2.6885\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 11s 299ms/step - loss: 1.3708 - val_loss: 2.6669\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 11s 295ms/step - loss: 1.3483 - val_loss: 2.6537\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 1.3289 - val_loss: 2.6394\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 11s 284ms/step - loss: 1.3105 - val_loss: 2.6196\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 1.2932 - val_loss: 2.6269\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 11s 289ms/step - loss: 1.2765 - val_loss: 2.6319\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 1.2606 - val_loss: 2.6307\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 11s 288ms/step - loss: 1.2446 - val_loss: 2.6220\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 11s 288ms/step - loss: 1.2306 - val_loss: 2.6266\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 11s 285ms/step - loss: 1.2160 - val_loss: 2.6336\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 1.2012 - val_loss: 2.6433\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 11s 286ms/step - loss: 1.1867 - val_loss: 2.6395\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 11s 292ms/step - loss: 1.1721 - val_loss: 2.6513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8754d5420>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], \n",
    "          decoder_target_one_hot,\n",
    "          batch_size=64,\n",
    "          epochs=20,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDZlu731KXob"
   },
   "source": [
    "### Save the model for later reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpUOjtksKXoc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_training_translation.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_training_translation.hd5\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('seq2seq_training_translation.hd5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "guuaYKaDKXod"
   },
   "source": [
    "# Building Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-tXkDaqKXod"
   },
   "source": [
    "### Build the Encoder Model to predict Encoder States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdM2QenRKXod"
   },
   "outputs": [],
   "source": [
    "encoder_model = tf.keras.models.Model(encoder_inputs, #Padded input sequences\n",
    "                                      encoder_states) #Hidden state and Cell state at last time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jj07QPsc941I"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_1')>,\n",
       " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_1')>]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBvy3uDnKXof"
   },
   "source": [
    "### Build the Decoder Model \n",
    "<p/>\n",
    "\n",
    "<ol><li>Define Input for both 'h' state and 'c' state initialization </li>\n",
    "<li>Get Decoder RNN outputs along with h and c state</li>\n",
    "<li>Get Decoder Dense layer output</li>\n",
    "        <li>Build Model</li></ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ohsoa5J_KXof"
   },
   "source": [
    "##### Step 1 - Define Input for both 'h' state and 'c' state initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aNlm9ufvKXoh"
   },
   "outputs": [],
   "source": [
    "#Hidden state input\n",
    "decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n",
    "\n",
    "#Cell state input\n",
    "decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n",
    "\n",
    "#Putting it together\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzbTg44oKXoi"
   },
   "source": [
    "##### Step 2 - Get Decoder RNN outputs along with h and c state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVHzmr1hKXoi"
   },
   "outputs": [],
   "source": [
    "#Get Embedding layer output\n",
    "x = decoder_embedding(decoder_inputs)\n",
    "\n",
    "#We will use the layer which we trained earlier\n",
    "rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n",
    "\n",
    "#Why do we need this?\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gX884-sKXoj"
   },
   "source": [
    "##### Step 3 - Get Decoder Dense layer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lj9ZkJh0KXoj"
   },
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_dense(rnn_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0HiEPMqnKXok"
   },
   "source": [
    "##### Step 4 - Build Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExV0PWSPKXol"
   },
   "outputs": [],
   "source": [
    "decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs,  #Model inputs\n",
    "                                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnKbxenGKXom"
   },
   "source": [
    "# Predicting output from Seq2Seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFsy3KR7KXon"
   },
   "source": [
    "##### Build a prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIwVWxXXKXon"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_t.word_index['<start>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nR2H6c3YKXop"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start>'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word_decoder[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VEG8fmnbKXop"
   },
   "outputs": [],
   "source": [
    "def decode_sentence(input_sequence):\n",
    "    \n",
    "    #Get the encoder state values - Sentence embedding\n",
    "    decoder_initial_states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #Build a sequence with '<start>' - starting sequence for Decoder\n",
    "    target_seq = np.zeros((1,1))    \n",
    "    target_seq[0][0] = decoder_t.word_index['<start>']\n",
    "    \n",
    "    #flag to check if prediction should be stopped\n",
    "    stop_loop = False\n",
    "    \n",
    "    #Initialize predicted sentence\n",
    "    predicted_sentence = ''\n",
    "    \n",
    "    num_of_predictions = 0\n",
    "    \n",
    "    #start the loop\n",
    "    while not stop_loop:\n",
    "        \n",
    "        predicted_outputs, h, c = decoder_model.predict([target_seq] + \n",
    "                                                        decoder_initial_states_value)\n",
    "        \n",
    "        #Get the predicted word index with highest probability\n",
    "        predicted_output = np.argmax(predicted_outputs[0,-1,:])\n",
    "        \n",
    "        #Get the predicted word from predicter index\n",
    "        predicted_word = int_to_word_decoder[predicted_output]\n",
    "        \n",
    "        #Check if prediction should stop\n",
    "        if(predicted_word == '<end>' or num_of_predictions > max_decoder_seq_length):\n",
    "            \n",
    "            stop_loop = True\n",
    "            continue\n",
    "        \n",
    "        num_of_predictions += 1\n",
    "        \n",
    "        #Updated predicted sentence\n",
    "        if (len(predicted_sentence) == 0):\n",
    "            predicted_sentence = predicted_word\n",
    "        else:\n",
    "            predicted_sentence = predicted_sentence + ' ' + predicted_word\n",
    "            \n",
    "        #Update target_seq to be the predicted word index\n",
    "        target_seq[0][0] = predicted_output\n",
    "        \n",
    "        #Update initial states value for decoder\n",
    "        decoder_initial_states_value = [h,c]\n",
    "        \n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_jtZM8iaKXoq"
   },
   "source": [
    "##### Call Prediction function on a random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1515,
     "status": "ok",
     "timestamp": 1576308757256,
     "user": {
      "displayName": "Rajeev Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBC_Jt2baS4Hv7JJvLmgAJFGZpvIs0sh5ggT7ZM9hw=s64",
      "userId": "10567937244174773728"
     },
     "user_tz": -330
    },
    "id": "perGUle1KXor",
    "outputId": "7c8e2d6b-b153-4264-ea3e-ea6f56064011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 966ms/step\n",
      "1/1 [==============================] - 1s 738ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "--------\n",
      "Input sentence:  That is not a tiger.\n",
      "Predicted sentence:  मैं बहुत नहीं है।\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "--------\n",
      "Input sentence:  That was my mistake.\n",
      "Predicted sentence:  मैं एक बहुत नहीं है।\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "--------\n",
      "Input sentence:  The skies are clear.\n",
      "Predicted sentence:  मैं बहुत नहीं है।\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "--------\n",
      "Input sentence:  The trees are green.\n",
      "Predicted sentence:  मैं बहुत नहीं है।\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "--------\n",
      "Input sentence:  These are our books.\n",
      "Predicted sentence:  मैं एक बहुत नहीं है।\n"
     ]
    }
   ],
   "source": [
    "#Generate a random number\n",
    "start_num = np.random.randint(0, high=len(encoder_text) - 10)\n",
    "\n",
    "#Predict model output for 5 sentences\n",
    "for i in range(start_num, start_num + 5):\n",
    "    input_seq = encoder_input_data[i : i+1]\n",
    "    predicted_sentence = decode_sentence(input_seq)\n",
    "    print('--------')\n",
    "    print ('Input sentence: ', encoder_text[i])\n",
    "    print ('Predicted sentence: ', predicted_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqi_-4Y0KXos"
   },
   "source": [
    "##### Save encoder and decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1TbJoYhJKXos"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_encoder_eng_hin.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_encoder_eng_hin.hd5\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_decoder_eng_hin.hd5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq_decoder_eng_hin.hd5\\assets\n"
     ]
    }
   ],
   "source": [
    "#Compile models to avoid error\n",
    "encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "\n",
    "#Save the models\n",
    "encoder_model.save('seq2seq_encoder_eng_hin.hd5')  #Encoder model\n",
    "decoder_model.save('seq2seq_decoder_eng_hin.hd5')  #Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skLA1matKXot"
   },
   "source": [
    "##### Save encoder and decoder tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCLkBUL7KXou"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(encoder_t,open('encoder_tokenizer_eng','wb'))\n",
    "pickle.dump(decoder_t,open('decoder_tokenizer_hin','wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1. Seq2Seq LSTM Model - Translation_with_prediction.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
