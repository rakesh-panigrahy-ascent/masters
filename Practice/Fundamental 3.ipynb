{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f05fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c1c00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,))\n",
    "dense = layers.Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f12c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291f844",
   "metadata": {},
   "source": [
    "#### Use the same graph of layers to define multiple models\n",
    "In the functional API, models are created by specifying their inputs and outputs in a graph of layers. That means that a single graph of layers can be used to generate multiple models.\n",
    "\n",
    "In the example below, you use the same stack of layers to instantiate two models: an encoder model that turns image inputs into 16-dimensional vectors, and an end-to-end autoencoder model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43b4a550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 32)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 16)               0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 1)           0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 6, 6, 16)         160       \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 32)         4640      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 24, 24, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 26, 26, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 28, 28, 1)        145       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e02a64a",
   "metadata": {},
   "source": [
    "Here, the decoding architecture is strictly symmetrical to the encoding architecture, so the output shape is the same as the input shape (28, 28, 1).\n",
    "\n",
    "The reverse of a Conv2D layer is a Conv2DTranspose layer, and the reverse of a MaxPooling2D layer is an UpSampling2D layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde79a7",
   "metadata": {},
   "source": [
    "#### All models are callable, just like layers\n",
    "You can treat any model as if it were a layer by invoking it on an Input or on the output of another layer. By calling a model you aren't just reusing the architecture of the model, you're also reusing its weights.\n",
    "\n",
    "To see this in action, here's a different take on the autoencoder example that creates an encoder model, a decoder model, and chains them in two calls to obtain the autoencoder model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da8ffbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " original_img (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Glo  (None, 16)               0         \n",
      " balMaxPooling2D)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoded_img (InputLayer)    [(None, 16)]              0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 1)           0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 6, 6, 16)         160       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 8, 8, 32)         4640      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 24, 24, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 26, 26, 16)       4624      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2DT  (None, 28, 28, 1)        145       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,569\n",
      "Trainable params: 9,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                18672     \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         9569      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6102f678",
   "metadata": {},
   "source": [
    "#### Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a64217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputs = keras.Input(shape=(128,))\n",
    "    outputs = layers.Dense(1)(inputs)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model1 = get_model()\n",
    "model2 = get_model()\n",
    "model3 = get_model()\n",
    "\n",
    "inputs = keras.Input(shape=(128,))\n",
    "y1 = model1(inputs)\n",
    "y2 = model2(inputs)\n",
    "y3 = model3(inputs)\n",
    "outputs = layers.average([y1, y2, y3])\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e763b0",
   "metadata": {},
   "source": [
    "### Manipulate complex graph topologies\n",
    "#### Models with multiple inputs and outputs\n",
    "The functional API makes it easy to manipulate multiple inputs and outputs. This cannot be handled with the Sequential API.\n",
    "\n",
    "For example, if you're building a system for ranking customer issue tickets by priority and routing them to the correct department, then the model will have three inputs:\n",
    "\n",
    "* the title of the ticket (text input),\n",
    "* the text body of the ticket (text input), and\n",
    "* any tags added by the user (categorical input)\n",
    "\n",
    "This model will have two outputs:\n",
    "\n",
    "* the priority score between 0 and 1 (scalar sigmoid output), and\n",
    "* the department that should handle the ticket (softmax output over the set of departments).\n",
    "You can build this model in a few lines with the functional API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea9fb331",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(\n",
    "    shape=(None,), name=\"title\"\n",
    ")  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(\n",
    "    shape=(num_tags,), name=\"tags\"\n",
    ")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d0476ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Now plot the model:\n",
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72d90c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " title (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " body (InputLayer)              [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 64)     640000      ['title[0][0]']                  \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 64)     640000      ['body[0][0]']                   \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 128)          98816       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 32)           12416       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " tags (InputLayer)              [(None, 12)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 172)          0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_1[0][0]',                 \n",
      "                                                                  'tags[0][0]']                   \n",
      "                                                                                                  \n",
      " priority (Dense)               (None, 1)            173         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " department (Dense)             (None, 4)            692         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,392,097\n",
      "Trainable params: 1,392,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bee8a850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    },\n",
    "    loss_weights={\"priority\": 1.0, \"department\": 0.2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3729e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "40/40 [==============================] - 7s 44ms/step - loss: 1.2753 - priority_loss: 0.6981 - department_loss: 2.8859\n",
      "Epoch 2/2\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 1.2741 - priority_loss: 0.6977 - department_loss: 2.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x205eb0c63d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f193f",
   "metadata": {},
   "source": [
    "#### A toy ResNet model\n",
    "In addition to models with multiple inputs and outputs, the functional API makes it easy to manipulate non-linear connectivity topologies -- these are models with layers that are not connected sequentially, which the Sequential API cannot handle.\n",
    "\n",
    "A common use case for this is residual connections. Let's build a toy ResNet model for CIFAR10 to demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ebc0341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"toy_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " img (InputLayer)               [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 30, 30, 32)   896         ['img[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 28, 28, 64)   18496       ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 9, 9, 64)    0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 9, 9, 64)     36928       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 9, 9, 64)     36928       ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 9, 9, 64)     0           ['conv2d_11[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 9, 9, 64)     36928       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 9, 9, 64)     36928       ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 9, 9, 64)     0           ['conv2d_13[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 7, 7, 64)     36928       ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 64)          0           ['conv2d_14[0][0]']              \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 256)          16640       ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 10)           2570        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "block_1_output = layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_2_output = layers.add([x, block_1_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "block_3_output = layers.add([x, block_2_output])\n",
    "\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(10)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name=\"toy_resnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8567a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 228s 1us/step\n",
      "13/13 [==============================] - 4s 174ms/step - loss: 2.3025 - acc: 0.1325 - val_loss: 2.5025 - val_acc: 0.1150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x205f43f5850>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "# We restrict the data to the first 1000 samples so as to limit execution time\n",
    "# on Colab. Try to train on the entire dataset until convergence!\n",
    "model.fit(x_train[:1000], y_train[:1000], batch_size=64, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf97d5a",
   "metadata": {},
   "source": [
    "#### Shared layers\n",
    "\n",
    "Another good use for the functional API are models that use shared layers. Shared layers are layer instances that are reused multiple times in the same model -- they learn features that correspond to multiple paths in the graph-of-layers.\n",
    "\n",
    "Shared layers are often used to encode inputs from similar spaces (say, two different pieces of text that feature similar vocabulary). They enable sharing of information across these different inputs, and they make it possible to train such a model on less data. If a given word is seen in one of the inputs, that will benefit the processing of all inputs that pass through the shared layer.\n",
    "\n",
    "To share a layer in the functional API, call the same layer instance multiple times. For instance, here's an Embedding layer shared across two different text inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3ef546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "shared_embedding = layers.Embedding(1000, 128)\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_a = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Variable-length sequence of integers\n",
    "text_input_b = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Reuse the same layer to encode both inputs\n",
    "encoded_input_a = shared_embedding(text_input_a)\n",
    "encoded_input_b = shared_embedding(text_input_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06296be7",
   "metadata": {},
   "source": [
    "##### Extend the API using custom layers\n",
    "tf.keras includes a wide range of built-in layers, for example:\n",
    "\n",
    "* Convolutional layers: Conv1D, Conv2D, Conv3D, Conv2DTranspose\n",
    "* Pooling layers: MaxPooling1D, MaxPooling2D, MaxPooling3D, AveragePooling1D\n",
    "* RNN layers: GRU, LSTM, ConvLSTM2D\n",
    "* BatchNormalization, Dropout, Embedding, etc.\n",
    "\n",
    "But if you don't find what you need, it's easy to extend the API by creating your own layers. All layers subclass the Layer class and implement:\n",
    "\n",
    "* call method, that specifies the computation done by the layer.\n",
    "* build method, that creates the weights of the layer (this is just a style convention since you can create weights in __init__, as well).\n",
    "To learn more about creating layers from scratch, read custom layers and models guide.\n",
    "\n",
    "The following is a basic implementation of tf.keras.layers.Dense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b262b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"units\": self.units}\n",
    "\n",
    "\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "\n",
    "new_model = keras.Model.from_config(config, custom_objects={\"CustomDense\": CustomDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbc0bf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model_6',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 4),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_12'},\n",
       "   'name': 'input_12',\n",
       "   'inbound_nodes': []},\n",
       "  {'class_name': 'CustomDense',\n",
       "   'config': {'units': 10},\n",
       "   'name': 'custom_dense_1',\n",
       "   'inbound_nodes': [[['input_12', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_12', 0, 0]],\n",
       " 'output_layers': [['custom_dense_1', 0, 0]]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
